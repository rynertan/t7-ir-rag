{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage\n",
    "import logging\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.readers.file.base:> [SimpleDirectoryReader] Total files added: 7\n",
      "> [SimpleDirectoryReader] Total files added: 7\n",
      "> [SimpleDirectoryReader] Total files added: 7\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 62 0 (offset 0)\n",
      "Ignoring wrong pointing object 62 0 (offset 0)\n",
      "Ignoring wrong pointing object 62 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 64 0 (offset 0)\n",
      "Ignoring wrong pointing object 64 0 (offset 0)\n",
      "Ignoring wrong pointing object 64 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 66 0 (offset 0)\n",
      "Ignoring wrong pointing object 66 0 (offset 0)\n",
      "Ignoring wrong pointing object 66 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 68 0 (offset 0)\n",
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 73 0 (offset 0)\n",
      "Ignoring wrong pointing object 73 0 (offset 0)\n",
      "Ignoring wrong pointing object 73 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 106 0 (offset 0)\n",
      "Ignoring wrong pointing object 106 0 (offset 0)\n",
      "Ignoring wrong pointing object 106 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 129 0 (offset 0)\n",
      "Ignoring wrong pointing object 129 0 (offset 0)\n",
      "Ignoring wrong pointing object 129 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 131 0 (offset 0)\n",
      "Ignoring wrong pointing object 131 0 (offset 0)\n",
      "Ignoring wrong pointing object 131 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 133 0 (offset 0)\n",
      "Ignoring wrong pointing object 133 0 (offset 0)\n",
      "Ignoring wrong pointing object 133 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 136 0 (offset 0)\n",
      "Ignoring wrong pointing object 136 0 (offset 0)\n",
      "Ignoring wrong pointing object 136 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 138 0 (offset 0)\n",
      "Ignoring wrong pointing object 138 0 (offset 0)\n",
      "Ignoring wrong pointing object 138 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 146 0 (offset 0)\n",
      "Ignoring wrong pointing object 146 0 (offset 0)\n",
      "Ignoring wrong pointing object 146 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 159 0 (offset 0)\n",
      "Ignoring wrong pointing object 159 0 (offset 0)\n",
      "Ignoring wrong pointing object 159 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 161 0 (offset 0)\n",
      "Ignoring wrong pointing object 161 0 (offset 0)\n",
      "Ignoring wrong pointing object 161 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 165 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 185 0 (offset 0)\n",
      "Ignoring wrong pointing object 185 0 (offset 0)\n",
      "Ignoring wrong pointing object 185 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 187 0 (offset 0)\n",
      "Ignoring wrong pointing object 187 0 (offset 0)\n",
      "Ignoring wrong pointing object 187 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 198 0 (offset 0)\n",
      "Ignoring wrong pointing object 198 0 (offset 0)\n",
      "Ignoring wrong pointing object 198 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 200 0 (offset 0)\n",
      "Ignoring wrong pointing object 200 0 (offset 0)\n",
      "Ignoring wrong pointing object 200 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 202 0 (offset 0)\n",
      "Ignoring wrong pointing object 202 0 (offset 0)\n",
      "Ignoring wrong pointing object 202 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 204 0 (offset 0)\n",
      "Ignoring wrong pointing object 204 0 (offset 0)\n",
      "Ignoring wrong pointing object 204 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 234 0 (offset 0)\n",
      "Ignoring wrong pointing object 234 0 (offset 0)\n",
      "Ignoring wrong pointing object 234 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 255 0 (offset 0)\n",
      "Ignoring wrong pointing object 255 0 (offset 0)\n",
      "Ignoring wrong pointing object 255 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 266 0 (offset 0)\n",
      "Ignoring wrong pointing object 266 0 (offset 0)\n",
      "Ignoring wrong pointing object 266 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 268 0 (offset 0)\n",
      "Ignoring wrong pointing object 268 0 (offset 0)\n",
      "Ignoring wrong pointing object 268 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 270 0 (offset 0)\n",
      "Ignoring wrong pointing object 270 0 (offset 0)\n",
      "Ignoring wrong pointing object 270 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 272 0 (offset 0)\n",
      "Ignoring wrong pointing object 272 0 (offset 0)\n",
      "Ignoring wrong pointing object 272 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 286 0 (offset 0)\n",
      "Ignoring wrong pointing object 286 0 (offset 0)\n",
      "Ignoring wrong pointing object 286 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 288 0 (offset 0)\n",
      "Ignoring wrong pointing object 288 0 (offset 0)\n",
      "Ignoring wrong pointing object 288 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 294 0 (offset 0)\n",
      "Ignoring wrong pointing object 294 0 (offset 0)\n",
      "Ignoring wrong pointing object 294 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 318 0 (offset 0)\n",
      "Ignoring wrong pointing object 318 0 (offset 0)\n",
      "Ignoring wrong pointing object 318 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 320 0 (offset 0)\n",
      "Ignoring wrong pointing object 320 0 (offset 0)\n",
      "Ignoring wrong pointing object 320 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 354 0 (offset 0)\n",
      "Ignoring wrong pointing object 354 0 (offset 0)\n",
      "Ignoring wrong pointing object 354 0 (offset 0)\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 112 0 (offset 0)\n",
      "Ignoring wrong pointing object 112 0 (offset 0)\n",
      "Ignoring wrong pointing object 112 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 121 0 (offset 0)\n",
      "Ignoring wrong pointing object 121 0 (offset 0)\n",
      "Ignoring wrong pointing object 121 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 127 0 (offset 0)\n",
      "Ignoring wrong pointing object 127 0 (offset 0)\n",
      "Ignoring wrong pointing object 127 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 179 0 (offset 0)\n",
      "Ignoring wrong pointing object 179 0 (offset 0)\n",
      "Ignoring wrong pointing object 179 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 181 0 (offset 0)\n",
      "Ignoring wrong pointing object 181 0 (offset 0)\n",
      "Ignoring wrong pointing object 181 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 183 0 (offset 0)\n",
      "Ignoring wrong pointing object 183 0 (offset 0)\n",
      "Ignoring wrong pointing object 183 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 185 0 (offset 0)\n",
      "Ignoring wrong pointing object 185 0 (offset 0)\n",
      "Ignoring wrong pointing object 185 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 187 0 (offset 0)\n",
      "Ignoring wrong pointing object 187 0 (offset 0)\n",
      "Ignoring wrong pointing object 187 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 189 0 (offset 0)\n",
      "Ignoring wrong pointing object 189 0 (offset 0)\n",
      "Ignoring wrong pointing object 189 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 195 0 (offset 0)\n",
      "Ignoring wrong pointing object 195 0 (offset 0)\n",
      "Ignoring wrong pointing object 195 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 197 0 (offset 0)\n",
      "Ignoring wrong pointing object 197 0 (offset 0)\n",
      "Ignoring wrong pointing object 197 0 (offset 0)\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 39 0 (offset 0)\n",
      "Ignoring wrong pointing object 39 0 (offset 0)\n",
      "Ignoring wrong pointing object 39 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 85 0 (offset 0)\n",
      "Ignoring wrong pointing object 85 0 (offset 0)\n",
      "Ignoring wrong pointing object 85 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 92 0 (offset 0)\n",
      "Ignoring wrong pointing object 92 0 (offset 0)\n",
      "Ignoring wrong pointing object 92 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 94 0 (offset 0)\n",
      "Ignoring wrong pointing object 94 0 (offset 0)\n",
      "Ignoring wrong pointing object 94 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 96 0 (offset 0)\n",
      "Ignoring wrong pointing object 96 0 (offset 0)\n",
      "Ignoring wrong pointing object 96 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 100 0 (offset 0)\n",
      "Ignoring wrong pointing object 100 0 (offset 0)\n",
      "Ignoring wrong pointing object 100 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 112 0 (offset 0)\n",
      "Ignoring wrong pointing object 112 0 (offset 0)\n",
      "Ignoring wrong pointing object 112 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 114 0 (offset 0)\n",
      "Ignoring wrong pointing object 114 0 (offset 0)\n",
      "Ignoring wrong pointing object 114 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 116 0 (offset 0)\n",
      "Ignoring wrong pointing object 116 0 (offset 0)\n",
      "Ignoring wrong pointing object 116 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 118 0 (offset 0)\n",
      "Ignoring wrong pointing object 118 0 (offset 0)\n",
      "Ignoring wrong pointing object 118 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 147 0 (offset 0)\n",
      "Ignoring wrong pointing object 147 0 (offset 0)\n",
      "Ignoring wrong pointing object 147 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 157 0 (offset 0)\n",
      "Ignoring wrong pointing object 157 0 (offset 0)\n",
      "Ignoring wrong pointing object 157 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 159 0 (offset 0)\n",
      "Ignoring wrong pointing object 159 0 (offset 0)\n",
      "Ignoring wrong pointing object 159 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 161 0 (offset 0)\n",
      "Ignoring wrong pointing object 161 0 (offset 0)\n",
      "Ignoring wrong pointing object 161 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 165 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 172 0 (offset 0)\n",
      "Ignoring wrong pointing object 172 0 (offset 0)\n",
      "Ignoring wrong pointing object 172 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 182 0 (offset 0)\n",
      "Ignoring wrong pointing object 182 0 (offset 0)\n",
      "Ignoring wrong pointing object 182 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 192 0 (offset 0)\n",
      "Ignoring wrong pointing object 192 0 (offset 0)\n",
      "Ignoring wrong pointing object 192 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 215 0 (offset 0)\n",
      "Ignoring wrong pointing object 215 0 (offset 0)\n",
      "Ignoring wrong pointing object 215 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 219 0 (offset 0)\n",
      "Ignoring wrong pointing object 219 0 (offset 0)\n",
      "Ignoring wrong pointing object 219 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 221 0 (offset 0)\n",
      "Ignoring wrong pointing object 221 0 (offset 0)\n",
      "Ignoring wrong pointing object 221 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 229 0 (offset 0)\n",
      "Ignoring wrong pointing object 229 0 (offset 0)\n",
      "Ignoring wrong pointing object 229 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 233 0 (offset 0)\n",
      "Ignoring wrong pointing object 233 0 (offset 0)\n",
      "Ignoring wrong pointing object 233 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 235 0 (offset 0)\n",
      "Ignoring wrong pointing object 235 0 (offset 0)\n",
      "Ignoring wrong pointing object 235 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 245 0 (offset 0)\n",
      "Ignoring wrong pointing object 245 0 (offset 0)\n",
      "Ignoring wrong pointing object 245 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 248 0 (offset 0)\n",
      "Ignoring wrong pointing object 248 0 (offset 0)\n",
      "Ignoring wrong pointing object 248 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 254 0 (offset 0)\n",
      "Ignoring wrong pointing object 254 0 (offset 0)\n",
      "Ignoring wrong pointing object 254 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 256 0 (offset 0)\n",
      "Ignoring wrong pointing object 256 0 (offset 0)\n",
      "Ignoring wrong pointing object 256 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 258 0 (offset 0)\n",
      "Ignoring wrong pointing object 258 0 (offset 0)\n",
      "Ignoring wrong pointing object 258 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 266 0 (offset 0)\n",
      "Ignoring wrong pointing object 266 0 (offset 0)\n",
      "Ignoring wrong pointing object 266 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 268 0 (offset 0)\n",
      "Ignoring wrong pointing object 268 0 (offset 0)\n",
      "Ignoring wrong pointing object 268 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 270 0 (offset 0)\n",
      "Ignoring wrong pointing object 270 0 (offset 0)\n",
      "Ignoring wrong pointing object 270 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 274 0 (offset 0)\n",
      "Ignoring wrong pointing object 274 0 (offset 0)\n",
      "Ignoring wrong pointing object 274 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 276 0 (offset 0)\n",
      "Ignoring wrong pointing object 276 0 (offset 0)\n",
      "Ignoring wrong pointing object 276 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 278 0 (offset 0)\n",
      "Ignoring wrong pointing object 278 0 (offset 0)\n",
      "Ignoring wrong pointing object 278 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 295 0 (offset 0)\n",
      "Ignoring wrong pointing object 295 0 (offset 0)\n",
      "Ignoring wrong pointing object 295 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 299 0 (offset 0)\n",
      "Ignoring wrong pointing object 299 0 (offset 0)\n",
      "Ignoring wrong pointing object 299 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 301 0 (offset 0)\n",
      "Ignoring wrong pointing object 301 0 (offset 0)\n",
      "Ignoring wrong pointing object 301 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 303 0 (offset 0)\n",
      "Ignoring wrong pointing object 303 0 (offset 0)\n",
      "Ignoring wrong pointing object 303 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 305 0 (offset 0)\n",
      "Ignoring wrong pointing object 305 0 (offset 0)\n",
      "Ignoring wrong pointing object 305 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 307 0 (offset 0)\n",
      "Ignoring wrong pointing object 307 0 (offset 0)\n",
      "Ignoring wrong pointing object 307 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 309 0 (offset 0)\n",
      "Ignoring wrong pointing object 309 0 (offset 0)\n",
      "Ignoring wrong pointing object 309 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 420 0 (offset 0)\n",
      "Ignoring wrong pointing object 420 0 (offset 0)\n",
      "Ignoring wrong pointing object 420 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 427 0 (offset 0)\n",
      "Ignoring wrong pointing object 427 0 (offset 0)\n",
      "Ignoring wrong pointing object 427 0 (offset 0)\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 66 0 (offset 0)\n",
      "Ignoring wrong pointing object 66 0 (offset 0)\n",
      "Ignoring wrong pointing object 66 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 83 0 (offset 0)\n",
      "Ignoring wrong pointing object 83 0 (offset 0)\n",
      "Ignoring wrong pointing object 83 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 85 0 (offset 0)\n",
      "Ignoring wrong pointing object 85 0 (offset 0)\n",
      "Ignoring wrong pointing object 85 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 92 0 (offset 0)\n",
      "Ignoring wrong pointing object 92 0 (offset 0)\n",
      "Ignoring wrong pointing object 92 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 99 0 (offset 0)\n",
      "Ignoring wrong pointing object 99 0 (offset 0)\n",
      "Ignoring wrong pointing object 99 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 106 0 (offset 0)\n",
      "Ignoring wrong pointing object 106 0 (offset 0)\n",
      "Ignoring wrong pointing object 106 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 126 0 (offset 0)\n",
      "Ignoring wrong pointing object 126 0 (offset 0)\n",
      "Ignoring wrong pointing object 126 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 128 0 (offset 0)\n",
      "Ignoring wrong pointing object 128 0 (offset 0)\n",
      "Ignoring wrong pointing object 128 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 130 0 (offset 0)\n",
      "Ignoring wrong pointing object 130 0 (offset 0)\n",
      "Ignoring wrong pointing object 130 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 136 0 (offset 0)\n",
      "Ignoring wrong pointing object 136 0 (offset 0)\n",
      "Ignoring wrong pointing object 136 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 141 0 (offset 0)\n",
      "Ignoring wrong pointing object 141 0 (offset 0)\n",
      "Ignoring wrong pointing object 141 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 146 0 (offset 0)\n",
      "Ignoring wrong pointing object 146 0 (offset 0)\n",
      "Ignoring wrong pointing object 146 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 154 0 (offset 0)\n",
      "Ignoring wrong pointing object 154 0 (offset 0)\n",
      "Ignoring wrong pointing object 154 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 165 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 167 0 (offset 0)\n",
      "Ignoring wrong pointing object 167 0 (offset 0)\n",
      "Ignoring wrong pointing object 167 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 176 0 (offset 0)\n",
      "Ignoring wrong pointing object 176 0 (offset 0)\n",
      "Ignoring wrong pointing object 176 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 178 0 (offset 0)\n",
      "Ignoring wrong pointing object 178 0 (offset 0)\n",
      "Ignoring wrong pointing object 178 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 180 0 (offset 0)\n",
      "Ignoring wrong pointing object 180 0 (offset 0)\n",
      "Ignoring wrong pointing object 180 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 182 0 (offset 0)\n",
      "Ignoring wrong pointing object 182 0 (offset 0)\n",
      "Ignoring wrong pointing object 182 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 193 0 (offset 0)\n",
      "Ignoring wrong pointing object 193 0 (offset 0)\n",
      "Ignoring wrong pointing object 193 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 195 0 (offset 0)\n",
      "Ignoring wrong pointing object 195 0 (offset 0)\n",
      "Ignoring wrong pointing object 195 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 197 0 (offset 0)\n",
      "Ignoring wrong pointing object 197 0 (offset 0)\n",
      "Ignoring wrong pointing object 197 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 199 0 (offset 0)\n",
      "Ignoring wrong pointing object 199 0 (offset 0)\n",
      "Ignoring wrong pointing object 199 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 205 0 (offset 0)\n",
      "Ignoring wrong pointing object 205 0 (offset 0)\n",
      "Ignoring wrong pointing object 205 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 207 0 (offset 0)\n",
      "Ignoring wrong pointing object 207 0 (offset 0)\n",
      "Ignoring wrong pointing object 207 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 209 0 (offset 0)\n",
      "Ignoring wrong pointing object 209 0 (offset 0)\n",
      "Ignoring wrong pointing object 209 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 211 0 (offset 0)\n",
      "Ignoring wrong pointing object 211 0 (offset 0)\n",
      "Ignoring wrong pointing object 211 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 247 0 (offset 0)\n",
      "Ignoring wrong pointing object 247 0 (offset 0)\n",
      "Ignoring wrong pointing object 247 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 271 0 (offset 0)\n",
      "Ignoring wrong pointing object 271 0 (offset 0)\n",
      "Ignoring wrong pointing object 271 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 273 0 (offset 0)\n",
      "Ignoring wrong pointing object 273 0 (offset 0)\n",
      "Ignoring wrong pointing object 273 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 275 0 (offset 0)\n",
      "Ignoring wrong pointing object 275 0 (offset 0)\n",
      "Ignoring wrong pointing object 275 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 278 0 (offset 0)\n",
      "Ignoring wrong pointing object 278 0 (offset 0)\n",
      "Ignoring wrong pointing object 278 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 289 0 (offset 0)\n",
      "Ignoring wrong pointing object 289 0 (offset 0)\n",
      "Ignoring wrong pointing object 289 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 291 0 (offset 0)\n",
      "Ignoring wrong pointing object 291 0 (offset 0)\n",
      "Ignoring wrong pointing object 291 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 293 0 (offset 0)\n",
      "Ignoring wrong pointing object 293 0 (offset 0)\n",
      "Ignoring wrong pointing object 293 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 296 0 (offset 0)\n",
      "Ignoring wrong pointing object 296 0 (offset 0)\n",
      "Ignoring wrong pointing object 296 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 308 0 (offset 0)\n",
      "Ignoring wrong pointing object 308 0 (offset 0)\n",
      "Ignoring wrong pointing object 308 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 310 0 (offset 0)\n",
      "Ignoring wrong pointing object 310 0 (offset 0)\n",
      "Ignoring wrong pointing object 310 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 312 0 (offset 0)\n",
      "Ignoring wrong pointing object 312 0 (offset 0)\n",
      "Ignoring wrong pointing object 312 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 315 0 (offset 0)\n",
      "Ignoring wrong pointing object 315 0 (offset 0)\n",
      "Ignoring wrong pointing object 315 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 339 0 (offset 0)\n",
      "Ignoring wrong pointing object 339 0 (offset 0)\n",
      "Ignoring wrong pointing object 339 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 369 0 (offset 0)\n",
      "Ignoring wrong pointing object 369 0 (offset 0)\n",
      "Ignoring wrong pointing object 369 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 384 0 (offset 0)\n",
      "Ignoring wrong pointing object 384 0 (offset 0)\n",
      "Ignoring wrong pointing object 384 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 413 0 (offset 0)\n",
      "Ignoring wrong pointing object 413 0 (offset 0)\n",
      "Ignoring wrong pointing object 413 0 (offset 0)\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 25 0 (offset 0)\n",
      "Ignoring wrong pointing object 25 0 (offset 0)\n",
      "Ignoring wrong pointing object 25 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 31 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 39 0 (offset 0)\n",
      "Ignoring wrong pointing object 39 0 (offset 0)\n",
      "Ignoring wrong pointing object 39 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 47 0 (offset 0)\n",
      "Ignoring wrong pointing object 47 0 (offset 0)\n",
      "Ignoring wrong pointing object 47 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 57 0 (offset 0)\n",
      "Ignoring wrong pointing object 57 0 (offset 0)\n",
      "Ignoring wrong pointing object 57 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 59 0 (offset 0)\n",
      "Ignoring wrong pointing object 59 0 (offset 0)\n",
      "Ignoring wrong pointing object 59 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 61 0 (offset 0)\n",
      "Ignoring wrong pointing object 61 0 (offset 0)\n",
      "Ignoring wrong pointing object 61 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 63 0 (offset 0)\n",
      "Ignoring wrong pointing object 63 0 (offset 0)\n",
      "Ignoring wrong pointing object 63 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 73 0 (offset 0)\n",
      "Ignoring wrong pointing object 73 0 (offset 0)\n",
      "Ignoring wrong pointing object 73 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 75 0 (offset 0)\n",
      "Ignoring wrong pointing object 75 0 (offset 0)\n",
      "Ignoring wrong pointing object 75 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 77 0 (offset 0)\n",
      "Ignoring wrong pointing object 77 0 (offset 0)\n",
      "Ignoring wrong pointing object 77 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 79 0 (offset 0)\n",
      "Ignoring wrong pointing object 79 0 (offset 0)\n",
      "Ignoring wrong pointing object 79 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 81 0 (offset 0)\n",
      "Ignoring wrong pointing object 81 0 (offset 0)\n",
      "Ignoring wrong pointing object 81 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 83 0 (offset 0)\n",
      "Ignoring wrong pointing object 83 0 (offset 0)\n",
      "Ignoring wrong pointing object 83 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 85 0 (offset 0)\n",
      "Ignoring wrong pointing object 85 0 (offset 0)\n",
      "Ignoring wrong pointing object 85 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 94 0 (offset 0)\n",
      "Ignoring wrong pointing object 94 0 (offset 0)\n",
      "Ignoring wrong pointing object 94 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 100 0 (offset 0)\n",
      "Ignoring wrong pointing object 100 0 (offset 0)\n",
      "Ignoring wrong pointing object 100 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 102 0 (offset 0)\n",
      "Ignoring wrong pointing object 102 0 (offset 0)\n",
      "Ignoring wrong pointing object 102 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 113 0 (offset 0)\n",
      "Ignoring wrong pointing object 113 0 (offset 0)\n",
      "Ignoring wrong pointing object 113 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 115 0 (offset 0)\n",
      "Ignoring wrong pointing object 115 0 (offset 0)\n",
      "Ignoring wrong pointing object 115 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 121 0 (offset 0)\n",
      "Ignoring wrong pointing object 121 0 (offset 0)\n",
      "Ignoring wrong pointing object 121 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 123 0 (offset 0)\n",
      "Ignoring wrong pointing object 123 0 (offset 0)\n",
      "Ignoring wrong pointing object 123 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 156 0 (offset 0)\n",
      "Ignoring wrong pointing object 156 0 (offset 0)\n",
      "Ignoring wrong pointing object 156 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 165 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 174 0 (offset 0)\n",
      "Ignoring wrong pointing object 174 0 (offset 0)\n",
      "Ignoring wrong pointing object 174 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 176 0 (offset 0)\n",
      "Ignoring wrong pointing object 176 0 (offset 0)\n",
      "Ignoring wrong pointing object 176 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 178 0 (offset 0)\n",
      "Ignoring wrong pointing object 178 0 (offset 0)\n",
      "Ignoring wrong pointing object 178 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 180 0 (offset 0)\n",
      "Ignoring wrong pointing object 180 0 (offset 0)\n",
      "Ignoring wrong pointing object 180 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 184 0 (offset 0)\n",
      "Ignoring wrong pointing object 184 0 (offset 0)\n",
      "Ignoring wrong pointing object 184 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 186 0 (offset 0)\n",
      "Ignoring wrong pointing object 186 0 (offset 0)\n",
      "Ignoring wrong pointing object 186 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 188 0 (offset 0)\n",
      "Ignoring wrong pointing object 188 0 (offset 0)\n",
      "Ignoring wrong pointing object 188 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 191 0 (offset 0)\n",
      "Ignoring wrong pointing object 191 0 (offset 0)\n",
      "Ignoring wrong pointing object 191 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 205 0 (offset 0)\n",
      "Ignoring wrong pointing object 205 0 (offset 0)\n",
      "Ignoring wrong pointing object 205 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 212 0 (offset 0)\n",
      "Ignoring wrong pointing object 212 0 (offset 0)\n",
      "Ignoring wrong pointing object 212 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 214 0 (offset 0)\n",
      "Ignoring wrong pointing object 214 0 (offset 0)\n",
      "Ignoring wrong pointing object 214 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 216 0 (offset 0)\n",
      "Ignoring wrong pointing object 216 0 (offset 0)\n",
      "Ignoring wrong pointing object 216 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 220 0 (offset 0)\n",
      "Ignoring wrong pointing object 220 0 (offset 0)\n",
      "Ignoring wrong pointing object 220 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 230 0 (offset 0)\n",
      "Ignoring wrong pointing object 230 0 (offset 0)\n",
      "Ignoring wrong pointing object 230 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 232 0 (offset 0)\n",
      "Ignoring wrong pointing object 232 0 (offset 0)\n",
      "Ignoring wrong pointing object 232 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 234 0 (offset 0)\n",
      "Ignoring wrong pointing object 234 0 (offset 0)\n",
      "Ignoring wrong pointing object 234 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 242 0 (offset 0)\n",
      "Ignoring wrong pointing object 242 0 (offset 0)\n",
      "Ignoring wrong pointing object 242 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 244 0 (offset 0)\n",
      "Ignoring wrong pointing object 244 0 (offset 0)\n",
      "Ignoring wrong pointing object 244 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 246 0 (offset 0)\n",
      "Ignoring wrong pointing object 246 0 (offset 0)\n",
      "Ignoring wrong pointing object 246 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 248 0 (offset 0)\n",
      "Ignoring wrong pointing object 248 0 (offset 0)\n",
      "Ignoring wrong pointing object 248 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 250 0 (offset 0)\n",
      "Ignoring wrong pointing object 250 0 (offset 0)\n",
      "Ignoring wrong pointing object 250 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 256 0 (offset 0)\n",
      "Ignoring wrong pointing object 256 0 (offset 0)\n",
      "Ignoring wrong pointing object 256 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 258 0 (offset 0)\n",
      "Ignoring wrong pointing object 258 0 (offset 0)\n",
      "Ignoring wrong pointing object 258 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 260 0 (offset 0)\n",
      "Ignoring wrong pointing object 260 0 (offset 0)\n",
      "Ignoring wrong pointing object 260 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 262 0 (offset 0)\n",
      "Ignoring wrong pointing object 262 0 (offset 0)\n",
      "Ignoring wrong pointing object 262 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 277 0 (offset 0)\n",
      "Ignoring wrong pointing object 277 0 (offset 0)\n",
      "Ignoring wrong pointing object 277 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 287 0 (offset 0)\n",
      "Ignoring wrong pointing object 287 0 (offset 0)\n",
      "Ignoring wrong pointing object 287 0 (offset 0)\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Language  Models  for \n",
      "Information  Retrieval\n",
      "S...\n",
      "> Adding chunk: Language  Models  for \n",
      "Information  Retrieval\n",
      "S...\n",
      "> Adding chunk: Language  Models  for \n",
      "Information  Retrieval\n",
      "S...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 4\n",
      "What is a language model?\n",
      "“The goal of a lang...\n",
      "> Adding chunk: 4\n",
      "What is a language model?\n",
      "“The goal of a lang...\n",
      "> Adding chunk: 4\n",
      "What is a language model?\n",
      "“The goal of a lang...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 19\n",
      "What can we do with a probability \n",
      "distribut...\n",
      "> Adding chunk: 19\n",
      "What can we do with a probability \n",
      "distribut...\n",
      "> Adding chunk: 19\n",
      "What can we do with a probability \n",
      "distribut...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: • Defines a probability distribution over indiv...\n",
      "> Adding chunk: • Defines a probability distribution over indiv...\n",
      "> Adding chunk: • Defines a probability distribution over indiv...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: •\n",
      "•\n",
      "It is called a unigram language model becau...\n",
      "> Adding chunk: •\n",
      "•\n",
      "It is called a unigram language model becau...\n",
      "> Adding chunk: •\n",
      "•\n",
      "It is called a unigram language model becau...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: • Sequences of words can be assigned a probabil...\n",
      "> Adding chunk: • Sequences of words can be assigned a probabil...\n",
      "> Adding chunk: • Sequences of words can be assigned a probabil...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: • There are two important steps in language mod...\n",
      "> Adding chunk: • There are two important steps in language mod...\n",
      "> Adding chunk: • There are two important steps in language mod...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: •\n",
      "•\n",
      "Any span of text can be used to estimate a ...\n",
      "> Adding chunk: •\n",
      "•\n",
      "Any span of text can be used to estimate a ...\n",
      "> Adding chunk: •\n",
      "•\n",
      "Any span of text can be used to estimate a ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: • General estimation approach:\n",
      "‣\n",
      "‣\n",
      "‣\n",
      "‣ tokenize...\n",
      "> Adding chunk: • General estimation approach:\n",
      "‣\n",
      "‣\n",
      "‣\n",
      "‣ tokenize...\n",
      "> Adding chunk: • General estimation approach:\n",
      "‣\n",
      "‣\n",
      "‣\n",
      "‣ tokenize...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 29\n",
      "IMDB Corpus\n",
      "language model estimation (top 2...\n",
      "> Adding chunk: 29\n",
      "IMDB Corpus\n",
      "language model estimation (top 2...\n",
      "> Adding chunk: 29\n",
      "IMDB Corpus\n",
      "language model estimation (top 2...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 30\n",
      "term tf N P(term) term tf N P(term)\n",
      "the 1586...\n",
      "> Adding chunk: 30\n",
      "term tf N P(term) term tf N P(term)\n",
      "the 1586...\n",
      "> Adding chunk: 30\n",
      "term tf N P(term) term tf N P(term)\n",
      "the 1586...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 31\n",
      "term tf N P(term) term tf N P(term)\n",
      "the 1586...\n",
      "> Adding chunk: 31\n",
      "term tf N P(term) term tf N P(term)\n",
      "the 1586...\n",
      "> Adding chunk: 31\n",
      "term tf N P(term) term tf N P(term)\n",
      "the 1586...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 32\n",
      "term tf N P(term) term tf N P(term)\n",
      "the 1586...\n",
      "> Adding chunk: 32\n",
      "term tf N P(term) term tf N P(term)\n",
      "the 1586...\n",
      "> Adding chunk: 32\n",
      "term tf N P(term) term tf N P(term)\n",
      "the 1586...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 35\n",
      "Language Models\n",
      "•\n",
      "•\n",
      "A language model is a pr...\n",
      "> Adding chunk: 35\n",
      "Language Models\n",
      "•\n",
      "•\n",
      "A language model is a pr...\n",
      "> Adding chunk: 35\n",
      "Language Models\n",
      "•\n",
      "•\n",
      "A language model is a pr...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ...\n",
      "movies politics sports music nature\n",
      "P(RED) ...\n",
      "> Adding chunk: ...\n",
      "movies politics sports music nature\n",
      "P(RED) ...\n",
      "> Adding chunk: ...\n",
      "movies politics sports music nature\n",
      "P(RED) ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 37\n",
      "0\n",
      "0.15\n",
      "0.30\n",
      "0.45\n",
      "0.60\n",
      "actress cast movie par...\n",
      "> Adding chunk: 37\n",
      "0\n",
      "0.15\n",
      "0.30\n",
      "0.45\n",
      "0.60\n",
      "actress cast movie par...\n",
      "> Adding chunk: 37\n",
      "0\n",
      "0.15\n",
      "0.30\n",
      "0.45\n",
      "0.60\n",
      "actress cast movie par...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 38\n",
      "0\n",
      "0.15\n",
      "0.30\n",
      "0.45\n",
      "0.60\n",
      "actress cast movie par...\n",
      "> Adding chunk: 38\n",
      "0\n",
      "0.15\n",
      "0.30\n",
      "0.45\n",
      "0.60\n",
      "actress cast movie par...\n",
      "> Adding chunk: 38\n",
      "0\n",
      "0.15\n",
      "0.30\n",
      "0.45\n",
      "0.60\n",
      "actress cast movie par...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 39\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "Many factors affect whether a docu...\n",
      "> Adding chunk: 39\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "Many factors affect whether a docu...\n",
      "> Adding chunk: 39\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "Many factors affect whether a docu...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 40\n",
      "Document Language Models\n",
      "• The topic (or top...\n",
      "> Adding chunk: 40\n",
      "Document Language Models\n",
      "• The topic (or top...\n",
      "> Adding chunk: 40\n",
      "Document Language Models\n",
      "• The topic (or top...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 41\n",
      "Document Language Models\n",
      "• Estimating a docu...\n",
      "> Adding chunk: 41\n",
      "Document Language Models\n",
      "• Estimating a docu...\n",
      "> Adding chunk: 41\n",
      "Document Language Models\n",
      "• Estimating a docu...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 42\n",
      "Document Language Models\n",
      "•\n",
      "•\n",
      "P(t|D) = P(t|θD...\n",
      "> Adding chunk: 42\n",
      "Document Language Models\n",
      "•\n",
      "•\n",
      "P(t|D) = P(t|θD...\n",
      "> Adding chunk: 42\n",
      "Document Language Models\n",
      "•\n",
      "•\n",
      "P(t|D) = P(t|θD...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 43\n",
      "•\n",
      "•\n",
      "Movie: Rocky (1976) \n",
      "Plot:\n",
      "Rocky Balboa ...\n",
      "> Adding chunk: 43\n",
      "•\n",
      "•\n",
      "Movie: Rocky (1976) \n",
      "Plot:\n",
      "Rocky Balboa ...\n",
      "> Adding chunk: 43\n",
      "•\n",
      "•\n",
      "Movie: Rocky (1976) \n",
      "Plot:\n",
      "Rocky Balboa ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 44\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "> Adding chunk: 44\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "> Adding chunk: 44\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 45\n",
      "Document Language Models\n",
      "•\n",
      "•\n",
      "•\n",
      "Suppose we ha...\n",
      "> Adding chunk: 45\n",
      "Document Language Models\n",
      "•\n",
      "•\n",
      "•\n",
      "Suppose we ha...\n",
      "> Adding chunk: 45\n",
      "Document Language Models\n",
      "•\n",
      "•\n",
      "•\n",
      "Suppose we ha...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 46\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "> Adding chunk: 46\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "> Adding chunk: 46\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 47\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "> Adding chunk: 47\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "> Adding chunk: 47\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 48\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "> Adding chunk: 48\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "> Adding chunk: 48\n",
      "term tft,D ND P(term|D) term tft,D ND P(term...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 49\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "Object...\n",
      "> Adding chunk: 49\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "Object...\n",
      "> Adding chunk: 49\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "Object...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 50\n",
      "Query -Likelihood Retrieval Model\n",
      "• Every do...\n",
      "> Adding chunk: 50\n",
      "Query -Likelihood Retrieval Model\n",
      "• Every do...\n",
      "> Adding chunk: 50\n",
      "Query -Likelihood Retrieval Model\n",
      "• Every do...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 51\n",
      "Query -Likelihood Model\n",
      "back to our analogy\n",
      "...\n",
      "> Adding chunk: 51\n",
      "Query -Likelihood Model\n",
      "back to our analogy\n",
      "...\n",
      "> Adding chunk: 51\n",
      "Query -Likelihood Model\n",
      "back to our analogy\n",
      "...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 52\n",
      "Query -Likelihood Model\n",
      "back to our analogy\n",
      "...\n",
      "> Adding chunk: 52\n",
      "Query -Likelihood Model\n",
      "back to our analogy\n",
      "...\n",
      "> Adding chunk: 52\n",
      "Query -Likelihood Model\n",
      "back to our analogy\n",
      "...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 53\n",
      "Query -Likelihood Model\n",
      "back to our analogy\n",
      "...\n",
      "> Adding chunk: 53\n",
      "Query -Likelihood Model\n",
      "back to our analogy\n",
      "...\n",
      "> Adding chunk: 53\n",
      "Query -Likelihood Model\n",
      "back to our analogy\n",
      "...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: • Query =\n",
      "• Which would be the top-ranked docum...\n",
      "> Adding chunk: • Query =\n",
      "• Which would be the top-ranked docum...\n",
      "> Adding chunk: • Query =\n",
      "• Which would be the top-ranked docum...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: • Query =\n",
      "• Which would be the top-ranked docum...\n",
      "> Adding chunk: • Query =\n",
      "• Which would be the top-ranked docum...\n",
      "> Adding chunk: • Query =\n",
      "• Which would be the top-ranked docum...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Query -Likelihood Retrieval Model\n",
      "D1\n",
      "D5\n",
      "D4\n",
      "D3\n",
      "D...\n",
      "> Adding chunk: Query -Likelihood Retrieval Model\n",
      "D1\n",
      "D5\n",
      "D4\n",
      "D3\n",
      "D...\n",
      "> Adding chunk: Query -Likelihood Retrieval Model\n",
      "D1\n",
      "D5\n",
      "D4\n",
      "D3\n",
      "D...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 57\n",
      "Query -Likelihood Retrieval Model\n",
      "n\n",
      "score(Q,...\n",
      "> Adding chunk: 57\n",
      "Query -Likelihood Retrieval Model\n",
      "n\n",
      "score(Q,...\n",
      "> Adding chunk: 57\n",
      "Query -Likelihood Retrieval Model\n",
      "n\n",
      "score(Q,...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 58\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "Becaus...\n",
      "> Adding chunk: 58\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "Becaus...\n",
      "> Adding chunk: 58\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "Becaus...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 59\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "•\n",
      "Beca...\n",
      "> Adding chunk: 59\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "•\n",
      "Beca...\n",
      "> Adding chunk: 59\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "•\n",
      "Beca...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 60\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "n\n",
      "scor...\n",
      "> Adding chunk: 60\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "n\n",
      "scor...\n",
      "> Adding chunk: 60\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "n\n",
      "scor...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 61\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "A docu...\n",
      "> Adding chunk: 61\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "A docu...\n",
      "> Adding chunk: 61\n",
      "Query -Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "A docu...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "> Adding chunk: Outline\n",
      "Introduction to language modeling \n",
      "Lang...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 63\n",
      "• When estimating probabilities, we tend to ...\n",
      "> Adding chunk: 63\n",
      "• When estimating probabilities, we tend to ...\n",
      "> Adding chunk: 63\n",
      "• When estimating probabilities, we tend to ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 66\n",
      "P(RED) = 0.5\n",
      "P(BLUE) = 0.25\n",
      "P(ORANGE) = 0.25...\n",
      "> Adding chunk: 66\n",
      "P(RED) = 0.5\n",
      "P(BLUE) = 0.25\n",
      "P(ORANGE) = 0.25...\n",
      "> Adding chunk: 66\n",
      "P(RED) = 0.5\n",
      "P(BLUE) = 0.25\n",
      "P(ORANGE) = 0.25...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 67\n",
      "P(RED) = (10/20)  \n",
      "P(BLUE) = (5/20)  \n",
      "P(ORAN...\n",
      "> Adding chunk: 67\n",
      "P(RED) = (10/20)  \n",
      "P(BLUE) = (5/20)  \n",
      "P(ORAN...\n",
      "> Adding chunk: 67\n",
      "P(RED) = (10/20)  \n",
      "P(BLUE) = (5/20)  \n",
      "P(ORAN...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: P(RED) = (11/25)  \n",
      "P(BLUE) = (6/25)  \n",
      "P(ORANGE)...\n",
      "> Adding chunk: P(RED) = (11/25)  \n",
      "P(BLUE) = (6/25)  \n",
      "P(ORANGE)...\n",
      "> Adding chunk: P(RED) = (11/25)  \n",
      "P(BLUE) = (6/25)  \n",
      "P(ORANGE)...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: P(GREEN ) = (1/25) 69\n",
      "Add -One Smoothing\n",
      "• Give...\n",
      "> Adding chunk: P(GREEN ) = (1/25) 69\n",
      "Add -One Smoothing\n",
      "• Give...\n",
      "> Adding chunk: P(GREEN ) = (1/25) 69\n",
      "Add -One Smoothing\n",
      "• Give...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 70\n",
      "•\n",
      "•\n",
      "Movie: Rocky (1976) \n",
      "Plot:\n",
      "Rocky Balboa ...\n",
      "> Adding chunk: 70\n",
      "•\n",
      "•\n",
      "Movie: Rocky (1976) \n",
      "Plot:\n",
      "Rocky Balboa ...\n",
      "> Adding chunk: 70\n",
      "•\n",
      "•\n",
      "Movie: Rocky (1976) \n",
      "Plot:\n",
      "Rocky Balboa ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 71\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "Smoothing Probability Estimates\n",
      "fo...\n",
      "> Adding chunk: 71\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "Smoothing Probability Estimates\n",
      "fo...\n",
      "> Adding chunk: 71\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "Smoothing Probability Estimates\n",
      "fo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 72\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "In theory, we could use add-one smoo...\n",
      "> Adding chunk: 72\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "In theory, we could use add-one smoo...\n",
      "> Adding chunk: 72\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "In theory, we could use add-one smoo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 73\n",
      "Linear Interpolation Smoothing\n",
      "•\n",
      "•\n",
      "•\n",
      "Let θD ...\n",
      "> Adding chunk: 73\n",
      "Linear Interpolation Smoothing\n",
      "•\n",
      "•\n",
      "•\n",
      "Let θD ...\n",
      "> Adding chunk: 73\n",
      "Linear Interpolation Smoothing\n",
      "•\n",
      "•\n",
      "•\n",
      "Let θD ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 74\n",
      "Linear Interpolation Smoothing\n",
      "P(t|D) = αP(t...\n",
      "> Adding chunk: 74\n",
      "Linear Interpolation Smoothing\n",
      "P(t|D) = αP(t...\n",
      "> Adding chunk: 74\n",
      "Linear Interpolation Smoothing\n",
      "P(t|D) = αP(t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 75\n",
      "Linear Interpolation Smoothing\n",
      "P(t|D) = αP(t...\n",
      "> Adding chunk: 75\n",
      "Linear Interpolation Smoothing\n",
      "P(t|D) = αP(t...\n",
      "> Adding chunk: 75\n",
      "Linear Interpolation Smoothing\n",
      "P(t|D) = αP(t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: •\n",
      "•\n",
      "•\n",
      "As before, a document’s score is given by...\n",
      "> Adding chunk: •\n",
      "•\n",
      "•\n",
      "As before, a document’s score is given by...\n",
      "> Adding chunk: •\n",
      "•\n",
      "•\n",
      "As before, a document’s score is given by...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: •\n",
      "•\n",
      "•\n",
      "•\n",
      "Linear interpolation helps us avoid zer...\n",
      "> Adding chunk: •\n",
      "•\n",
      "•\n",
      "•\n",
      "Linear interpolation helps us avoid zer...\n",
      "> Adding chunk: •\n",
      "•\n",
      "•\n",
      "•\n",
      "Linear interpolation helps us avoid zer...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 78\n",
      "Query Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "no smoo...\n",
      "> Adding chunk: 78\n",
      "Query Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "no smoo...\n",
      "> Adding chunk: 78\n",
      "Query Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "no smoo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 79\n",
      "Query Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "no smoo...\n",
      "> Adding chunk: 79\n",
      "Query Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "no smoo...\n",
      "> Adding chunk: 79\n",
      "Query Likelihood Retrieval Model\n",
      "•\n",
      "•\n",
      "no smoo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 80\n",
      "Query Likelihood Retrieval Model\n",
      "no smoothin...\n",
      "> Adding chunk: 80\n",
      "Query Likelihood Retrieval Model\n",
      "no smoothin...\n",
      "> Adding chunk: 80\n",
      "Query Likelihood Retrieval Model\n",
      "no smoothin...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 81\n",
      "Query Likelihood Retrieval Model\n",
      "D1 (ND1=50)...\n",
      "> Adding chunk: 81\n",
      "Query Likelihood Retrieval Model\n",
      "D1 (ND1=50)...\n",
      "> Adding chunk: 81\n",
      "Query Likelihood Retrieval Model\n",
      "D1 (ND1=50)...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 82\n",
      "Query Likelihood Retrieval Model\n",
      "with linear...\n",
      "> Adding chunk: 82\n",
      "Query Likelihood Retrieval Model\n",
      "with linear...\n",
      "> Adding chunk: 82\n",
      "Query Likelihood Retrieval Model\n",
      "with linear...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 83\n",
      "Query Likelihood Retrieval Model\n",
      "D1 (ND1=50)...\n",
      "> Adding chunk: 83\n",
      "Query Likelihood Retrieval Model\n",
      "D1 (ND1=50)...\n",
      "> Adding chunk: 83\n",
      "Query Likelihood Retrieval Model\n",
      "D1 (ND1=50)...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 84\n",
      "Query Likelihood Retrieval Model\n",
      "with linear...\n",
      "> Adding chunk: 84\n",
      "Query Likelihood Retrieval Model\n",
      "with linear...\n",
      "> Adding chunk: 84\n",
      "Query Likelihood Retrieval Model\n",
      "with linear...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 85\n",
      "Query Likelihood Retrieval Model\n",
      "with linear...\n",
      "> Adding chunk: 85\n",
      "Query Likelihood Retrieval Model\n",
      "with linear...\n",
      "> Adding chunk: 85\n",
      "Query Likelihood Retrieval Model\n",
      "with linear...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Extend the unigram model to \n",
      "bigrams\n",
      "> Adding chunk: Extend the unigram model to \n",
      "bigrams\n",
      "> Adding chunk: Extend the unigram model to \n",
      "bigrams\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Parametric Language Modeling : Transformers\n",
      "> Adding chunk: Parametric Language Modeling : Transformers\n",
      "> Adding chunk: Parametric Language Modeling : Transformers\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Parametric Language Modeling•Can we do better t...\n",
      "> Adding chunk: Parametric Language Modeling•Can we do better t...\n",
      "> Adding chunk: Parametric Language Modeling•Can we do better t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Lecture Plan\n",
      "3\n",
      "1.From recurrence (RNN) to atten...\n",
      "> Adding chunk: Lecture Plan\n",
      "3\n",
      "1.From recurrence (RNN) to atten...\n",
      "> Adding chunk: Lecture Plan\n",
      "3\n",
      "1.From recurrence (RNN) to atten...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: As oflastweek:recurrent models for (most) NLP!•...\n",
      "> Adding chunk: As oflastweek:recurrent models for (most) NLP!•...\n",
      "> Adding chunk: As oflastweek:recurrent models for (most) NLP!•...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Issues with recurrent models: Linear interactio...\n",
      "> Adding chunk: Issues with recurrent models: Linear interactio...\n",
      "> Adding chunk: Issues with recurrent models: Linear interactio...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Issues with recurrent models: Linear interactio...\n",
      "> Adding chunk: Issues with recurrent models: Linear interactio...\n",
      "> Adding chunk: Issues with recurrent models: Linear interactio...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Issues with recurrent models: Lack of paralleli...\n",
      "> Adding chunk: Issues with recurrent models: Lack of paralleli...\n",
      "> Adding chunk: Issues with recurrent models: Lack of paralleli...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: If not recurrence, then what? How about attenti...\n",
      "> Adding chunk: If not recurrence, then what? How about attenti...\n",
      "> Adding chunk: If not recurrence, then what? How about attenti...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Self-Attention\n",
      "11\n",
      "> Adding chunk: Self-Attention\n",
      "11\n",
      "> Adding chunk: Self-Attention\n",
      "11\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Self-attention as an NLP building block\n",
      "𝑤1The\n",
      "𝑞...\n",
      "> Adding chunk: Self-attention as an NLP building block\n",
      "𝑤1The\n",
      "𝑞...\n",
      "> Adding chunk: Self-attention as an NLP building block\n",
      "𝑤1The\n",
      "𝑞...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Fixing the first self-attention problem: sequen...\n",
      "> Adding chunk: Fixing the first self-attention problem: sequen...\n",
      "> Adding chunk: Fixing the first self-attention problem: sequen...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: •Pros:•Periodicity indicates that maybe “absolu...\n",
      "> Adding chunk: •Pros:•Periodicity indicates that maybe “absolu...\n",
      "> Adding chunk: •Pros:•Periodicity indicates that maybe “absolu...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: •Learned absolute position representations: Let...\n",
      "> Adding chunk: •Learned absolute position representations: Let...\n",
      "> Adding chunk: •Learned absolute position representations: Let...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Adding nonlinearities in self-attention•Note th...\n",
      "> Adding chunk: Adding nonlinearities in self-attention•Note th...\n",
      "> Adding chunk: Adding nonlinearities in self-attention•Note th...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Masking the future in self-attention•To use sel...\n",
      "> Adding chunk: Masking the future in self-attention•To use sel...\n",
      "> Adding chunk: Masking the future in self-attention•To use sel...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Masking the future in self-attention•To use sel...\n",
      "> Adding chunk: Masking the future in self-attention•To use sel...\n",
      "> Adding chunk: Masking the future in self-attention•To use sel...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "> Adding chunk: Barriers•Doesn’t have an inherentnotion of orde...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: •Self-attention:•the basis of the method.•Posit...\n",
      "> Adding chunk: •Self-attention:•the basis of the method.•Posit...\n",
      "> Adding chunk: •Self-attention:•the basis of the method.•Posit...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Outline\n",
      "22\n",
      "1.From recurrence (RNN) to attention...\n",
      "> Adding chunk: Outline\n",
      "22\n",
      "1.From recurrence (RNN) to attention...\n",
      "> Adding chunk: Outline\n",
      "22\n",
      "1.From recurrence (RNN) to attention...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder: Key-Query-Value Attent...\n",
      "> Adding chunk: The Transformer Encoder: Key-Query-Value Attent...\n",
      "> Adding chunk: The Transformer Encoder: Key-Query-Value Attent...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder: Key-Query-Value Attent...\n",
      "> Adding chunk: The Transformer Encoder: Key-Query-Value Attent...\n",
      "> Adding chunk: The Transformer Encoder: Key-Query-Value Attent...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder: Multi-headed attention...\n",
      "> Adding chunk: The Transformer Encoder: Multi-headed attention...\n",
      "> Adding chunk: The Transformer Encoder: Multi-headed attention...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder: Multi-headed attention...\n",
      "> Adding chunk: The Transformer Encoder: Multi-headed attention...\n",
      "> Adding chunk: The Transformer Encoder: Multi-headed attention...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder: Residual connections [...\n",
      "> Adding chunk: The Transformer Encoder: Residual connections [...\n",
      "> Adding chunk: The Transformer Encoder: Residual connections [...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder: Layer normalization [B...\n",
      "> Adding chunk: The Transformer Encoder: Layer normalization [B...\n",
      "> Adding chunk: The Transformer Encoder: Layer normalization [B...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder: Layer normalization [B...\n",
      "> Adding chunk: The Transformer Encoder: Layer normalization [B...\n",
      "> Adding chunk: The Transformer Encoder: Layer normalization [B...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder: Scaled Dot Product [Va...\n",
      "> Adding chunk: The Transformer Encoder: Scaled Dot Product [Va...\n",
      "> Adding chunk: The Transformer Encoder: Scaled Dot Product [Va...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "> Adding chunk: The Transformer Encoder-Decoder [Vaswani et al....\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Decoder: Cross-attention (detai...\n",
      "> Adding chunk: The Transformer Decoder: Cross-attention (detai...\n",
      "> Adding chunk: The Transformer Decoder: Cross-attention (detai...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The Transformer Encoder: Cross-attention (detai...\n",
      "> Adding chunk: The Transformer Encoder: Cross-attention (detai...\n",
      "> Adding chunk: The Transformer Encoder: Cross-attention (detai...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Outline\n",
      "39\n",
      "1.From recurrence (RNN) to attention...\n",
      "> Adding chunk: Outline\n",
      "39\n",
      "1.From recurrence (RNN) to attention...\n",
      "> Adding chunk: Outline\n",
      "39\n",
      "1.From recurrence (RNN) to attention...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Great Results with Transformers\n",
      "Not just better...\n",
      "> Adding chunk: Great Results with Transformers\n",
      "Not just better...\n",
      "> Adding chunk: Great Results with Transformers\n",
      "Not just better...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Great Results with Transformers\n",
      "Transformers al...\n",
      "> Adding chunk: Great Results with Transformers\n",
      "Transformers al...\n",
      "> Adding chunk: Great Results with Transformers\n",
      "Transformers al...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Great Results with Transformers\n",
      "[Liu et al., 20...\n",
      "> Adding chunk: Great Results with Transformers\n",
      "[Liu et al., 20...\n",
      "> Adding chunk: Great Results with Transformers\n",
      "[Liu et al., 20...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Information Retrieval \n",
      "and Web Search\n",
      "IR Evalua...\n",
      "> Adding chunk: Information Retrieval \n",
      "and Web Search\n",
      "IR Evalua...\n",
      "> Adding chunk: Information Retrieval \n",
      "and Web Search\n",
      "IR Evalua...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: IR Evaluation Measures\n",
      "1) How fast does it inde...\n",
      "> Adding chunk: IR Evaluation Measures\n",
      "1) How fast does it inde...\n",
      "> Adding chunk: IR Evaluation Measures\n",
      "1) How fast does it inde...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: User Happiness\n",
      "• Who is the user we are trying ...\n",
      "> Adding chunk: User Happiness\n",
      "• Who is the user we are trying ...\n",
      "> Adding chunk: User Happiness\n",
      "• Who is the user we are trying ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Relevance as Proxy for User Happiness\n",
      "• User ha...\n",
      "> Adding chunk: Relevance as Proxy for User Happiness\n",
      "• User ha...\n",
      "> Adding chunk: Relevance as Proxy for User Happiness\n",
      "• User ha...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Standard Methodology for Measuring \n",
      "Relevance i...\n",
      "> Adding chunk: Standard Methodology for Measuring \n",
      "Relevance i...\n",
      "> Adding chunk: Standard Methodology for Measuring \n",
      "Relevance i...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Why System Evaluations?\n",
      "• Is a retrieval system...\n",
      "> Adding chunk: Why System Evaluations?\n",
      "• Is a retrieval system...\n",
      "> Adding chunk: Why System Evaluations?\n",
      "• Is a retrieval system...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: documents relevant of number Total\n",
      "retrieved do...\n",
      "> Adding chunk: documents relevant of number Total\n",
      "retrieved do...\n",
      "> Adding chunk: documents relevant of number Total\n",
      "retrieved do...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Precision and Recall\n",
      "• Precision vs. Recall:\n",
      "– ...\n",
      "> Adding chunk: Precision and Recall\n",
      "• Precision vs. Recall:\n",
      "– ...\n",
      "> Adding chunk: Precision and Recall\n",
      "• Precision vs. Recall:\n",
      "– ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Trade-off between Recall and Precision\n",
      "10\n",
      "1\n",
      "Rec...\n",
      "> Adding chunk: Trade-off between Recall and Precision\n",
      "10\n",
      "1\n",
      "Rec...\n",
      "> Adding chunk: Trade-off between Recall and Precision\n",
      "10\n",
      "1\n",
      "Rec...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: F-measure\n",
      "• One measure of performance that tak...\n",
      "> Adding chunk: F-measure\n",
      "• One measure of performance that tak...\n",
      "> Adding chunk: F-measure\n",
      "• One measure of performance that tak...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Ranked Retrieval Measures\n",
      "• Binary relevance:\n",
      "–...\n",
      "> Adding chunk: Ranked Retrieval Measures\n",
      "• Binary relevance:\n",
      "–...\n",
      "> Adding chunk: Ranked Retrieval Measures\n",
      "• Binary relevance:\n",
      "–...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: R=3/6=0.5;     P=3/4=0.75\n",
      "Recall-Precision Curv...\n",
      "> Adding chunk: R=3/6=0.5;     P=3/4=0.75\n",
      "Recall-Precision Curv...\n",
      "> Adding chunk: R=3/6=0.5;     P=3/4=0.75\n",
      "Recall-Precision Curv...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Interpolating a \n",
      "Recall/Precision Curve\n",
      "• Inter...\n",
      "> Adding chunk: Interpolating a \n",
      "Recall/Precision Curve\n",
      "• Inter...\n",
      "> Adding chunk: Interpolating a \n",
      "Recall/Precision Curve\n",
      "• Inter...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Interpolating a Recall/Precision Curve\n",
      "Rational...\n",
      "> Adding chunk: Interpolating a Recall/Precision Curve\n",
      "Rational...\n",
      "> Adding chunk: Interpolating a Recall/Precision Curve\n",
      "Rational...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Interpolating a Recall/Precision Curve\n",
      "• Comput...\n",
      "> Adding chunk: Interpolating a Recall/Precision Curve\n",
      "• Comput...\n",
      "> Adding chunk: Interpolating a Recall/Precision Curve\n",
      "• Comput...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Worked Example avg-11-pt prec: Query 1, \n",
      "measur...\n",
      "> Adding chunk: Worked Example avg-11-pt prec: Query 1, \n",
      "measur...\n",
      "> Adding chunk: Worked Example avg-11-pt prec: Query 1, \n",
      "measur...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Worked Example avg-11-pt prec: Query 1, \n",
      "measur...\n",
      "> Adding chunk: Worked Example avg-11-pt prec: Query 1, \n",
      "measur...\n",
      "> Adding chunk: Worked Example avg-11-pt prec: Query 1, \n",
      "measur...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Worked Example avg-11-pt prec: Query 2, \n",
      "measur...\n",
      "> Adding chunk: Worked Example avg-11-pt prec: Query 2, \n",
      "measur...\n",
      "> Adding chunk: Worked Example avg-11-pt prec: Query 2, \n",
      "measur...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Worked Example avg-11-pt prec: Query 2, \n",
      "interp...\n",
      "> Adding chunk: Worked Example avg-11-pt prec: Query 2, \n",
      "interp...\n",
      "> Adding chunk: Worked Example avg-11-pt prec: Query 2, \n",
      "interp...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Worked Example avg-11-pt prec: averaging\n",
      "> Adding chunk: Worked Example avg-11-pt prec: averaging\n",
      "> Adding chunk: Worked Example avg-11-pt prec: averaging\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Worked Example avg-11-pt prec: area/result\n",
      "> Adding chunk: Worked Example avg-11-pt prec: area/result\n",
      "> Adding chunk: Worked Example avg-11-pt prec: area/result\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Accuracy\n",
      "• Why do we use complex measures like ...\n",
      "> Adding chunk: Accuracy\n",
      "• Why do we use complex measures like ...\n",
      "> Adding chunk: Accuracy\n",
      "• Why do we use complex measures like ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Accuracy\n",
      "• Simple trick to maximize accuracy in...\n",
      "> Adding chunk: Accuracy\n",
      "• Simple trick to maximize accuracy in...\n",
      "> Adding chunk: Accuracy\n",
      "• Simple trick to maximize accuracy in...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Recall-criticality and precision-criticality\n",
      "• ...\n",
      "> Adding chunk: Recall-criticality and precision-criticality\n",
      "• ...\n",
      "> Adding chunk: Recall-criticality and precision-criticality\n",
      "• ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Recall-criticality and precision-criticality\n",
      "> Adding chunk: Recall-criticality and precision-criticality\n",
      "> Adding chunk: Recall-criticality and precision-criticality\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Average Recall/Precision Curve\n",
      "• Typically aver...\n",
      "> Adding chunk: Average Recall/Precision Curve\n",
      "• Typically aver...\n",
      "> Adding chunk: Average Recall/Precision Curve\n",
      "• Typically aver...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: How To Compare \n",
      "Two or More Systems\n",
      "• The curve...\n",
      "> Adding chunk: How To Compare \n",
      "Two or More Systems\n",
      "• The curve...\n",
      "> Adding chunk: How To Compare \n",
      "Two or More Systems\n",
      "• The curve...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: R-precision\n",
      "• Precision at the R-th position in...\n",
      "> Adding chunk: R-precision\n",
      "• Precision at the R-th position in...\n",
      "> Adding chunk: R-precision\n",
      "• Precision at the R-th position in...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: R-precision\n",
      "• Precision at the R-th position in...\n",
      "> Adding chunk: R-precision\n",
      "• Precision at the R-th position in...\n",
      "> Adding chunk: R-precision\n",
      "• Precision at the R-th position in...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Precision@K\n",
      "1. Set a rank threshold K.\n",
      "2. Compu...\n",
      "> Adding chunk: Precision@K\n",
      "1. Set a rank threshold K.\n",
      "2. Compu...\n",
      "> Adding chunk: Precision@K\n",
      "1. Set a rank threshold K.\n",
      "2. Compu...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Mean Average Precision (MAP)\n",
      "1. Consider rank p...\n",
      "> Adding chunk: Mean Average Precision (MAP)\n",
      "1. Consider rank p...\n",
      "> Adding chunk: Mean Average Precision (MAP)\n",
      "1. Consider rank p...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Exercise: Average Precision\n",
      "Assume a query with...\n",
      "> Adding chunk: Exercise: Average Precision\n",
      "Assume a query with...\n",
      "> Adding chunk: Exercise: Average Precision\n",
      "Assume a query with...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Mean Average Precision (MAP)\n",
      "Average precision ...\n",
      "> Adding chunk: Mean Average Precision (MAP)\n",
      "Average precision ...\n",
      "> Adding chunk: Mean Average Precision (MAP)\n",
      "Average precision ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Mean Average Precision (MAP)\n",
      "• If a relevant do...\n",
      "> Adding chunk: Mean Average Precision (MAP)\n",
      "• If a relevant do...\n",
      "> Adding chunk: Mean Average Precision (MAP)\n",
      "• If a relevant do...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Mean Reciprocal Rank\n",
      "• Consider rank position, ...\n",
      "> Adding chunk: Mean Reciprocal Rank\n",
      "• Consider rank position, ...\n",
      "> Adding chunk: Mean Reciprocal Rank\n",
      "• Consider rank position, ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Multiple Levels of Relevance\n",
      "• Documents are ra...\n",
      "> Adding chunk: Multiple Levels of Relevance\n",
      "• Documents are ra...\n",
      "> Adding chunk: Multiple Levels of Relevance\n",
      "• Documents are ra...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Cummulative Gain\n",
      "• With graded relevance \n",
      "judgm...\n",
      "> Adding chunk: Cummulative Gain\n",
      "• With graded relevance \n",
      "judgm...\n",
      "> Adding chunk: Cummulative Gain\n",
      "• With graded relevance \n",
      "judgm...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Discounted Cumulative Gain\n",
      "• Users care more ab...\n",
      "> Adding chunk: Discounted Cumulative Gain\n",
      "• Users care more ab...\n",
      "> Adding chunk: Discounted Cumulative Gain\n",
      "• Users care more ab...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Normalized Discounted \n",
      "Cumulative Gain (NDCG)\n",
      "•...\n",
      "> Adding chunk: Normalized Discounted \n",
      "Cumulative Gain (NDCG)\n",
      "•...\n",
      "> Adding chunk: Normalized Discounted \n",
      "Cumulative Gain (NDCG)\n",
      "•...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Normalized Discounted \n",
      "Cumulative Gain (NDCG)\n",
      "•...\n",
      "> Adding chunk: Normalized Discounted \n",
      "Cumulative Gain (NDCG)\n",
      "•...\n",
      "> Adding chunk: Normalized Discounted \n",
      "Cumulative Gain (NDCG)\n",
      "•...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Evaluation with Clickthrough Data\n",
      "# of clicks r...\n",
      "> Adding chunk: Evaluation with Clickthrough Data\n",
      "# of clicks r...\n",
      "> Adding chunk: Evaluation with Clickthrough Data\n",
      "# of clicks r...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Pairwise Relative Ratings\n",
      "• Pairs of the form: ...\n",
      "> Adding chunk: Pairwise Relative Ratings\n",
      "• Pairs of the form: ...\n",
      "> Adding chunk: Pairwise Relative Ratings\n",
      "• Pairs of the form: ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Comparing two rankings to a baseline \n",
      "ranking\n",
      "•...\n",
      "> Adding chunk: Comparing two rankings to a baseline \n",
      "ranking\n",
      "•...\n",
      "> Adding chunk: Comparing two rankings to a baseline \n",
      "ranking\n",
      "•...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Kendall-tau Distance to Compare Rankings\n",
      "• Gene...\n",
      "> Adding chunk: Kendall-tau Distance to Compare Rankings\n",
      "• Gene...\n",
      "> Adding chunk: Kendall-tau Distance to Compare Rankings\n",
      "• Gene...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Exercise\n",
      "• Assume perfect ranking P = (1, 2, 3,...\n",
      "> Adding chunk: Exercise\n",
      "• Assume perfect ranking P = (1, 2, 3,...\n",
      "> Adding chunk: Exercise\n",
      "• Assume perfect ranking P = (1, 2, 3,...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: A/B Testing at Web Search Engines \n",
      "• Can exploi...\n",
      "> Adding chunk: A/B Testing at Web Search Engines \n",
      "• Can exploi...\n",
      "> Adding chunk: A/B Testing at Web Search Engines \n",
      "• Can exploi...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Amazon Mechanical Turk Testing\n",
      "• https://reques...\n",
      "> Adding chunk: Amazon Mechanical Turk Testing\n",
      "• https://reques...\n",
      "> Adding chunk: Amazon Mechanical Turk Testing\n",
      "• https://reques...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Standard Methodology for Measuring \n",
      "Relevance i...\n",
      "> Adding chunk: Standard Methodology for Measuring \n",
      "Relevance i...\n",
      "> Adding chunk: Standard Methodology for Measuring \n",
      "Relevance i...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Early Test Collections\n",
      "• Previous experiments w...\n",
      "> Adding chunk: Early Test Collections\n",
      "• Previous experiments w...\n",
      "> Adding chunk: Early Test Collections\n",
      "• Previous experiments w...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The TREC Benchmark\n",
      "• TREC: Text REtrieval Confe...\n",
      "> Adding chunk: The TREC Benchmark\n",
      "• TREC: Text REtrieval Confe...\n",
      "> Adding chunk: The TREC Benchmark\n",
      "• TREC: Text REtrieval Confe...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: TREC Objectives\n",
      "• Provide a common ground for c...\n",
      "> Adding chunk: TREC Objectives\n",
      "• Provide a common ground for c...\n",
      "> Adding chunk: TREC Objectives\n",
      "• Provide a common ground for c...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: TREC Advantages\n",
      "• Large scale (compared to a fe...\n",
      "> Adding chunk: TREC Advantages\n",
      "• Large scale (compared to a fe...\n",
      "> Adding chunk: TREC Advantages\n",
      "• Large scale (compared to a fe...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: TREC Tasks\n",
      "• Ad hoc: New questions are being as...\n",
      "> Adding chunk: TREC Tasks\n",
      "• Ad hoc: New questions are being as...\n",
      "> Adding chunk: TREC Tasks\n",
      "• Ad hoc: New questions are being as...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The TREC Collection\n",
      "• Both long and short docum...\n",
      "> Adding chunk: The TREC Collection\n",
      "• Both long and short docum...\n",
      "> Adding chunk: The TREC Collection\n",
      "• Both long and short docum...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Sample SGML Document\n",
      "<DOC> \n",
      "<DOCNO> WSJ870324-0...\n",
      "> Adding chunk: Sample SGML Document\n",
      "<DOC> \n",
      "<DOCNO> WSJ870324-0...\n",
      "> Adding chunk: Sample SGML Document\n",
      "<DOC> \n",
      "<DOCNO> WSJ870324-0...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Sample SGML Query\n",
      "<top> \n",
      "<head> Tipster Topic D...\n",
      "> Adding chunk: Sample SGML Query\n",
      "<top> \n",
      "<head> Tipster Topic D...\n",
      "> Adding chunk: Sample SGML Query\n",
      "<top> \n",
      "<head> Tipster Topic D...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: INFORMATION RETRIEVAL \n",
      "Soujanya Poria\n",
      "> Adding chunk: INFORMATION RETRIEVAL \n",
      "Soujanya Poria\n",
      "> Adding chunk: INFORMATION RETRIEVAL \n",
      "Soujanya Poria\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Syllabus•Week 1 – Introduction to IR, Boolean a...\n",
      "> Adding chunk: Syllabus•Week 1 – Introduction to IR, Boolean a...\n",
      "> Adding chunk: Syllabus•Week 1 – Introduction to IR, Boolean a...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Syllabus•Week 10 – Learning to Rank•Week 11 – L...\n",
      "> Adding chunk: Syllabus•Week 10 – Learning to Rank•Week 11 – L...\n",
      "> Adding chunk: Syllabus•Week 10 – Learning to Rank•Week 11 – L...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Words of Wisdom!•I have just crossed my 30 \n",
      "😁 –...\n",
      "> Adding chunk: Words of Wisdom!•I have just crossed my 30 \n",
      "😁 –...\n",
      "> Adding chunk: Words of Wisdom!•I have just crossed my 30 \n",
      "😁 –...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: What can you expect in this course?•You use Goo...\n",
      "> Adding chunk: What can you expect in this course?•You use Goo...\n",
      "> Adding chunk: What can you expect in this course?•You use Goo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Book to readhttp://nlp.stanford.edu/IR-book/pdf...\n",
      "> Adding chunk: Book to readhttp://nlp.stanford.edu/IR-book/pdf...\n",
      "> Adding chunk: Book to readhttp://nlp.stanford.edu/IR-book/pdf...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: INFORMATION RETRIEVAL Boolean retrieval\n",
      "> Adding chunk: INFORMATION RETRIEVAL Boolean retrieval\n",
      "> Adding chunk: INFORMATION RETRIEVAL Boolean retrieval\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Typical IR task•Input:–A large collection of un...\n",
      "> Adding chunk: Typical IR task•Input:–A large collection of un...\n",
      "> Adding chunk: Typical IR task•Input:–A large collection of un...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Generative IR task•Input:–A large collection of...\n",
      "> Adding chunk: Generative IR task•Input:–A large collection of...\n",
      "> Adding chunk: Generative IR task•Input:–A large collection of...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Boolean  Typical IR task•Input:–A large collect...\n",
      "> Adding chunk: Boolean  Typical IR task•Input:–A large collect...\n",
      "> Adding chunk: Boolean  Typical IR task•Input:–A large collect...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Boolean retrieval•Information Need: Which plays...\n",
      "> Adding chunk: Boolean retrieval•Information Need: Which plays...\n",
      "> Adding chunk: Boolean retrieval•Information Need: Which plays...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Term-document incidence matrices\n",
      "Antony and Cle...\n",
      "> Adding chunk: Term-document incidence matrices\n",
      "Antony and Cle...\n",
      "> Adding chunk: Term-document incidence matrices\n",
      "Antony and Cle...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Term-document incidence matrix M\n",
      "Brutus AND Cae...\n",
      "> Adding chunk: Term-document incidence matrix M\n",
      "Brutus AND Cae...\n",
      "> Adding chunk: Term-document incidence matrix M\n",
      "Brutus AND Cae...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Answers to Query•Antony and Cleopatra, Act III,...\n",
      "> Adding chunk: Answers to Query•Antony and Cleopatra, Act III,...\n",
      "> Adding chunk: Answers to Query•Antony and Cleopatra, Act III,...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Scalability: Dense Format•Assume:–Corpus has 1 ...\n",
      "> Adding chunk: Scalability: Dense Format•Assume:–Corpus has 1 ...\n",
      "> Adding chunk: Scalability: Dense Format•Assume:–Corpus has 1 ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Scalability: Sparse Format•Of the 500 billion e...\n",
      "> Adding chunk: Scalability: Sparse Format•Of the 500 billion e...\n",
      "> Adding chunk: Scalability: Sparse Format•Of the 500 billion e...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Inverted Index for Boolean Retrieval\n",
      "•Map each ...\n",
      "> Adding chunk: Inverted Index for Boolean Retrieval\n",
      "•Map each ...\n",
      "> Adding chunk: Inverted Index for Boolean Retrieval\n",
      "•Map each ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Inverted Index: Step 1•Assemble sequence of áto...\n",
      "> Adding chunk: Inverted Index: Step 1•Assemble sequence of áto...\n",
      "> Adding chunk: Inverted Index: Step 1•Assemble sequence of áto...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Inverted Index: Step 2•Sort by terms, then by d...\n",
      "> Adding chunk: Inverted Index: Step 2•Sort by terms, then by d...\n",
      "> Adding chunk: Inverted Index: Step 2•Sort by terms, then by d...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Inverted Index: Step 3•Merge multiple term entr...\n",
      "> Adding chunk: Inverted Index: Step 3•Merge multiple term entr...\n",
      "> Adding chunk: Inverted Index: Step 3•Merge multiple term entr...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Inverted Index: Step 3\n",
      "> Adding chunk: Inverted Index: Step 3\n",
      "> Adding chunk: Inverted Index: Step 3\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Query Processing: AND•Consider processing the q...\n",
      "> Adding chunk: Query Processing: AND•Consider processing the q...\n",
      "> Adding chunk: Query Processing: AND•Consider processing the q...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Query Processing: AND\n",
      "Merge Algorithm\n",
      "> Adding chunk: Query Processing: AND\n",
      "Merge Algorithm\n",
      "> Adding chunk: Query Processing: AND\n",
      "Merge Algorithm\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Query Processing: OR•Exercise: Adapt the merge ...\n",
      "> Adding chunk: Query Processing: OR•Exercise: Adapt the merge ...\n",
      "> Adding chunk: Query Processing: OR•Exercise: Adapt the merge ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Query Optimization:What is the best order for q...\n",
      "> Adding chunk: Query Optimization:What is the best order for q...\n",
      "> Adding chunk: Query Optimization:What is the best order for q...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Query Optimization•Exercise: recommend a query ...\n",
      "> Adding chunk: Query Optimization•Exercise: recommend a query ...\n",
      "> Adding chunk: Query Optimization•Exercise: recommend a query ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: INFORMATION RETRIEVAL IR models: Vector Space M...\n",
      "> Adding chunk: INFORMATION RETRIEVAL IR models: Vector Space M...\n",
      "> Adding chunk: INFORMATION RETRIEVAL IR models: Vector Space M...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Information Retrieval \n",
      "and Web SearchIR models:...\n",
      "> Adding chunk: Information Retrieval \n",
      "and Web SearchIR models:...\n",
      "> Adding chunk: Information Retrieval \n",
      "and Web SearchIR models:...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Ranked Retrieval•Thus far, our queries have all...\n",
      "> Adding chunk: Ranked Retrieval•Thus far, our queries have all...\n",
      "> Adding chunk: Ranked Retrieval•Thus far, our queries have all...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Problem with Boolean Search•Boolean queries oft...\n",
      "> Adding chunk: Problem with Boolean Search•Boolean queries oft...\n",
      "> Adding chunk: Problem with Boolean Search•Boolean queries oft...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Ranked Retrieval Models•Rather than a set of do...\n",
      "> Adding chunk: Ranked Retrieval Models•Rather than a set of do...\n",
      "> Adding chunk: Ranked Retrieval Models•Rather than a set of do...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Not a Problem in Ranked Retrieval•When a system...\n",
      "> Adding chunk: Not a Problem in Ranked Retrieval•When a system...\n",
      "> Adding chunk: Not a Problem in Ranked Retrieval•When a system...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Scoring as the Basis of Ranked Retrieval•We wis...\n",
      "> Adding chunk: Scoring as the Basis of Ranked Retrieval•We wis...\n",
      "> Adding chunk: Scoring as the Basis of Ranked Retrieval•We wis...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Query-document Matching Scores•We need a way of...\n",
      "> Adding chunk: Query-document Matching Scores•We need a way of...\n",
      "> Adding chunk: Query-document Matching Scores•We need a way of...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Take 1: Jaccard coefficient•Jaccard: A commonly...\n",
      "> Adding chunk: Take 1: Jaccard coefficient•Jaccard: A commonly...\n",
      "> Adding chunk: Take 1: Jaccard coefficient•Jaccard: A commonly...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Jaccard Coefficient: Scoring ExampleAssume the ...\n",
      "> Adding chunk: Jaccard Coefficient: Scoring ExampleAssume the ...\n",
      "> Adding chunk: Jaccard Coefficient: Scoring ExampleAssume the ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Issues with Jaccard for Scoring•It does not con...\n",
      "> Adding chunk: Issues with Jaccard for Scoring•It does not con...\n",
      "> Adding chunk: Issues with Jaccard for Scoring•It does not con...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Recall (from Boolean Retrieval): Binary Term-Do...\n",
      "> Adding chunk: Recall (from Boolean Retrieval): Binary Term-Do...\n",
      "> Adding chunk: Recall (from Boolean Retrieval): Binary Term-Do...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Term-document Count Matrices•Consider the numbe...\n",
      "> Adding chunk: Term-document Count Matrices•Consider the numbe...\n",
      "> Adding chunk: Term-document Count Matrices•Consider the numbe...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Vector-Space Model•t distinct terms remain afte...\n",
      "> Adding chunk: Vector-Space Model•t distinct terms remain afte...\n",
      "> Adding chunk: Vector-Space Model•t distinct terms remain afte...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Vector-Space ModelQuery as vector:•We regard qu...\n",
      "> Adding chunk: Vector-Space ModelQuery as vector:•We regard qu...\n",
      "> Adding chunk: Vector-Space ModelQuery as vector:•We regard qu...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Graphic RepresentationExample:D1 = 2T1 + 3T2 + ...\n",
      "> Adding chunk: Graphic RepresentationExample:D1 = 2T1 + 3T2 + ...\n",
      "> Adding chunk: Graphic RepresentationExample:D1 = 2T1 + 3T2 + ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Document Collection Representation•A collection...\n",
      "> Adding chunk: Document Collection Representation•A collection...\n",
      "> Adding chunk: Document Collection Representation•A collection...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Term Frequency tf•The term frequency tft,d of t...\n",
      "> Adding chunk: Term Frequency tf•The term frequency tft,d of t...\n",
      "> Adding chunk: Term Frequency tf•The term frequency tft,d of t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Term Frequency tf•Raw term frequency is not wha...\n",
      "> Adding chunk: Term Frequency tf•Raw term frequency is not wha...\n",
      "> Adding chunk: Term Frequency tf•Raw term frequency is not wha...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Document Frequency•Rare terms are more informat...\n",
      "> Adding chunk: Document Frequency•Rare terms are more informat...\n",
      "> Adding chunk: Document Frequency•Rare terms are more informat...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Document Frequency (continued)•Frequent terms a...\n",
      "> Adding chunk: Document Frequency (continued)•Frequent terms a...\n",
      "> Adding chunk: Document Frequency (continued)•Frequent terms a...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Idf Weight•dft is the document frequency of t: ...\n",
      "> Adding chunk: Idf Weight•dft is the document frequency of t: ...\n",
      "> Adding chunk: Idf Weight•dft is the document frequency of t: ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: idf example, suppose N = 1 millionterm dft idft...\n",
      "> Adding chunk: idf example, suppose N = 1 millionterm dft idft...\n",
      "> Adding chunk: idf example, suppose N = 1 millionterm dft idft...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Collection vs. Document Frequency•The collectio...\n",
      "> Adding chunk: Collection vs. Document Frequency•The collectio...\n",
      "> Adding chunk: Collection vs. Document Frequency•The collectio...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: tf-idf Weighting•The tf-idf weight of a term is...\n",
      "> Adding chunk: tf-idf Weighting•The tf-idf weight of a term is...\n",
      "> Adding chunk: tf-idf Weighting•The tf-idf weight of a term is...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Computing tf-idf: An ExampleGiven a document co...\n",
      "> Adding chunk: Computing tf-idf: An ExampleGiven a document co...\n",
      "> Adding chunk: Computing tf-idf: An ExampleGiven a document co...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Binary → Count → Weight matrixAntony and Cleopa...\n",
      "> Adding chunk: Binary → Count → Weight matrixAntony and Cleopa...\n",
      "> Adding chunk: Binary → Count → Weight matrixAntony and Cleopa...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Documents as Vectors•So we have a |V|-dimension...\n",
      "> Adding chunk: Documents as Vectors•So we have a |V|-dimension...\n",
      "> Adding chunk: Documents as Vectors•So we have a |V|-dimension...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Query as Vector•Query vector is typically treat...\n",
      "> Adding chunk: Query as Vector•Query vector is typically treat...\n",
      "> Adding chunk: Query as Vector•Query vector is typically treat...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Similarity Measure•We now have vectors for all ...\n",
      "> Adding chunk: Similarity Measure•We now have vectors for all ...\n",
      "> Adding chunk: Similarity Measure•We now have vectors for all ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: First Cut: Euclidean Distance•Distance between ...\n",
      "> Adding chunk: First Cut: Euclidean Distance•Distance between ...\n",
      "> Adding chunk: First Cut: Euclidean Distance•Distance between ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Second Cut: Manhattan Distance•Or “city block” ...\n",
      "> Adding chunk: Second Cut: Manhattan Distance•Or “city block” ...\n",
      "> Adding chunk: Second Cut: Manhattan Distance•Or “city block” ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Third Cut: Inner Product•Similarity between vec...\n",
      "> Adding chunk: Third Cut: Inner Product•Similarity between vec...\n",
      "> Adding chunk: Third Cut: Inner Product•Similarity between vec...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Properties of Inner Product•Favors long documen...\n",
      "> Adding chunk: Properties of Inner Product•Favors long documen...\n",
      "> Adding chunk: Properties of Inner Product•Favors long documen...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: InnerProductExercise k1 k2 k3 q • dj \n",
      "d1 1 0 1 ...\n",
      "> Adding chunk: InnerProductExercise k1 k2 k3 q • dj \n",
      "d1 1 0 1 ...\n",
      "> Adding chunk: InnerProductExercise k1 k2 k3 q • dj \n",
      "d1 1 0 1 ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Cosine Similarity•Distance between vectors d1 a...\n",
      "> Adding chunk: Cosine Similarity•Distance between vectors d1 a...\n",
      "> Adding chunk: Cosine Similarity•Distance between vectors d1 a...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Cosine Similarity\n",
      "•Cosine of angle between two ...\n",
      "> Adding chunk: Cosine Similarity\n",
      "•Cosine of angle between two ...\n",
      "> Adding chunk: Cosine Similarity\n",
      "•Cosine of angle between two ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Cosine Similarity Exercise•Exercise: Rank the f...\n",
      "> Adding chunk: Cosine Similarity Exercise•Exercise: Rank the f...\n",
      "> Adding chunk: Cosine Similarity Exercise•Exercise: Rank the f...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Cosine Similarity Example•Documents: Sense and ...\n",
      "> Adding chunk: Cosine Similarity Example•Documents: Sense and ...\n",
      "> Adding chunk: Cosine Similarity Example•Documents: Sense and ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Cosine Similarity vs. Inner Product•Cosine simi...\n",
      "> Adding chunk: Cosine Similarity vs. Inner Product•Cosine simi...\n",
      "> Adding chunk: Cosine Similarity vs. Inner Product•Cosine simi...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ExerciseConsider the following four documents:•...\n",
      "> Adding chunk: ExerciseConsider the following four documents:•...\n",
      "> Adding chunk: ExerciseConsider the following four documents:•...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Comments on Vector Space Models•Simple, mathema...\n",
      "> Adding chunk: Comments on Vector Space Models•Simple, mathema...\n",
      "> Adding chunk: Comments on Vector Space Models•Simple, mathema...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Problems with Vector Space Model•Missing semant...\n",
      "> Adding chunk: Problems with Vector Space Model•Missing semant...\n",
      "> Adding chunk: Problems with Vector Space Model•Missing semant...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Evaluation of IR ModelsPrecision & Recall\n",
      "> Adding chunk: Evaluation of IR ModelsPrecision & Recall\n",
      "> Adding chunk: Evaluation of IR ModelsPrecision & Recall\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Standard Evaluation Measures\n",
      "w x\n",
      "y z\n",
      "n2 = w + y...\n",
      "> Adding chunk: Standard Evaluation Measures\n",
      "w x\n",
      "y z\n",
      "n2 = w + y...\n",
      "> Adding chunk: Standard Evaluation Measures\n",
      "w x\n",
      "y z\n",
      "n2 = w + y...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Precision and Recall\n",
      "Recall:\n",
      "Precision:\n",
      "w\n",
      "w+y\n",
      "w...\n",
      "> Adding chunk: Precision and Recall\n",
      "Recall:\n",
      "Precision:\n",
      "w\n",
      "w+y\n",
      "w...\n",
      "> Adding chunk: Precision and Recall\n",
      "Recall:\n",
      "Precision:\n",
      "w\n",
      "w+y\n",
      "w...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Precision and Recall for a Set of Queries•For e...\n",
      "> Adding chunk: Precision and Recall for a Set of Queries•For e...\n",
      "> Adding chunk: Precision and Recall for a Set of Queries•For e...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Term Weighting Approaches\n",
      "> Adding chunk: Term Weighting Approaches\n",
      "> Adding chunk: Term Weighting Approaches\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Graphic RepresentationExample:D1 = 2T1 + 3T2 + ...\n",
      "> Adding chunk: Graphic RepresentationExample:D1 = 2T1 + 3T2 + ...\n",
      "> Adding chunk: Graphic RepresentationExample:D1 = 2T1 + 3T2 + ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Document Collection Representation•A collection...\n",
      "> Adding chunk: Document Collection Representation•A collection...\n",
      "> Adding chunk: Document Collection Representation•A collection...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Salton & Buckley•Experiments with term weightin...\n",
      "> Adding chunk: Salton & Buckley•Experiments with term weightin...\n",
      "> Adding chunk: Salton & Buckley•Experiments with term weightin...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: IR Test Collections•CACM (articles from 'Commun...\n",
      "> Adding chunk: IR Test Collections•CACM (articles from 'Commun...\n",
      "> Adding chunk: IR Test Collections•CACM (articles from 'Commun...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: IR Collections\n",
      "> Adding chunk: IR Collections\n",
      "> Adding chunk: IR Collections\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Term Weighting Components\n",
      "> Adding chunk: Term Weighting Components\n",
      "> Adding chunk: Term Weighting Components\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Sample Weighting Schemes\n",
      "> Adding chunk: Sample Weighting Schemes\n",
      "> Adding chunk: Sample Weighting Schemes\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Performance Results\n",
      "> Adding chunk: Performance Results\n",
      "> Adding chunk: Performance Results\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Lessons Learned•Term weighting DOES matter•Quer...\n",
      "> Adding chunk: Lessons Learned•Term weighting DOES matter•Quer...\n",
      "> Adding chunk: Lessons Learned•Term weighting DOES matter•Quer...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Lessons Learned•Document vectors:–Term-frequenc...\n",
      "> Adding chunk: Lessons Learned•Document vectors:–Term-frequenc...\n",
      "> Adding chunk: Lessons Learned•Document vectors:–Term-frequenc...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Vector Space Model\n",
      "Implementation\n",
      "> Adding chunk: Vector Space Model\n",
      "Implementation\n",
      "> Adding chunk: Vector Space Model\n",
      "Implementation\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Naïve ImplementationConvert all documents in co...\n",
      "> Adding chunk: Naïve ImplementationConvert all documents in co...\n",
      "> Adding chunk: Naïve ImplementationConvert all documents in co...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Practical Implementation•Based on  the observat...\n",
      "> Adding chunk: Practical Implementation•Based on  the observat...\n",
      "> Adding chunk: Practical Implementation•Based on  the observat...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Step 1: Preprocessing•Implement the preprocessi...\n",
      "> Adding chunk: Step 1: Preprocessing•Implement the preprocessi...\n",
      "> Adding chunk: Step 1: Preprocessing•Implement the preprocessi...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Step 2: Indexing•Build an inverted index, with ...\n",
      "> Adding chunk: Step 2: Indexing•Build an inverted index, with ...\n",
      "> Adding chunk: Step 2: Indexing•Build an inverted index, with ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Step 2 (continued)•Many data structures are app...\n",
      "> Adding chunk: Step 2 (continued)•Many data structures are app...\n",
      "> Adding chunk: Step 2 (continued)•Many data structures are app...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Step 2 (continued)\n",
      "system\n",
      "computerdatabase\n",
      "scie...\n",
      "> Adding chunk: Step 2 (continued)\n",
      "system\n",
      "computerdatabase\n",
      "scie...\n",
      "> Adding chunk: Step 2 (continued)\n",
      "system\n",
      "computerdatabase\n",
      "scie...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Step 2 (continued)•TF and IDF for each token ca...\n",
      "> Adding chunk: Step 2 (continued)•TF and IDF for each token ca...\n",
      "> Adding chunk: Step 2 (continued)•TF and IDF for each token ca...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Time Complexity of Indexing•Complexity of creat...\n",
      "> Adding chunk: Time Complexity of Indexing•Complexity of creat...\n",
      "> Adding chunk: Time Complexity of Indexing•Complexity of creat...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Step 3: Retrieval •Use inverted index (from ste...\n",
      "> Adding chunk: Step 3: Retrieval •Use inverted index (from ste...\n",
      "> Adding chunk: Step 3: Retrieval •Use inverted index (from ste...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Step 4: Ranking•Sort the search structure inclu...\n",
      "> Adding chunk: Step 4: Ranking•Sort the search structure inclu...\n",
      "> Adding chunk: Step 4: Ranking•Sort the search structure inclu...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Tfidf vectorizerIn the class, we learnt how to ...\n",
      "> Adding chunk: Tfidf vectorizerIn the class, we learnt how to ...\n",
      "> Adding chunk: Tfidf vectorizerIn the class, we learnt how to ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Information Retrieval and \n",
      "Web SearchWord Repre...\n",
      "> Adding chunk: Information Retrieval and \n",
      "Web SearchWord Repre...\n",
      "> Adding chunk: Information Retrieval and \n",
      "Web SearchWord Repre...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Why Word Representations?•Computing with words–...\n",
      "> Adding chunk: Why Word Representations?•Computing with words–...\n",
      "> Adding chunk: Why Word Representations?•Computing with words–...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Word Embeddings for IR•Compute similarity betwe...\n",
      "> Adding chunk: Word Embeddings for IR•Compute similarity betwe...\n",
      "> Adding chunk: Word Embeddings for IR•Compute similarity betwe...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Word Representations in IR/NLP•Core component i...\n",
      "> Adding chunk: Word Representations in IR/NLP•Core component i...\n",
      "> Adding chunk: Word Representations in IR/NLP•Core component i...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Word Representations in IR/NLPQuestion answerin...\n",
      "> Adding chunk: Word Representations in IR/NLPQuestion answerin...\n",
      "> Adding chunk: Word Representations in IR/NLPQuestion answerin...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: •Plagiarism detection\n",
      "Word Representations in I...\n",
      "> Adding chunk: •Plagiarism detection\n",
      "Word Representations in I...\n",
      "> Adding chunk: •Plagiarism detection\n",
      "Word Representations in I...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Kulkarni, Al-Rfou, Perozzi, Skiena 2015\n",
      "Word Re...\n",
      "> Adding chunk: Kulkarni, Al-Rfou, Perozzi, Skiena 2015\n",
      "Word Re...\n",
      "> Adding chunk: Kulkarni, Al-Rfou, Perozzi, Skiena 2015\n",
      "Word Re...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Core intuition:“You shall know a word by the co...\n",
      "> Adding chunk: Core intuition:“You shall know a word by the co...\n",
      "> Adding chunk: Core intuition:“You shall know a word by the co...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Vector RepresentationsSparse vector representat...\n",
      "> Adding chunk: Vector RepresentationsSparse vector representat...\n",
      "> Adding chunk: Vector RepresentationsSparse vector representat...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Vector Space Model\n",
      "> Adding chunk: Vector Space Model\n",
      "> Adding chunk: Vector Space Model\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Term-Document MatrixAntony and CleopatraJulius ...\n",
      "> Adding chunk: Term-Document MatrixAntony and CleopatraJulius ...\n",
      "> Adding chunk: Term-Document MatrixAntony and CleopatraJulius ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Co-occurrence Matrices\n",
      "> Adding chunk: Co-occurrence Matrices\n",
      "> Adding chunk: Co-occurrence Matrices\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Word-Word or Word-Context Matrices•Instead of e...\n",
      "> Adding chunk: Word-Word or Word-Context Matrices•Instead of e...\n",
      "> Adding chunk: Word-Word or Word-Context Matrices•Instead of e...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Word-Word MatrixSample contexts ± 7 words\n",
      "aardv...\n",
      "> Adding chunk: Word-Word MatrixSample contexts ± 7 words\n",
      "aardv...\n",
      "> Adding chunk: Word-Word MatrixSample contexts ± 7 words\n",
      "aardv...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Word-word Matrix•We showed only 4x6, but the re...\n",
      "> Adding chunk: Word-word Matrix•We showed only 4x6, but the re...\n",
      "> Adding chunk: Word-word Matrix•We showed only 4x6, but the re...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Pointwise Mutual Information\n",
      "Pointwise mutual i...\n",
      "> Adding chunk: Pointwise Mutual Information\n",
      "Pointwise mutual i...\n",
      "> Adding chunk: Pointwise Mutual Information\n",
      "Pointwise mutual i...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Positive Pointwise Mutual Information–PMI range...\n",
      "> Adding chunk: Positive Pointwise Mutual Information–PMI range...\n",
      "> Adding chunk: Positive Pointwise Mutual Information–PMI range...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: PPMI on a Term-Context Matrix•Matrix F with W r...\n",
      "> Adding chunk: PPMI on a Term-Context Matrix•Matrix F with W r...\n",
      "> Adding chunk: PPMI on a Term-Context Matrix•Matrix F with W r...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: pij=fijfijj=1C∑i=1W∑pi*=fijj=1C∑fijj=1C∑i=1W∑p*...\n",
      "> Adding chunk: pij=fijfijj=1C∑i=1W∑pi*=fijj=1C∑fijj=1C∑i=1W∑p*...\n",
      "> Adding chunk: pij=fijfijj=1C∑i=1W∑pi*=fijj=1C∑fijj=1C∑i=1W∑p*...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: p(w,context)p(w)computerdatapinchresultsugarapr...\n",
      "> Adding chunk: p(w,context)p(w)computerdatapinchresultsugarapr...\n",
      "> Adding chunk: p(w,context)p(w)computerdatapinchresultsugarapr...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: pmiij=log2pijpi*p*j p(w,context)p(w)computerdat...\n",
      "> Adding chunk: pmiij=log2pijpi*p*j p(w,context)p(w)computerdat...\n",
      "> Adding chunk: pmiij=log2pijpi*p*j p(w,context)p(w)computerdat...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Weighting PMI•PMI is biased toward infrequent e...\n",
      "> Adding chunk: Weighting PMI•PMI is biased toward infrequent e...\n",
      "> Adding chunk: Weighting PMI•PMI is biased toward infrequent e...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Example: Add-two SmoothingAdd#2%Smoothed%Count(...\n",
      "> Adding chunk: Example: Add-two SmoothingAdd#2%Smoothed%Count(...\n",
      "> Adding chunk: Example: Add-two SmoothingAdd#2%Smoothed%Count(...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: PPMI versus Add-2 Smoothed PPMI\n",
      "PPMI(w,context)...\n",
      "> Adding chunk: PPMI versus Add-2 Smoothed PPMI\n",
      "PPMI(w,context)...\n",
      "> Adding chunk: PPMI versus Add-2 Smoothed PPMI\n",
      "PPMI(w,context)...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Explicit Semantic Analysis\n",
      "> Adding chunk: Explicit Semantic Analysis\n",
      "> Adding chunk: Explicit Semantic Analysis\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Explicit Semantic Analysis•Determine the extent...\n",
      "> Adding chunk: Explicit Semantic Analysis•Determine the extent...\n",
      "> Adding chunk: Explicit Semantic Analysis•Determine the extent...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Explicit Semantic Analysis Example•Word1: heigh...\n",
      "> Adding chunk: Explicit Semantic Analysis Example•Word1: heigh...\n",
      "> Adding chunk: Explicit Semantic Analysis Example•Word1: heigh...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Explicit Semantic Analysis Example•Text1: The d...\n",
      "> Adding chunk: Explicit Semantic Analysis Example•Text1: The d...\n",
      "> Adding chunk: Explicit Semantic Analysis Example•Text1: The d...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Singular Value Decomposition\n",
      "> Adding chunk: Singular Value Decomposition\n",
      "> Adding chunk: Singular Value Decomposition\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Sparse versus Dense Vectors•PPMI vectors are–lo...\n",
      "> Adding chunk: Sparse versus Dense Vectors•PPMI vectors are–lo...\n",
      "> Adding chunk: Sparse versus Dense Vectors•PPMI vectors are–lo...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: •Why dense vectors?–Short vectors may be easier...\n",
      "> Adding chunk: •Why dense vectors?–Short vectors may be easier...\n",
      "> Adding chunk: •Why dense vectors?–Short vectors may be easier...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Singular Value Decomposition•For any matrix X, ...\n",
      "> Adding chunk: Singular Value Decomposition•For any matrix X, ...\n",
      "> Adding chunk: Singular Value Decomposition•For any matrix X, ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Dimensions of Matrices\n",
      "X = T0 D0'S0\n",
      "t x t t x m...\n",
      "> Adding chunk: Dimensions of Matrices\n",
      "X = T0 D0'S0\n",
      "t x t t x m...\n",
      "> Adding chunk: Dimensions of Matrices\n",
      "X = T0 D0'S0\n",
      "t x t t x m...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Reduced Rank•S0 can be chosen so that the diago...\n",
      "> Adding chunk: Reduced Rank•S0 can be chosen so that the diago...\n",
      "> Adding chunk: Reduced Rank•S0 can be chosen so that the diago...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Dimensionality  Reduction\n",
      "X =\n",
      "t x t t x k k x t...\n",
      "> Adding chunk: Dimensionality  Reduction\n",
      "X =\n",
      "t x t t x k k x t...\n",
      "> Adding chunk: Dimensionality  Reduction\n",
      "X =\n",
      "t x t t x k k x t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: SVD Applied to PPMI Word-Word Matrix\n",
      "19.3 • D E...\n",
      "> Adding chunk: SVD Applied to PPMI Word-Word Matrix\n",
      "19.3 • D E...\n",
      "> Adding chunk: SVD Applied to PPMI Word-Word Matrix\n",
      "19.3 • D E...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ". . .\n",
      ".\n",
      ".\n",
      ".\n",
      "000 ... s k\n",
      "3\n",
      "7\n",
      "7\n",
      "7...\n",
      "> Adding chunk: .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ". . .\n",
      ".\n",
      ".\n",
      ".\n",
      "000 ... s k\n",
      "3\n",
      "7\n",
      "7\n",
      "7...\n",
      "> Adding chunk: .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ". . .\n",
      ".\n",
      ".\n",
      ".\n",
      "000 ... s k\n",
      "3\n",
      "7\n",
      "7\n",
      "7...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Truncated SVD – Keep K Dimensions\n",
      "19.3 • D ENSE...\n",
      "> Adding chunk: Truncated SVD – Keep K Dimensions\n",
      "19.3 • D ENSE...\n",
      "> Adding chunk: Truncated SVD – Keep K Dimensions\n",
      "19.3 • D ENSE...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ". . .\n",
      ".\n",
      ".\n",
      ".\n",
      "000 ... s k\n",
      "3\n",
      "7\n",
      "7\n",
      "7...\n",
      "> Adding chunk: .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ". . .\n",
      ".\n",
      ".\n",
      ".\n",
      "000 ... s k\n",
      "3\n",
      "7\n",
      "7\n",
      "7...\n",
      "> Adding chunk: .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ". . .\n",
      ".\n",
      ".\n",
      ".\n",
      "000 ... s k\n",
      "3\n",
      "7\n",
      "7\n",
      "7...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Truncated SVD Produces Embeddings•Each row of W...\n",
      "> Adding chunk: Truncated SVD Produces Embeddings•Each row of W...\n",
      "> Adding chunk: Truncated SVD Produces Embeddings•Each row of W...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ". . .\n",
      ".\n",
      ".\n",
      ".\n",
      "000 ... s k\n",
      "3\n",
      "7\n",
      "7\n",
      "7...\n",
      "> Adding chunk: .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ". . .\n",
      ".\n",
      ".\n",
      ".\n",
      "000 ... s k\n",
      "3\n",
      "7\n",
      "7\n",
      "7...\n",
      "> Adding chunk: .\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ". . .\n",
      ".\n",
      ".\n",
      ".\n",
      "000 ... s k\n",
      "3\n",
      "7\n",
      "7\n",
      "7...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Neural-Network Embeddings\n",
      "> Adding chunk: Neural-Network Embeddings\n",
      "> Adding chunk: Neural-Network Embeddings\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Neural Networks•Neural-inspired architectures u...\n",
      "> Adding chunk: Neural Networks•Neural-inspired architectures u...\n",
      "> Adding chunk: Neural Networks•Neural-inspired architectures u...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Applications of Neural Networks•Classification–...\n",
      "> Adding chunk: Applications of Neural Networks•Classification–...\n",
      "> Adding chunk: Applications of Neural Networks•Classification–...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: A Neuron•A unit of computation in the neural ne...\n",
      "> Adding chunk: A Neuron•A unit of computation in the neural ne...\n",
      "> Adding chunk: A Neuron•A unit of computation in the neural ne...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Feed-forward Network Example\n",
      "•Assume a simple n...\n",
      "> Adding chunk: Feed-forward Network Example\n",
      "•Assume a simple n...\n",
      "> Adding chunk: Feed-forward Network Example\n",
      "•Assume a simple n...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Training a Network•Run all the training instanc...\n",
      "> Adding chunk: Training a Network•Run all the training instanc...\n",
      "> Adding chunk: Training a Network•Run all the training instanc...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Neural Networks for Word Embeddings•Skip-gram (...\n",
      "> Adding chunk: Neural Networks for Word Embeddings•Skip-gram (...\n",
      "> Adding chunk: Neural Networks for Word Embeddings•Skip-gram (...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Prediction-based Neural Network Models•Create a...\n",
      "> Adding chunk: Prediction-based Neural Network Models•Create a...\n",
      "> Adding chunk: Prediction-based Neural Network Models•Create a...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Learning Word Embeddings•Create a lot of traini...\n",
      "> Adding chunk: Learning Word Embeddings•Create a lot of traini...\n",
      "> Adding chunk: Learning Word Embeddings•Create a lot of traini...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Skip-grams\n",
      "Input layer Projection layer\n",
      "Output ...\n",
      "> Adding chunk: Skip-grams\n",
      "Input layer Projection layer\n",
      "Output ...\n",
      "> Adding chunk: Skip-grams\n",
      "Input layer Projection layer\n",
      "Output ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Skip-grams: Training the Network•Use existing c...\n",
      "> Adding chunk: Skip-grams: Training the Network•Use existing c...\n",
      "> Adding chunk: Skip-grams: Training the Network•Use existing c...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: One-hot Vectors•As input, represent a word as a...\n",
      "> Adding chunk: One-hot Vectors•As input, represent a word as a...\n",
      "> Adding chunk: One-hot Vectors•As input, represent a word as a...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Forward/backward propagation•Initialize all wei...\n",
      "> Adding chunk: Forward/backward propagation•Initialize all wei...\n",
      "> Adding chunk: Forward/backward propagation•Initialize all wei...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Skip-grams\n",
      "Input layer Projection layer\n",
      "Output ...\n",
      "> Adding chunk: Skip-grams\n",
      "Input layer Projection layer\n",
      "Output ...\n",
      "> Adding chunk: Skip-grams\n",
      "Input layer Projection layer\n",
      "Output ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CBOWInput layer\n",
      "Projection layer Output layer\n",
      "W...\n",
      "> Adding chunk: CBOWInput layer\n",
      "Projection layer Output layer\n",
      "W...\n",
      "> Adding chunk: CBOWInput layer\n",
      "Projection layer Output layer\n",
      "W...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Result•A “dense” vector learned after training ...\n",
      "> Adding chunk: Result•A “dense” vector learned after training ...\n",
      "> Adding chunk: Result•A “dense” vector learned after training ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Word Embeddings in Practice•word2vec •https://c...\n",
      "> Adding chunk: Word Embeddings in Practice•word2vec •https://c...\n",
      "> Adding chunk: Word Embeddings in Practice•word2vec •https://c...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Introduction to Information Retrieval\n",
      "CS3245\n",
      "In...\n",
      "> Adding chunk: Introduction to Information Retrieval\n",
      "CS3245\n",
      "In...\n",
      "> Adding chunk: Introduction to Information Retrieval\n",
      "CS3245\n",
      "In...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilisticIRMode...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilisticIRMode...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilisticIRMode...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ProbabilisticApproachtoRetrieval\n",
      "InformationRet...\n",
      "> Adding chunk: ProbabilisticApproachtoRetrieval\n",
      "InformationRet...\n",
      "> Adding chunk: ProbabilisticApproachtoRetrieval\n",
      "InformationRet...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: BasicProbabilityTheory\n",
      "InformationRetrieval 4\n",
      "■...\n",
      "> Adding chunk: BasicProbabilityTheory\n",
      "InformationRetrieval 4\n",
      "■...\n",
      "> Adding chunk: BasicProbabilityTheory\n",
      "InformationRetrieval 4\n",
      "■...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "BasicProbabilityThe...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "BasicProbabilityThe...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "BasicProbabilityThe...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: THEPROBABILITY RANKINGPRINCIPLE\n",
      "Sec.11.2\n",
      "Inform...\n",
      "> Adding chunk: THEPROBABILITY RANKINGPRINCIPLE\n",
      "Sec.11.2\n",
      "Inform...\n",
      "> Adding chunk: THEPROBABILITY RANKINGPRINCIPLE\n",
      "Sec.11.2\n",
      "Inform...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "TheDocumentRankingP...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "TheDocumentRankingP...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "TheDocumentRankingP...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilityRankingP...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilityRankingP...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilityRankingP...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "BinaryIndependenceM...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "■Givenaqueryq,ranki...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "■Givenaqueryq,ranki...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "■Givenaqueryq,ranki...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "■Itisatthispointtha...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "■Itisatthispointtha...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "■Itisatthispointtha...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "■Sinceeachxtiseithe...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "■Sinceeachxtiseithe...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "■Sinceeachxtiseithe...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "■Additionalsimplify...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "■Additionalsimplify...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "■Additionalsimplify...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "■Includingthequeryt...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "■Includingthequeryt...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "■Includingthequeryt...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "Deriving aRankingFu...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "Deriving aRankingFu...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "Deriving aRankingFu...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilityEstimate...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilityEstimate...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilityEstimate...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ProbabilityEstimatesinPractice\n",
      "InformationRetri...\n",
      "> Adding chunk: ProbabilityEstimatesinPractice\n",
      "InformationRetri...\n",
      "> Adding chunk: ProbabilityEstimatesinPractice\n",
      "InformationRetri...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilityEstimate...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilityEstimate...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "ProbabilityEstimate...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Probabilistic Relevance Feedback\n",
      "k\n",
      "k\n",
      "+\n",
      "+\n",
      "=\n",
      "||\n",
      "|...\n",
      "> Adding chunk: Probabilistic Relevance Feedback\n",
      "k\n",
      "k\n",
      "+\n",
      "+\n",
      "=\n",
      "||\n",
      "|...\n",
      "> Adding chunk: Probabilistic Relevance Feedback\n",
      "k\n",
      "k\n",
      "+\n",
      "+\n",
      "=\n",
      "||\n",
      "|...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Pseudo-relevance feedback(iteratively auto-esti...\n",
      "> Adding chunk: Pseudo-relevance feedback(iteratively auto-esti...\n",
      "> Adding chunk: Pseudo-relevance feedback(iteratively auto-esti...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "ANAPPRAISALOF PROBA...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "ANAPPRAISALOF PROBA...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "ANAPPRAISALOF PROBA...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "AnAppraisalofProbab...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "AnAppraisalofProbab...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "AnAppraisalofProbab...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "AnAppraisalofProbab...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "AnAppraisalofProbab...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "AnAppraisalofProbab...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:ANonbinar...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:ANonbinar...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:ANonbinar...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:ANonbinar...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:ANonbinar...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:ANonbinar...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:ANonbinar...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:ANonbinar...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:ANonbinar...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:Factoring...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:Factoring...\n",
      "> Adding chunk: CS3245–InformationRetrieval\n",
      "OkapiBM25:Factoring...\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96ade0>, 'json_data': {'input': ['page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Language  Models  for  Information  Retrieval Soujanya Poria', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval  Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval  Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  4 What is a language model? “The goal of a language model is to assign a probability  to a sequence of words by means of a probability distribution” --Wikipedia', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  19 What can we do with a probability  distribution? P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25 • • • • • • P( ) = 0.25 P( ) = 0.5 P( ) = 0.25 x 0.25 x 0.25 P( ) = 0.25 x 0.25 x 0.25 P( ) = 0.25 x 0.50 x 0.25 P( ) = 0.25 x 0.50 x 0.25 x 0.50', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Defines a probability distribution over individual words ‣ P(singapore) = 2/20 ‣ P(university) = 4/20 ‣ P(of) = 4/20 ‣ P(technology) = 2/20 ‣ P(and) = 5/20 ‣ P(design) = 3/20 23 Unigram Language Model singapore singapore of of of of technology and university university university technology and and and and design design design university', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • It is called a unigram language model because we estimate (and predict) the likelihood of each word independent of any other word Assumes that words are independent! • • • • The probability of seeing “tarheels” is the same, even  if the preceding word is “carolina” Other language models take context into account Those work betterfor applications like speech  recognition or automatic language translation Unigram models work well for information retrieval 24 Unigram Language Model', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Sequences of words can be assigned a probability by  multiplying their individual probabilities: 25 Unigram Language Model P(Singapore universityof technology and design) = P(singapore) x P(university) x P(of) x P(technology) x  P(and) x P(design) = (2/20) x (4/20) x (4/20) x (2/20) x (5/20) x (3/20) = 0.000 015 P(singaporeuniveristy) =   P(singapore) x P(univeristy) =  (2/20) x (4/20) = 0.0 2', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • There are two important steps in language modeling ‣ ‣ estimation: observing text and estimating the  probability of each word prediction: using the language model to assign a  probability to a span of text 26 Unigram Language Model', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • Any span of text can be used to estimate a language  model And, given a language model, we can assign a  probability to any span of text ‣ ‣ ‣ ‣ ‣ a word a  sentence  a document  a corpus the entire web 27 Unigram Language Model', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • General estimation approach: ‣ ‣ ‣ ‣ tokenize/split the text into terms count the total number of term occurrences (N)  count the number of occurrences of each term (tft)  assign term t a probability equal to 28 Unigram Language Model Estimation Pt = t ft N', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  29 IMDB Corpus language model estimation (top 20 terms) term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  30 term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053 • What is the probabilityassociatedwith “artist of the year”? IMDB Corpus language model estimation (top 20 terms)', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  31 term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053 • What is more probable:“artist of the year”or “movie to the  year?” IMDB Corpus language model estimation (top 20 terms)', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  32 term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053 • What is the most probable sequence“artist of the ”? IMDB Corpus language model estimation (top 20 terms)', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  35 Language Models • • A language model is a probability distribution defined  over a particular vocabulary In this analogy, each color represents a vocabulary term  and each ball represents a term occurrence in the text  used to estimate the language model P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  ... movies politics sports music nature P(RED) = 0.5 P(RED) = 0.05 P(RED) = 0.90 P(RED) = 0.00 P(RED) = 0.10 P(BLUE) = 0.25 P(BLUE) = 0.00 P(BLUE) = 0.10 P(BLUE) = 0.50 P(BLUE) = 0.80 P(ORANGE) = 0.25 P(ORANGE) = 0.95 P(ORANGE) = 0.00 P(ORANGE) = 0.50 P(ORANGE) = 0.10 36 Topic Models • • We can think of a topic as being defined by a language  model A high-probability of seeing certain words and a low- probability of seeing others', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  37 0 0.15 0.30 0.45 0.60 actress cast movie party political statecharacter election debate term probability Topic Models ???vs. ???', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  38 0 0.15 0.30 0.45 0.60 actress cast movie party political statecharacter election debate term probability Topic Models movies vs. politics', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  39 • • • • • Many factors affect whether a document satisfies a  particular user’s information need Topicality, novelty, freshness, authority, formatting,  reading level, assumed level of expertise, etc. Topical relevance: the document is on the same topic as  the query User relevance: everything else! Remember, our goal right now is to predict topical  relevance Topical Relevance', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  40 Document Language Models • The topic (or topics) discussed in a particular document  can be captured by its language model ... movies P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25 politics P(RED) = 0.05 P(BLUE) = 0.00 sports P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.95 P(ORANGE) = 0.00 music P(RED) = 0.00 P(BLUE) = 0.50 P(ORANGE) = 0.50 nature P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 What is this  document about?DocumentD232', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  41 Document Language Models • Estimating a document’s language model: 1. tokenize/split the document text into terms 2. count the number of times each term occurs (tft,D) 3. count the total number of term occurrences (ND) 4. assign term t a probability equal to: t ft,D   ND', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  42 Document Language Models • • P(t|D) = P(t|θD) = t ft,D ND The language model estimated from document D is   sometimes denoted as: θD The probability given to term t by the language model  estimated from document D is sometimes denoted as:', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  43 • • Movie: Rocky (1976)  Plot: Rocky Balboa is a struggling boxer trying to make the big time. Working in a meat factory in Philadelphia for a  pittance, he also earns extra cash as a debt collector. When heavyweight champion Apollo Creed visits  Philadelphia, his managers want to set up an exhibition match between Creed and a struggling boxer, touting the  fight as a chance for a \"nobody\" to become a \"somebody\". The match is supposed to be easily won by Creed, but  someone forgot to tell Rocky, who sees this as his only shot at the big time. Rocky Balboa is a small-time boxer  who lives in an apartment in Philadelphia, Pennsylvania, and his career has so far not gotten off the canvas. Rocky  earns a living by collecting debts for a loan shark named Gazzo, but Gazzo doesn\\'t think Rocky has the  viciousness it takes to beat up deadbeats. Rocky still boxes every once in a while to keep his boxing skills sharp,  and his ex-trainer, Mickey, believes he could\\'ve made it to the top if he was willing to work for it. Rocky, goes to a  pet store that sells pet supplies, and this is where he meets a young woman named Adrian, who is extremely shy,  with no ability to talk to men. Rocky befriends her .Adrain later surprised Rocky with a dog from the pet shop that  Rocky had befriended. Adrian\\'s brother Paulie, who works for a meat packing company, is thrilled that someone  has become interested in Adrian, and Adrian spends Thanksgiving with Rocky. Later ,they go to Rocky\\'s apartment,  where Adrian explains that she has never been in a man\\'s apartment before. Rocky sets her mind at ease, and they  become lovers. Current world heavyweight boxing champion Apollo Creed comes up with the idea of giving an  unknown a shot at the title. Apollo checks out the Philadelphia boxing scene, and chooses Rocky. Fight promoter  Jergens gets things in gear, and Rocky startstraining with Mickey. After a lot of training, Rocky is ready for the  match, and he wants to prove that he can go the distance with Apollo. The \\'Italian Stallion\\', Rocky Balboa, is an  aspiring boxer in downtown Philadelphia. His one chance to make a betterlife for himself is through his boxing  and Adrian, a girl who works in the local pet store.Through a publicity stunt, Rocky is set up to fight Apollo Creed,  the current heavyweight champion who is already set to win. But Rocky really needs to triumph, against all the  odds... Document Language Models', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  44 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms)', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  45 Document Language Models • • • Suppose we have a document D, with language model θD We can use this language model to determine the  probability of a particular sequence of text How? We multiple the probability associated with each  term in the sequence!', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  46 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms) • What is the probability given by this language model to  the sequence of text “rocky is a boxer”?', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  47 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms) • What is the probability given by this language model to  the sequence of text “a boxer is a pet”?', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  48 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms) • What is the probability given by this language model to  the sequence of text “a boxer is a dog”?', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  49 Query -Likelihood Retrieval Model • • Objective: rank documents based on the probability that  they are on the same topic as the query Solution: ‣ ‣ Score each document (denoted by D) according to the probability given by its language model to the query (denoted by Q) Rank documents in descending order of score n score(Q, D) = P(Q|θD) = ∏P(qi|θD) i=1', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  50 Query -Likelihood Retrieval Model • Every document in the collection is associated with a  language model • Let denote the language model associated with document D • • θD You can think of θD as a “black -box”: given a word, it  outputs a probability θDrocky 0.04524 Let P(t|θD ) denote the probability given by θD to term t', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  51 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00 • • Each document is scored according the probability that it  “generated” the query What does it mean for a document to “generate” the  query?', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  52 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00 • Query = • Which would be the top-ranked document and what  would be its score?', 'page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  53 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00 • Query = • Which would be the top-ranked document and what  would be its score?', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Query = • Which would be the top-ranked document and what  would be its score? 54 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Query = • Which would be the top-ranked document and what  would be its score? 55 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Query -Likelihood Retrieval Model D1 D5 D4 D3 D2 DM Q “rockyvs.apollo   creed” :: P(Q|θD1 ) = 0.001 P(Q|θD2 ) = 0.001 P(Q|θD3 ) = 0.0234 P(Q|θD4 ) = 0.621 P(Q|θD5 ) = 0.00345 :: P(Q|θDM ) = 0.3453 56', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  57 Query -Likelihood Retrieval Model n score(Q, D) = P(Q|θD) = ∏P(qi|θD) i=1 score(rocky vs apollo creed, D5) = P(rocky|θD5 ) ×P(vs|θD5 ) ×P(apollo|θD5 ) ×P(creed|θD5 )', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  58 Query -Likelihood Retrieval Model • • Because we are multiplying query-term probabilities,  the longer the query, the lower the document scores  (from all documents) Is this a problem?', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  59 Query -Likelihood Retrieval Model • • • Because we are multiplying query-term probabilities,  the longer the query, the lower the document scores  (from all documents) Is this a problem? No, because we’re scoring documents for the same  query', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  60 Query -Likelihood Retrieval Model • • n score(Q, D) = P(Q|θD) = ∏P(qi|θD) i=1 There are (at least) two issues with this scoring function What are they?', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  61 Query -Likelihood Retrieval Model • • A document with a single missing query-term will  receive a score of zero (similar to boolean AND) Where is IDF? ‣ Don’t we want to suppress the contribution of terms  that are frequent in the document, but frequent in  general (appear in many documents)?', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval  Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  63 • When estimating probabilities, we tend to ... ‣ Over-estimate the probability of observed outcomes ‣ Under-estimate the probability of unobserved  outcomes • The goal of smoothing is to ... ‣ ‣ Decrease the probability of observed outcomes  Increase the probability of unobserved outcomes • • It’s usually a good idea You probably already know this concept! Smoothing Probability Estimates', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  66 P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25 P( YELLOW ) = 0.00 P(GREEN ) = 0.00 Smoothing Probability Estimates • • • Suppose that in reality this bag is a sample from a  different, bigger bag ... And, our goal is to estimate the probabilities of that  bigger bag ... And, we know that the bigger bag has red, blue, orange,  yellow, and green balls.', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  67 P(RED) = (10/20)   P(BLUE) = (5/20)   P(ORANGE) = (5/20)  P(YELLOW) = (0/20)  P(GREEN) = (0/20) Smoothing Probability Estimates • • Do we really want to assign YELLOWand GREENballs  a zero probability? What else can we do?', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  P(RED) = (11/25)   P(BLUE) = (6/25)   P(ORANGE) = (6/25)  P( YELLOW ) = (1/25)  P(GREEN ) = (1/25) 68 Add -One Smoothing • • • • We could add one ball of each color to the bag This gives a small probability to unobserved outcomes  (YELLOWand GREEN) As a result, it also reduces the probability of observed  outcomes (RED, BLUE, ORANGE) by a small amount Very common solution (also called ‘discounting’)', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  P(GREEN ) = (1/25) 69 Add -One Smoothing • Gives a small probability to unobserved outcomes  (YELLOWand GREEN) and reduces the probability of  observed outcomes (RED, BLUE, ORANGE) by a small amount P(RED) = (10/20)   P(BLUE) = (5/20)   P(ORANGE) = (5/20)  P(YELLOW) = (0/20)  P(GREEN) = (0/20) P(RED) = (11/25)   P(BLUE) = (6/25)   P(ORANGE) = (6/25)  P( YELLOW ) = (1/25)', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  70 • • Movie: Rocky (1976)  Plot: Rocky Balboa is a struggling boxer trying to make the big time. Working in a meat factory in Philadelphia for a  pittance, he also earns extra cash as a debt collector. When heavyweight champion Apollo Creed visits  Philadelphia, his managers want to set up an exhibition match between Creed and a struggling boxer, touting the  fight as a chance for a \"nobody\" to become a \"somebody\". The match is supposed to be easily won by Creed, but  someone forgot to tell Rocky, who sees this as his only shot at the big time. Rocky Balboa is a small-time boxer  who lives in an apartment in Philadelphia, Pennsylvania, and his career has so far not gotten off the canvas. Rocky  earns a living by collecting debts for a loan shark named Gazzo, but Gazzo doesn\\'t think Rocky has the  viciousness it takes to beat up deadbeats. Rocky still boxes every once in a while to keep his boxing skills sharp,  and his ex-trainer, Mickey, believes he could\\'ve made it to the top if he was willing to work for it. Rocky, goes to a  pet store that sells pet supplies, and this is where he meets a young woman named Adrian, who is extremely shy,  with no ability to talk to men. Rocky befriends her .Adrain later surprised Rocky with a dog from the pet shop that  Rocky had befriended. Adrian\\'s brother Paulie, who works for a meat packing company, is thrilled that someone  has become interested in Adrian, and Adrian spends Thanksgiving with Rocky. Later ,they go to Rocky\\'s apartment,  where Adrian explains that she has never been in a man\\'s apartment before. Rocky sets her mind at ease, and they  become lovers. Current world heavyweight boxing champion Apollo Creed comes up with the idea of giving an  unknown a shot at the title. Apollo checks out the Philadelphia boxing scene, and chooses Rocky. Fight promoter  Jergens gets things in gear, and Rocky startstraining with Mickey. After a lot of training, Rocky is ready for the  match, and he wants to prove that he can go the distance with Apollo. The \\'Italian Stallion\\', Rocky Balboa, is an  aspiring boxer in downtown Philadelphia. His one chance to make a betterlife for himself is through his boxing  and Adrian, a girl who works in the local pet store.Through a publicity stunt, Rocky is set up to fight Apollo Creed,  the current heavyweight champion who is already set to win. But Rocky really needs to triumph, against all the  odds... Smoothing Probability Estimates', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  71 • • • • • Smoothing Probability Estimates for document language models We can view a document as words sampled from the  author’s mind High-frequency words (e.g., rocky, apollo, boxing) are  important Low-frequency words (e.g., shot, befriended, checks) are  arbitrary The author chose these, but could have easily chosen  others So, we want to allocate some probability to unobserved  indexed-terms and discount some probability from those  that appear in the document', 'page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  72 • • • • In theory, we could use add-one smoothing To do this, we would add each indexed-term once into  each document ‣ Conceptually! Then, we would compute its language model  probabilities In practice, a more effective approach to smoothing for  information retrieval is called linear interpolation Smoothing Probability Estimates for document language models', 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  73 Linear Interpolation Smoothing • • • Let θD denote the language model associated with  document D Let θC denote the language model associated with the  entire collection Using linear interpolation, the probability given by the  document language model to term t is: P(t|D) = αP(t|θD) + (1 − α)P(t|θC)', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  74 Linear Interpolation Smoothing P(t|D) = αP(t|θD) + (1 − α)P(t|θC) the probabilitygiven  to the term by the  documentlanguage  model the probabilitygiven  to the term by the  collectionlanguage  model', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  75 Linear Interpolation Smoothing P(t|D) = αP(t|θD) + (1 − α)P(t|θC) everyoneof thesenumbers  is between0 and 1,so P(t|D)   is between0 and 1', 'page_label: 56 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • • As before, a document’s score is given by the probability  that it “generated” the query As before, this is given by multiplying the individual  query-term probabilities However, the probabilities are obtained using the  linearly interpolated language model 76 n score(Q, D) = ∏(αP(qi|θD) + (1 − α)P(qi|θC)) i=1 Query Likelihood Retrieval Model with linear interpolation smoothing', 'page_label: 57 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • • • Linear interpolation helps us avoid zero-probabilities Remember, because we’re multiplying probabilities, if a document is missing a single query-term it will be given a score of zero! Linear interpolation smoothing has another added  benefit, though it’s not obvious Let’s start with an example 77 Query Likelihood Retrieval Model with linear interpolation smoothing', 'page_label: 58 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  78 Query Likelihood Retrieval Model • • no smoothing Query: apple ipad Two documents (D1 and D2), each with 50 term  occurrences D1 (ND1=50) D2 (ND2=50) apple 2/50= 0.04 3/50= 0.06 ipad 3/50= 0.06 2/50= 0.04 score (0.04x 0.06) = 0.0024 (0.06x 0.04) = 0.0024', 'page_label: 59 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  79 Query Likelihood Retrieval Model • • no smoothing Query: apple ipad Two documents (D1 and D2), each with 50 term  occurrences • Whi ch query-term is more important: apple or ipad? D1 (ND1=50) D2 (ND2=50) apple 2/50= 0.04 3/50= 0.06 ipad 3/50= 0.06 2/50= 0.04 score (0.04x 0.06) = 0.0024 (0.06x 0.04) = 0.0024', 'page_label: 60 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  80 Query Likelihood Retrieval Model no smoothing • • A term is descriptive of the document if it occurs many  times in the document But, not if it occurs many times in the document and  also occurs frequently in the collection', 'page_label: 61 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  81 Query Likelihood Retrieval Model D1 (ND1=50) D2 (ND2=50) apple 2/50= 0.04 3/50= 0.06 ipad 3/50= 0.06 2/50= 0.04 score (0.04x 0.06) = 0.0024 (0.06x 0.04) = 0.0024 • • no smoothing Query: apple ipad Two documents (D1 and D2), each with 50 term  occurrences • Without smoothing, the query -likelihood model ignores  how frequently the term occurs in general!', 'page_label: 62 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  82 Query Likelihood Retrieval Model with linear interpolation smoothing • • • • Suppose the corpus has 1,000,000 term-occurrences apple occurs 200 / 1,000,000 times ipad occurs 100 / 1,000,000 times   Therefore: P(apple|θC) = 200 1000000 = 0.0002 P(ipad|θC) = 100 1000000 = 0.0001', 'page_label: 63 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  83 Query Likelihood Retrieval Model D1 (ND1=50) D2 (ND2=50) P(apple|D) 0.04 0.06 P(apple|C) 0.0002 0.0002 score(apple) 0.0201 0.0301 P(ipad|D) 0.06 0.04 P(ipad|C) 0.0001 0.0001 score(ipad) 0.03005 0.02005 totalscore 0.000604005 0.000603505 with linear interpolation smoothing n score(Q, D) = ∏(αP(qi|θD) + (1 − α)P(qi|θC)) i=1 α= 0.50', 'page_label: 64 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  84 Query Likelihood Retrieval Model with linear interpolation smoothing • • Linear interpolation smoothing does not only avoid zero  probabilities ... It also introduces an IDF -like scoring of documents ‣ • terms are that are less frequent in the entire  collection have a higher contribution to a document’s  score Yes, but we’ve only seen an example. Where is the  mathematical proof!?', 'page_label: 65 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  85 Query Likelihood Retrieval Model with linear interpolation smoothing', 'page_label: 66 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Extend the unigram model to  bigrams', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Parametric Language Modeling : Transformers', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Parametric Language Modeling•Can we do better than tf-idf?•We need parametric language modeling.•Set a learnable objective.•Use this objective to tune the parameters with gradience descent.•Question is – what network to use?•RNN?•Transformer?', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Lecture Plan 3 1.From recurrence (RNN) to attention-based NLP models2.Introducing the Transformer model3.Great results with Transformers', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  As oflastweek:recurrent models for (most) NLP!•Circa 2016, the de facto strategy in NLP is toencode sentences with a bidirectional LSTM:(for example, the source sentence in a translation) •Define your output (parse, sentence, summary) as a sequence, and use an LSTM to generate it. •Use attention to allow flexible access to memory 4', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Issues with recurrent models: Linear interaction distance•RNNs are unrolled “left-to-right”.•This encodes linear locality: a useful heuristic!•Nearby words often affect each other’s meanings•Problem: RNNs take O(sequence length) steps fordistant word pairs to interact.O(sequence length) tastypizza The chef who …  was 5', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Issues with recurrent models: Linear interaction distance•O(sequence length) steps for distant word pairs to interact means:•Hard to learn long-distance dependencies (because of gradient problems!)•Linear order of words is “baked in”; we already know linear order isn’t the right way to think about sentences… The chef who … was Info of chef has gone through O(sequence length) many layers!6', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Issues with recurrent models: Lack of parallelizability•Forward and backward passes have O(sequence length)unparallelizable operations•GPUs can perform a bunch of independent computations at once!•But future RNN hidden states can’t be computed in full before past RNNhidden states have been computed•Inhibits training on very large datasets! h1 h201  T hTT-1 1223 Numbers indicate min # of steps before a state can be computed7', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  If not recurrence, then what? How about attention?•Attention treats each word’s representation as a query to access and incorporate information from a set of values.•Number of unparallelizable operations does not increase sequence length.•Maximum interaction distance: O(1), since all words interact at every layer! attention embedding0 0 0 0 0 000h1h2 hT 2 222222 2attention1 1111111 All words attendto all words in previous layer; most arrows here are omitted8', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Self-Attention 11', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Self-attention as an NLP building block 𝑤1The 𝑞1𝑘1\\t 𝑣1 𝑤2chef 𝑞2 𝑤3who 𝑤𝑇food 𝑘𝑇𝑞𝑇𝑣𝑇… 𝑞1𝑘1\\t 𝑣1𝑘2𝑞2 𝑞3𝑣2\\t 𝑘3\\t 𝑣3 𝑘𝑇𝑞𝑇𝑣𝑇…self-attention𝑘2\\t 𝑣2\\t 𝑘3\\t𝑞3\\t𝑣3 •In the diagram at the right, we have stacked self-attention blocks, like we might stack LSTM layers.•Can self-attention be a drop-inreplacement for recurrence?•No. It has a few issues, whichwe’ll go through.•First, self-attention is an operation on sets. It has no inherent notion of order. self-attention Self-attention doesn’t know the order of its inputs.10', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order! Barriers and solutions for Self-Attention as a building blockSolutions 11', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Fixing the first self-attention problem: sequence order 12', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  •Pros:•Periodicity indicates that maybe “absolute position” isn’t as important•Maybe can extrapolate to longer sequences as periods restart!•Cons:•Not learnable; also the extrapolation doesn’t really work! •Sinusoidal position representations: concatenate sinusoidal functions of varying periods:sin(𝑖/100002∗1/𝑑)\\tcos(𝑖/100002∗1/𝑑)𝑝𝑖\\t= 𝑑 Position representation vectors through sinusoids sin(𝑖/100002∗2/𝑑) 𝑑cos(𝑖/100002∗2/𝑑) Image: https://timodenk.com/blog/linear-relationships-in-the-transformers-positional-encoding/ Index in the sequence Dimension 15', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  •Learned absolute position representations: Let all 𝑝𝑖\\tbe learnable parameters! Learn a matrix 𝑝\\t∈\\tℝ𝑑×𝑇, and let each 𝑝𝑖\\tbe a column of that matrix!•Pros:•Flexibility: each position gets to be learned to fit the data•Cons:•Definitely can’t extrapolate to indices outside 1,\\t…\\t,\\t𝑇.•Most systems use this!•Sometimes people try more flexible representations of position:•Relative linear position attention [Shaw et al., 2018]•Dependency syntax-based position [Wang et al., 2019]14 Position representation vectors learned from scratch', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order!•No nonlinearities for deeplearning! It’s all just weightedaverages Barriers and solutions for Self-Attention as a building blockSolutions•Add position representations to the inputs 15', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Adding nonlinearities in self-attention•Note that there are no elementwise nonlinearities in self-attention; stacking more self-attention layers just re-averages value vectors•Easy fix: add a feed-forward networkto post-process each output vector.𝑚𝑖\\t=\\t𝑀𝐿𝑃\\toutput𝑖=\\t𝑊2\\t∗\\tReLU\\t𝑊1\\t×\\toutput𝑖\\t+\\t𝑏1+\\t𝑏2 𝑤1The𝑤2chef𝑤3who𝑤𝑇food…Intuition: the FF network processes the result of attention FF FF FFself-attentionFF…FF FF FFself-attentionFF 16', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order!•No nonlinearities for deep learning magic! It’s all just weighted averages•Need to ensure we don’t “look at the future” when predicting a sequence•Like in machine translation•Or language modeling Barriers and solutions for Self-Attention as a building blockSolutions•Add position representations to the inputs•Easy fix: apply the same feedforward network to each self- attention output. 17', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Masking the future in self-attention•To use self-attention in decoders, we need to ensure we can’t peek at the future.•At every timestep, we could change the set of keys and queries to include only past words. (Inefficient!)•To enable parallelization, we mask out attention to future words by setting attention scores to −∞. \\t The chef [START] who −∞ For encoding these words We can look at these (not greyed out) words −∞\\t −∞\\t −∞−∞\\t −∞ −∞\\t −∞\\t −∞\\t −∞ 20 [The matrix of 𝑒𝑖𝑗\\tvalues]', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Masking the future in self-attention•To use self-attention in decoders, we need to ensure we can’t peek at the future.•At every timestep, we could change the set of keys and queries to include only past words. (Inefficient!)•To enable parallelization, we mask out attention to future words by setting attention scores to −∞. −∞−∞−∞−∞−∞−∞−∞−∞−∞ −∞ The chef who [START] For encoding these words We can look at these (not greyed out) words 19', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order!•No nonlinearities for deep learning magic! It’s all just weighted averages•Need to ensure we don’t “look at the future” when predicting a sequence•Like in machine translation•Or language modeling Barriers and solutions for Self-Attention as a building blockSolutions•Add position representations to the inputs•Easy fix: apply the same feedforward network to each self- attention output.•Mask out the future by artificiallysetting attention weights to 0! 20', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  •Self-attention:•the basis of the method.•Position representations:•Specify the sequence order, since self-attention is an unordered function of its inputs.•Nonlinearities:•At the output of the self-attention block•Frequently implemented as a simple feed-forward network.•Masking:•In order to parallelize operations while not looking at the future.•Keeps information about the future from “leaking” to the past.•That’s it! But this is not the Transformer model we’ve been hearing about.21 Necessities for a self-attention building block:', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Outline 22 1.From recurrence (RNN) to attention-based NLP models2.Introducing the Transformer model3.Great results with Transformers', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Transformer Encoder Word Embeddings Position Representations+[input sequence] WordEmbeddings PositionRepresentations+[output sequence] Transformer Decoder [decoder attends to encoder states] Transformer Decoder First, let’s look at the Transformer Encoder and Decoder Blocks at a high level[predictions!] 23', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] 24 Next, let’s look at the Transformer Encoder and Decoder BlocksWhat’s left in a Transformer Encoder Block that we haven’t covered?1.Key-query-value attention: How do we get the 𝑘,\\t𝑞,\\t𝑣\\tvectors from a single word embedding?2.Multi-headed attention: Attend to multiple places in a single layer!3.Tricks to help with training!1.Residual connections2.Layer normalization3.Scaling the dot product4.These tricks don’t improve what the model is able to do; they help improve the training process. Both of these types of modeling improvements are very important!', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Key-Query-Value Attention 25 •We saw that self-attention is when keys, queries, and values come from the samesource. The Transformer does this in a particular way:•Let 𝑥1,\\t…\\t,\\t𝑥𝑇\\tbe input vectors to the Transformer encoder; 𝑥𝑖\\t∈\\tℝ𝑑 •Then keys, queries, values are:•𝑘𝑖\\t=\\t𝐾𝑥𝑖, where 𝐾\\t∈\\tℝ𝑑×𝑑\\tis the key matrix.•𝑞𝑖\\t=\\t𝑄𝑥𝑖, where Q\\t∈\\tℝ𝑑×𝑑\\tis the query matrix.•𝑣𝑖\\t=\\t𝑉𝑥𝑖, where V\\t∈\\tℝ𝑑×𝑑\\tis the value matrix.•These matrices allow different aspects of the 𝑥\\tvectors to be used/emphasized in each of the three roles.', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Key-Query-Value Attention•Let’s look at how key-query-value attention is computed, in matrices.•Let 𝑋\\t=\\t𝑥1;\\t…\\t;\\t𝑥𝑇\\t∈\\tℝ𝑇×𝑑\\tbe the concatenation of input vectors.•First, note that 𝑋𝐾\\t∈\\tℝ𝑇×𝑑, 𝑋𝑄\\t∈\\tℝ𝑇×𝑑, 𝑋𝑉\\t∈\\tℝ𝑇×𝑑.⊤•The output is defined as output\\t=\\tsoftmax\\t𝑋𝑄\\t𝑋𝐾\\t ×\\t𝑋𝑉. = 𝑋𝑄𝐾⊤\\t𝑋⊤∈\\tℝ𝑇×𝑇All pairs of attention scores! output\\t∈\\tℝ𝑇×𝑑= 𝐾⊤\\t𝑋⊤𝑋𝑄First, take the query-key dot products in one matrixmultiplication: 𝑋𝑄\\t𝑋𝐾⊤ Next, softmax, and compute the weighted average with another matrix multiplication.𝑋𝑄𝐾⊤\\t𝑋⊤softmax 𝑋𝑉 26', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Multi-headed attention•What if we want to look in multiple places in the sentence at once?𝑖•For word 𝑖, self-attention “looks” where 𝑥⊤𝑄⊤𝐾𝑥𝑗\\tis high, but maybe we want 𝑑× to focus on different 𝑗\\tfor different reasons?•We’ll define multiple attention “heads” through multiple Q,K,V matrices𝑑•Let,\\t𝑄ℓ,\\t𝐾ℓ,\\t𝑉ℓ\\t∈\\tℝ\\tℎ, where ℎ\\tis the number of attention heads, and ℓ\\trangesfrom 1 to ℎ.•Each attention head performs attention independently:ℓ•outputℓ\\t=\\tsoftmax\\t𝑋𝑄ℓ𝐾⊤𝑋⊤\\t∗\\t𝑋𝑉ℓ, where outputℓ\\t∈\\tℝ𝑑/ℎ•Then the outputs of all the heads are combined!•output\\t=\\t𝑌[output1;\\t…\\t;\\toutputℎ], where 𝑌\\t∈\\tℝ𝑑×𝑑 •Each head gets to “look” at different things, and construct value vectorsdifferently.29', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Multi-headed attention•What if we want to look in multiple places in the sentence at once?𝑖•For word 𝑖, self-attention “looks” where 𝑥⊤𝑄⊤𝐾𝑥𝑗\\tis high, but maybe we want 𝑑× to focus on different 𝑗\\tfor different reasons?•We’ll define multiple attention “heads” through multiple Q,K,V matrices𝑑•Let,\\t𝑄ℓ,\\t𝐾ℓ,\\t𝑉ℓ\\t∈\\tℝ\\tℎ, where ℎ\\tis the number of attention heads, and ℓ\\trangesfrom 1 to ℎ. 𝑋𝑄=𝑋𝑄 Single-head attention(just the query matrix) 𝑋 Multi-head attention(just two heads here) 𝑄1\\t𝑄2\\t=𝑋𝑄1\\t𝑋𝑄2 Same amount of computation as single-head self- attention! 30', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Residual connections [He et al., 2016]•Residual connections are a trick to help models train better.•Instead of 𝑋(𝑖)\\t=\\tLayer(𝑋\\t𝑖−1\\t)\\t(where 𝑖\\trepresents the layer) •We let 𝑋(𝑖)\\t=\\t𝑋(𝑖−1)\\t+\\tLayer(𝑋\\t𝑖−1\\t)\\t(so we only have to learn “the residual”from the previous layer) •Residual connections are thought to make the loss landscape considerably smoother (thus easier training!) Layer𝑋(𝑖−1)\\t 𝑋(𝑖) Layer𝑋(𝑖−1)\\t 𝑋(𝑖)+ [no residuals] [residuals][Loss landscape visualization, Li et al., 2018, on a ResNet]31', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Layer normalization [Ba et al., 2016] ∗\\t𝛾\\t+\\t𝛽 Modulate by learned elementwise gain and bias32', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Layer normalization [Ba et al., 2016] 33', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Scaled Dot Product [Vaswani et al., 2017] 32', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Word Embeddings Position Representations+ Transformer Encoder [input sequence] Transformer Decoder WordEmbeddings PositionRepresentations+ Transformer Decoder [output sequence] [decoder attends to encoder states] Looking back at the whole model, zooming in on an Encoder block:[predictions!] 33', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] Word Embeddings Position Representations+ TransformerEncoder [input sequence] Transformer Decoder WordEmbeddings PositionRepresentations+ Transformer Decoder [output sequence] [decoder attends to encoder states] Looking back at the whole model, zooming in on an Encoder block: [predictions!] Multi-Head AttentionResidual + LayerNorm Feed-ForwardResidual + LayerNorm 34'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96ade0>, 'json_data': {'input': ['page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Language  Models  for  Information  Retrieval Soujanya Poria', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval  Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval  Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  4 What is a language model? “The goal of a language model is to assign a probability  to a sequence of words by means of a probability distribution” --Wikipedia', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  19 What can we do with a probability  distribution? P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25 • • • • • • P( ) = 0.25 P( ) = 0.5 P( ) = 0.25 x 0.25 x 0.25 P( ) = 0.25 x 0.25 x 0.25 P( ) = 0.25 x 0.50 x 0.25 P( ) = 0.25 x 0.50 x 0.25 x 0.50', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Defines a probability distribution over individual words ‣ P(singapore) = 2/20 ‣ P(university) = 4/20 ‣ P(of) = 4/20 ‣ P(technology) = 2/20 ‣ P(and) = 5/20 ‣ P(design) = 3/20 23 Unigram Language Model singapore singapore of of of of technology and university university university technology and and and and design design design university', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • It is called a unigram language model because we estimate (and predict) the likelihood of each word independent of any other word Assumes that words are independent! • • • • The probability of seeing “tarheels” is the same, even  if the preceding word is “carolina” Other language models take context into account Those work betterfor applications like speech  recognition or automatic language translation Unigram models work well for information retrieval 24 Unigram Language Model', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Sequences of words can be assigned a probability by  multiplying their individual probabilities: 25 Unigram Language Model P(Singapore universityof technology and design) = P(singapore) x P(university) x P(of) x P(technology) x  P(and) x P(design) = (2/20) x (4/20) x (4/20) x (2/20) x (5/20) x (3/20) = 0.000 015 P(singaporeuniveristy) =   P(singapore) x P(univeristy) =  (2/20) x (4/20) = 0.0 2', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • There are two important steps in language modeling ‣ ‣ estimation: observing text and estimating the  probability of each word prediction: using the language model to assign a  probability to a span of text 26 Unigram Language Model', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • Any span of text can be used to estimate a language  model And, given a language model, we can assign a  probability to any span of text ‣ ‣ ‣ ‣ ‣ a word a  sentence  a document  a corpus the entire web 27 Unigram Language Model', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • General estimation approach: ‣ ‣ ‣ ‣ tokenize/split the text into terms count the total number of term occurrences (N)  count the number of occurrences of each term (tft)  assign term t a probability equal to 28 Unigram Language Model Estimation Pt = t ft N', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  29 IMDB Corpus language model estimation (top 20 terms) term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  30 term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053 • What is the probabilityassociatedwith “artist of the year”? IMDB Corpus language model estimation (top 20 terms)', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  31 term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053 • What is more probable:“artist of the year”or “movie to the  year?” IMDB Corpus language model estimation (top 20 terms)', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  32 term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053 • What is the most probable sequence“artist of the ”? IMDB Corpus language model estimation (top 20 terms)', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  35 Language Models • • A language model is a probability distribution defined  over a particular vocabulary In this analogy, each color represents a vocabulary term  and each ball represents a term occurrence in the text  used to estimate the language model P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  ... movies politics sports music nature P(RED) = 0.5 P(RED) = 0.05 P(RED) = 0.90 P(RED) = 0.00 P(RED) = 0.10 P(BLUE) = 0.25 P(BLUE) = 0.00 P(BLUE) = 0.10 P(BLUE) = 0.50 P(BLUE) = 0.80 P(ORANGE) = 0.25 P(ORANGE) = 0.95 P(ORANGE) = 0.00 P(ORANGE) = 0.50 P(ORANGE) = 0.10 36 Topic Models • • We can think of a topic as being defined by a language  model A high-probability of seeing certain words and a low- probability of seeing others', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  37 0 0.15 0.30 0.45 0.60 actress cast movie party political statecharacter election debate term probability Topic Models ???vs. ???', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  38 0 0.15 0.30 0.45 0.60 actress cast movie party political statecharacter election debate term probability Topic Models movies vs. politics', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  39 • • • • • Many factors affect whether a document satisfies a  particular user’s information need Topicality, novelty, freshness, authority, formatting,  reading level, assumed level of expertise, etc. Topical relevance: the document is on the same topic as  the query User relevance: everything else! Remember, our goal right now is to predict topical  relevance Topical Relevance', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  40 Document Language Models • The topic (or topics) discussed in a particular document  can be captured by its language model ... movies P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25 politics P(RED) = 0.05 P(BLUE) = 0.00 sports P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.95 P(ORANGE) = 0.00 music P(RED) = 0.00 P(BLUE) = 0.50 P(ORANGE) = 0.50 nature P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 What is this  document about?DocumentD232', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  41 Document Language Models • Estimating a document’s language model: 1. tokenize/split the document text into terms 2. count the number of times each term occurs (tft,D) 3. count the total number of term occurrences (ND) 4. assign term t a probability equal to: t ft,D   ND', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  42 Document Language Models • • P(t|D) = P(t|θD) = t ft,D ND The language model estimated from document D is   sometimes denoted as: θD The probability given to term t by the language model  estimated from document D is sometimes denoted as:', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  43 • • Movie: Rocky (1976)  Plot: Rocky Balboa is a struggling boxer trying to make the big time. Working in a meat factory in Philadelphia for a  pittance, he also earns extra cash as a debt collector. When heavyweight champion Apollo Creed visits  Philadelphia, his managers want to set up an exhibition match between Creed and a struggling boxer, touting the  fight as a chance for a \"nobody\" to become a \"somebody\". The match is supposed to be easily won by Creed, but  someone forgot to tell Rocky, who sees this as his only shot at the big time. Rocky Balboa is a small-time boxer  who lives in an apartment in Philadelphia, Pennsylvania, and his career has so far not gotten off the canvas. Rocky  earns a living by collecting debts for a loan shark named Gazzo, but Gazzo doesn\\'t think Rocky has the  viciousness it takes to beat up deadbeats. Rocky still boxes every once in a while to keep his boxing skills sharp,  and his ex-trainer, Mickey, believes he could\\'ve made it to the top if he was willing to work for it. Rocky, goes to a  pet store that sells pet supplies, and this is where he meets a young woman named Adrian, who is extremely shy,  with no ability to talk to men. Rocky befriends her .Adrain later surprised Rocky with a dog from the pet shop that  Rocky had befriended. Adrian\\'s brother Paulie, who works for a meat packing company, is thrilled that someone  has become interested in Adrian, and Adrian spends Thanksgiving with Rocky. Later ,they go to Rocky\\'s apartment,  where Adrian explains that she has never been in a man\\'s apartment before. Rocky sets her mind at ease, and they  become lovers. Current world heavyweight boxing champion Apollo Creed comes up with the idea of giving an  unknown a shot at the title. Apollo checks out the Philadelphia boxing scene, and chooses Rocky. Fight promoter  Jergens gets things in gear, and Rocky startstraining with Mickey. After a lot of training, Rocky is ready for the  match, and he wants to prove that he can go the distance with Apollo. The \\'Italian Stallion\\', Rocky Balboa, is an  aspiring boxer in downtown Philadelphia. His one chance to make a betterlife for himself is through his boxing  and Adrian, a girl who works in the local pet store.Through a publicity stunt, Rocky is set up to fight Apollo Creed,  the current heavyweight champion who is already set to win. But Rocky really needs to triumph, against all the  odds... Document Language Models', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  44 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms)', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  45 Document Language Models • • • Suppose we have a document D, with language model θD We can use this language model to determine the  probability of a particular sequence of text How? We multiple the probability associated with each  term in the sequence!', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  46 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms) • What is the probability given by this language model to  the sequence of text “rocky is a boxer”?', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  47 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms) • What is the probability given by this language model to  the sequence of text “a boxer is a pet”?', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  48 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms) • What is the probability given by this language model to  the sequence of text “a boxer is a dog”?', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  49 Query -Likelihood Retrieval Model • • Objective: rank documents based on the probability that  they are on the same topic as the query Solution: ‣ ‣ Score each document (denoted by D) according to the probability given by its language model to the query (denoted by Q) Rank documents in descending order of score n score(Q, D) = P(Q|θD) = ∏P(qi|θD) i=1', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  50 Query -Likelihood Retrieval Model • Every document in the collection is associated with a  language model • Let denote the language model associated with document D • • θD You can think of θD as a “black -box”: given a word, it  outputs a probability θDrocky 0.04524 Let P(t|θD ) denote the probability given by θD to term t', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  51 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00 • • Each document is scored according the probability that it  “generated” the query What does it mean for a document to “generate” the  query?', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  52 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00 • Query = • Which would be the top-ranked document and what  would be its score?', 'page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  53 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00 • Query = • Which would be the top-ranked document and what  would be its score?', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Query = • Which would be the top-ranked document and what  would be its score? 54 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Query = • Which would be the top-ranked document and what  would be its score? 55 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Query -Likelihood Retrieval Model D1 D5 D4 D3 D2 DM Q “rockyvs.apollo   creed” :: P(Q|θD1 ) = 0.001 P(Q|θD2 ) = 0.001 P(Q|θD3 ) = 0.0234 P(Q|θD4 ) = 0.621 P(Q|θD5 ) = 0.00345 :: P(Q|θDM ) = 0.3453 56', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  57 Query -Likelihood Retrieval Model n score(Q, D) = P(Q|θD) = ∏P(qi|θD) i=1 score(rocky vs apollo creed, D5) = P(rocky|θD5 ) ×P(vs|θD5 ) ×P(apollo|θD5 ) ×P(creed|θD5 )', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  58 Query -Likelihood Retrieval Model • • Because we are multiplying query-term probabilities,  the longer the query, the lower the document scores  (from all documents) Is this a problem?', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  59 Query -Likelihood Retrieval Model • • • Because we are multiplying query-term probabilities,  the longer the query, the lower the document scores  (from all documents) Is this a problem? No, because we’re scoring documents for the same  query', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  60 Query -Likelihood Retrieval Model • • n score(Q, D) = P(Q|θD) = ∏P(qi|θD) i=1 There are (at least) two issues with this scoring function What are they?', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  61 Query -Likelihood Retrieval Model • • A document with a single missing query-term will  receive a score of zero (similar to boolean AND) Where is IDF? ‣ Don’t we want to suppress the contribution of terms  that are frequent in the document, but frequent in  general (appear in many documents)?', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval  Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  63 • When estimating probabilities, we tend to ... ‣ Over-estimate the probability of observed outcomes ‣ Under-estimate the probability of unobserved  outcomes • The goal of smoothing is to ... ‣ ‣ Decrease the probability of observed outcomes  Increase the probability of unobserved outcomes • • It’s usually a good idea You probably already know this concept! Smoothing Probability Estimates', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  66 P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25 P( YELLOW ) = 0.00 P(GREEN ) = 0.00 Smoothing Probability Estimates • • • Suppose that in reality this bag is a sample from a  different, bigger bag ... And, our goal is to estimate the probabilities of that  bigger bag ... And, we know that the bigger bag has red, blue, orange,  yellow, and green balls.', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  67 P(RED) = (10/20)   P(BLUE) = (5/20)   P(ORANGE) = (5/20)  P(YELLOW) = (0/20)  P(GREEN) = (0/20) Smoothing Probability Estimates • • Do we really want to assign YELLOWand GREENballs  a zero probability? What else can we do?', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  P(RED) = (11/25)   P(BLUE) = (6/25)   P(ORANGE) = (6/25)  P( YELLOW ) = (1/25)  P(GREEN ) = (1/25) 68 Add -One Smoothing • • • • We could add one ball of each color to the bag This gives a small probability to unobserved outcomes  (YELLOWand GREEN) As a result, it also reduces the probability of observed  outcomes (RED, BLUE, ORANGE) by a small amount Very common solution (also called ‘discounting’)', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  P(GREEN ) = (1/25) 69 Add -One Smoothing • Gives a small probability to unobserved outcomes  (YELLOWand GREEN) and reduces the probability of  observed outcomes (RED, BLUE, ORANGE) by a small amount P(RED) = (10/20)   P(BLUE) = (5/20)   P(ORANGE) = (5/20)  P(YELLOW) = (0/20)  P(GREEN) = (0/20) P(RED) = (11/25)   P(BLUE) = (6/25)   P(ORANGE) = (6/25)  P( YELLOW ) = (1/25)', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  70 • • Movie: Rocky (1976)  Plot: Rocky Balboa is a struggling boxer trying to make the big time. Working in a meat factory in Philadelphia for a  pittance, he also earns extra cash as a debt collector. When heavyweight champion Apollo Creed visits  Philadelphia, his managers want to set up an exhibition match between Creed and a struggling boxer, touting the  fight as a chance for a \"nobody\" to become a \"somebody\". The match is supposed to be easily won by Creed, but  someone forgot to tell Rocky, who sees this as his only shot at the big time. Rocky Balboa is a small-time boxer  who lives in an apartment in Philadelphia, Pennsylvania, and his career has so far not gotten off the canvas. Rocky  earns a living by collecting debts for a loan shark named Gazzo, but Gazzo doesn\\'t think Rocky has the  viciousness it takes to beat up deadbeats. Rocky still boxes every once in a while to keep his boxing skills sharp,  and his ex-trainer, Mickey, believes he could\\'ve made it to the top if he was willing to work for it. Rocky, goes to a  pet store that sells pet supplies, and this is where he meets a young woman named Adrian, who is extremely shy,  with no ability to talk to men. Rocky befriends her .Adrain later surprised Rocky with a dog from the pet shop that  Rocky had befriended. Adrian\\'s brother Paulie, who works for a meat packing company, is thrilled that someone  has become interested in Adrian, and Adrian spends Thanksgiving with Rocky. Later ,they go to Rocky\\'s apartment,  where Adrian explains that she has never been in a man\\'s apartment before. Rocky sets her mind at ease, and they  become lovers. Current world heavyweight boxing champion Apollo Creed comes up with the idea of giving an  unknown a shot at the title. Apollo checks out the Philadelphia boxing scene, and chooses Rocky. Fight promoter  Jergens gets things in gear, and Rocky startstraining with Mickey. After a lot of training, Rocky is ready for the  match, and he wants to prove that he can go the distance with Apollo. The \\'Italian Stallion\\', Rocky Balboa, is an  aspiring boxer in downtown Philadelphia. His one chance to make a betterlife for himself is through his boxing  and Adrian, a girl who works in the local pet store.Through a publicity stunt, Rocky is set up to fight Apollo Creed,  the current heavyweight champion who is already set to win. But Rocky really needs to triumph, against all the  odds... Smoothing Probability Estimates', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  71 • • • • • Smoothing Probability Estimates for document language models We can view a document as words sampled from the  author’s mind High-frequency words (e.g., rocky, apollo, boxing) are  important Low-frequency words (e.g., shot, befriended, checks) are  arbitrary The author chose these, but could have easily chosen  others So, we want to allocate some probability to unobserved  indexed-terms and discount some probability from those  that appear in the document', 'page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  72 • • • • In theory, we could use add-one smoothing To do this, we would add each indexed-term once into  each document ‣ Conceptually! Then, we would compute its language model  probabilities In practice, a more effective approach to smoothing for  information retrieval is called linear interpolation Smoothing Probability Estimates for document language models', 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  73 Linear Interpolation Smoothing • • • Let θD denote the language model associated with  document D Let θC denote the language model associated with the  entire collection Using linear interpolation, the probability given by the  document language model to term t is: P(t|D) = αP(t|θD) + (1 − α)P(t|θC)', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  74 Linear Interpolation Smoothing P(t|D) = αP(t|θD) + (1 − α)P(t|θC) the probabilitygiven  to the term by the  documentlanguage  model the probabilitygiven  to the term by the  collectionlanguage  model', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  75 Linear Interpolation Smoothing P(t|D) = αP(t|θD) + (1 − α)P(t|θC) everyoneof thesenumbers  is between0 and 1,so P(t|D)   is between0 and 1', 'page_label: 56 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • • As before, a document’s score is given by the probability  that it “generated” the query As before, this is given by multiplying the individual  query-term probabilities However, the probabilities are obtained using the  linearly interpolated language model 76 n score(Q, D) = ∏(αP(qi|θD) + (1 − α)P(qi|θC)) i=1 Query Likelihood Retrieval Model with linear interpolation smoothing', 'page_label: 57 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • • • Linear interpolation helps us avoid zero-probabilities Remember, because we’re multiplying probabilities, if a document is missing a single query-term it will be given a score of zero! Linear interpolation smoothing has another added  benefit, though it’s not obvious Let’s start with an example 77 Query Likelihood Retrieval Model with linear interpolation smoothing', 'page_label: 58 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  78 Query Likelihood Retrieval Model • • no smoothing Query: apple ipad Two documents (D1 and D2), each with 50 term  occurrences D1 (ND1=50) D2 (ND2=50) apple 2/50= 0.04 3/50= 0.06 ipad 3/50= 0.06 2/50= 0.04 score (0.04x 0.06) = 0.0024 (0.06x 0.04) = 0.0024', 'page_label: 59 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  79 Query Likelihood Retrieval Model • • no smoothing Query: apple ipad Two documents (D1 and D2), each with 50 term  occurrences • Whi ch query-term is more important: apple or ipad? D1 (ND1=50) D2 (ND2=50) apple 2/50= 0.04 3/50= 0.06 ipad 3/50= 0.06 2/50= 0.04 score (0.04x 0.06) = 0.0024 (0.06x 0.04) = 0.0024', 'page_label: 60 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  80 Query Likelihood Retrieval Model no smoothing • • A term is descriptive of the document if it occurs many  times in the document But, not if it occurs many times in the document and  also occurs frequently in the collection', 'page_label: 61 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  81 Query Likelihood Retrieval Model D1 (ND1=50) D2 (ND2=50) apple 2/50= 0.04 3/50= 0.06 ipad 3/50= 0.06 2/50= 0.04 score (0.04x 0.06) = 0.0024 (0.06x 0.04) = 0.0024 • • no smoothing Query: apple ipad Two documents (D1 and D2), each with 50 term  occurrences • Without smoothing, the query -likelihood model ignores  how frequently the term occurs in general!', 'page_label: 62 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  82 Query Likelihood Retrieval Model with linear interpolation smoothing • • • • Suppose the corpus has 1,000,000 term-occurrences apple occurs 200 / 1,000,000 times ipad occurs 100 / 1,000,000 times   Therefore: P(apple|θC) = 200 1000000 = 0.0002 P(ipad|θC) = 100 1000000 = 0.0001', 'page_label: 63 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  83 Query Likelihood Retrieval Model D1 (ND1=50) D2 (ND2=50) P(apple|D) 0.04 0.06 P(apple|C) 0.0002 0.0002 score(apple) 0.0201 0.0301 P(ipad|D) 0.06 0.04 P(ipad|C) 0.0001 0.0001 score(ipad) 0.03005 0.02005 totalscore 0.000604005 0.000603505 with linear interpolation smoothing n score(Q, D) = ∏(αP(qi|θD) + (1 − α)P(qi|θC)) i=1 α= 0.50', 'page_label: 64 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  84 Query Likelihood Retrieval Model with linear interpolation smoothing • • Linear interpolation smoothing does not only avoid zero  probabilities ... It also introduces an IDF -like scoring of documents ‣ • terms are that are less frequent in the entire  collection have a higher contribution to a document’s  score Yes, but we’ve only seen an example. Where is the  mathematical proof!?', 'page_label: 65 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  85 Query Likelihood Retrieval Model with linear interpolation smoothing', 'page_label: 66 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Extend the unigram model to  bigrams', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Parametric Language Modeling : Transformers', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Parametric Language Modeling•Can we do better than tf-idf?•We need parametric language modeling.•Set a learnable objective.•Use this objective to tune the parameters with gradience descent.•Question is – what network to use?•RNN?•Transformer?', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Lecture Plan 3 1.From recurrence (RNN) to attention-based NLP models2.Introducing the Transformer model3.Great results with Transformers', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  As oflastweek:recurrent models for (most) NLP!•Circa 2016, the de facto strategy in NLP is toencode sentences with a bidirectional LSTM:(for example, the source sentence in a translation) •Define your output (parse, sentence, summary) as a sequence, and use an LSTM to generate it. •Use attention to allow flexible access to memory 4', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Issues with recurrent models: Linear interaction distance•RNNs are unrolled “left-to-right”.•This encodes linear locality: a useful heuristic!•Nearby words often affect each other’s meanings•Problem: RNNs take O(sequence length) steps fordistant word pairs to interact.O(sequence length) tastypizza The chef who …  was 5', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Issues with recurrent models: Linear interaction distance•O(sequence length) steps for distant word pairs to interact means:•Hard to learn long-distance dependencies (because of gradient problems!)•Linear order of words is “baked in”; we already know linear order isn’t the right way to think about sentences… The chef who … was Info of chef has gone through O(sequence length) many layers!6', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Issues with recurrent models: Lack of parallelizability•Forward and backward passes have O(sequence length)unparallelizable operations•GPUs can perform a bunch of independent computations at once!•But future RNN hidden states can’t be computed in full before past RNNhidden states have been computed•Inhibits training on very large datasets! h1 h201  T hTT-1 1223 Numbers indicate min # of steps before a state can be computed7', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  If not recurrence, then what? How about attention?•Attention treats each word’s representation as a query to access and incorporate information from a set of values.•Number of unparallelizable operations does not increase sequence length.•Maximum interaction distance: O(1), since all words interact at every layer! attention embedding0 0 0 0 0 000h1h2 hT 2 222222 2attention1 1111111 All words attendto all words in previous layer; most arrows here are omitted8', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Self-Attention 11', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Self-attention as an NLP building block 𝑤1The 𝑞1𝑘1\\t 𝑣1 𝑤2chef 𝑞2 𝑤3who 𝑤𝑇food 𝑘𝑇𝑞𝑇𝑣𝑇… 𝑞1𝑘1\\t 𝑣1𝑘2𝑞2 𝑞3𝑣2\\t 𝑘3\\t 𝑣3 𝑘𝑇𝑞𝑇𝑣𝑇…self-attention𝑘2\\t 𝑣2\\t 𝑘3\\t𝑞3\\t𝑣3 •In the diagram at the right, we have stacked self-attention blocks, like we might stack LSTM layers.•Can self-attention be a drop-inreplacement for recurrence?•No. It has a few issues, whichwe’ll go through.•First, self-attention is an operation on sets. It has no inherent notion of order. self-attention Self-attention doesn’t know the order of its inputs.10', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order! Barriers and solutions for Self-Attention as a building blockSolutions 11', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Fixing the first self-attention problem: sequence order 12', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  •Pros:•Periodicity indicates that maybe “absolute position” isn’t as important•Maybe can extrapolate to longer sequences as periods restart!•Cons:•Not learnable; also the extrapolation doesn’t really work! •Sinusoidal position representations: concatenate sinusoidal functions of varying periods:sin(𝑖/100002∗1/𝑑)\\tcos(𝑖/100002∗1/𝑑)𝑝𝑖\\t= 𝑑 Position representation vectors through sinusoids sin(𝑖/100002∗2/𝑑) 𝑑cos(𝑖/100002∗2/𝑑) Image: https://timodenk.com/blog/linear-relationships-in-the-transformers-positional-encoding/ Index in the sequence Dimension 15', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  •Learned absolute position representations: Let all 𝑝𝑖\\tbe learnable parameters! Learn a matrix 𝑝\\t∈\\tℝ𝑑×𝑇, and let each 𝑝𝑖\\tbe a column of that matrix!•Pros:•Flexibility: each position gets to be learned to fit the data•Cons:•Definitely can’t extrapolate to indices outside 1,\\t…\\t,\\t𝑇.•Most systems use this!•Sometimes people try more flexible representations of position:•Relative linear position attention [Shaw et al., 2018]•Dependency syntax-based position [Wang et al., 2019]14 Position representation vectors learned from scratch', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order!•No nonlinearities for deeplearning! It’s all just weightedaverages Barriers and solutions for Self-Attention as a building blockSolutions•Add position representations to the inputs 15', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Adding nonlinearities in self-attention•Note that there are no elementwise nonlinearities in self-attention; stacking more self-attention layers just re-averages value vectors•Easy fix: add a feed-forward networkto post-process each output vector.𝑚𝑖\\t=\\t𝑀𝐿𝑃\\toutput𝑖=\\t𝑊2\\t∗\\tReLU\\t𝑊1\\t×\\toutput𝑖\\t+\\t𝑏1+\\t𝑏2 𝑤1The𝑤2chef𝑤3who𝑤𝑇food…Intuition: the FF network processes the result of attention FF FF FFself-attentionFF…FF FF FFself-attentionFF 16', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order!•No nonlinearities for deep learning magic! It’s all just weighted averages•Need to ensure we don’t “look at the future” when predicting a sequence•Like in machine translation•Or language modeling Barriers and solutions for Self-Attention as a building blockSolutions•Add position representations to the inputs•Easy fix: apply the same feedforward network to each self- attention output. 17', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Masking the future in self-attention•To use self-attention in decoders, we need to ensure we can’t peek at the future.•At every timestep, we could change the set of keys and queries to include only past words. (Inefficient!)•To enable parallelization, we mask out attention to future words by setting attention scores to −∞. \\t The chef [START] who −∞ For encoding these words We can look at these (not greyed out) words −∞\\t −∞\\t −∞−∞\\t −∞ −∞\\t −∞\\t −∞\\t −∞ 20 [The matrix of 𝑒𝑖𝑗\\tvalues]', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Masking the future in self-attention•To use self-attention in decoders, we need to ensure we can’t peek at the future.•At every timestep, we could change the set of keys and queries to include only past words. (Inefficient!)•To enable parallelization, we mask out attention to future words by setting attention scores to −∞. −∞−∞−∞−∞−∞−∞−∞−∞−∞ −∞ The chef who [START] For encoding these words We can look at these (not greyed out) words 19', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order!•No nonlinearities for deep learning magic! It’s all just weighted averages•Need to ensure we don’t “look at the future” when predicting a sequence•Like in machine translation•Or language modeling Barriers and solutions for Self-Attention as a building blockSolutions•Add position representations to the inputs•Easy fix: apply the same feedforward network to each self- attention output.•Mask out the future by artificiallysetting attention weights to 0! 20', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  •Self-attention:•the basis of the method.•Position representations:•Specify the sequence order, since self-attention is an unordered function of its inputs.•Nonlinearities:•At the output of the self-attention block•Frequently implemented as a simple feed-forward network.•Masking:•In order to parallelize operations while not looking at the future.•Keeps information about the future from “leaking” to the past.•That’s it! But this is not the Transformer model we’ve been hearing about.21 Necessities for a self-attention building block:', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Outline 22 1.From recurrence (RNN) to attention-based NLP models2.Introducing the Transformer model3.Great results with Transformers', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Transformer Encoder Word Embeddings Position Representations+[input sequence] WordEmbeddings PositionRepresentations+[output sequence] Transformer Decoder [decoder attends to encoder states] Transformer Decoder First, let’s look at the Transformer Encoder and Decoder Blocks at a high level[predictions!] 23', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] 24 Next, let’s look at the Transformer Encoder and Decoder BlocksWhat’s left in a Transformer Encoder Block that we haven’t covered?1.Key-query-value attention: How do we get the 𝑘,\\t𝑞,\\t𝑣\\tvectors from a single word embedding?2.Multi-headed attention: Attend to multiple places in a single layer!3.Tricks to help with training!1.Residual connections2.Layer normalization3.Scaling the dot product4.These tricks don’t improve what the model is able to do; they help improve the training process. Both of these types of modeling improvements are very important!', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Key-Query-Value Attention 25 •We saw that self-attention is when keys, queries, and values come from the samesource. The Transformer does this in a particular way:•Let 𝑥1,\\t…\\t,\\t𝑥𝑇\\tbe input vectors to the Transformer encoder; 𝑥𝑖\\t∈\\tℝ𝑑 •Then keys, queries, values are:•𝑘𝑖\\t=\\t𝐾𝑥𝑖, where 𝐾\\t∈\\tℝ𝑑×𝑑\\tis the key matrix.•𝑞𝑖\\t=\\t𝑄𝑥𝑖, where Q\\t∈\\tℝ𝑑×𝑑\\tis the query matrix.•𝑣𝑖\\t=\\t𝑉𝑥𝑖, where V\\t∈\\tℝ𝑑×𝑑\\tis the value matrix.•These matrices allow different aspects of the 𝑥\\tvectors to be used/emphasized in each of the three roles.', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Key-Query-Value Attention•Let’s look at how key-query-value attention is computed, in matrices.•Let 𝑋\\t=\\t𝑥1;\\t…\\t;\\t𝑥𝑇\\t∈\\tℝ𝑇×𝑑\\tbe the concatenation of input vectors.•First, note that 𝑋𝐾\\t∈\\tℝ𝑇×𝑑, 𝑋𝑄\\t∈\\tℝ𝑇×𝑑, 𝑋𝑉\\t∈\\tℝ𝑇×𝑑.⊤•The output is defined as output\\t=\\tsoftmax\\t𝑋𝑄\\t𝑋𝐾\\t ×\\t𝑋𝑉. = 𝑋𝑄𝐾⊤\\t𝑋⊤∈\\tℝ𝑇×𝑇All pairs of attention scores! output\\t∈\\tℝ𝑇×𝑑= 𝐾⊤\\t𝑋⊤𝑋𝑄First, take the query-key dot products in one matrixmultiplication: 𝑋𝑄\\t𝑋𝐾⊤ Next, softmax, and compute the weighted average with another matrix multiplication.𝑋𝑄𝐾⊤\\t𝑋⊤softmax 𝑋𝑉 26', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Multi-headed attention•What if we want to look in multiple places in the sentence at once?𝑖•For word 𝑖, self-attention “looks” where 𝑥⊤𝑄⊤𝐾𝑥𝑗\\tis high, but maybe we want 𝑑× to focus on different 𝑗\\tfor different reasons?•We’ll define multiple attention “heads” through multiple Q,K,V matrices𝑑•Let,\\t𝑄ℓ,\\t𝐾ℓ,\\t𝑉ℓ\\t∈\\tℝ\\tℎ, where ℎ\\tis the number of attention heads, and ℓ\\trangesfrom 1 to ℎ.•Each attention head performs attention independently:ℓ•outputℓ\\t=\\tsoftmax\\t𝑋𝑄ℓ𝐾⊤𝑋⊤\\t∗\\t𝑋𝑉ℓ, where outputℓ\\t∈\\tℝ𝑑/ℎ•Then the outputs of all the heads are combined!•output\\t=\\t𝑌[output1;\\t…\\t;\\toutputℎ], where 𝑌\\t∈\\tℝ𝑑×𝑑 •Each head gets to “look” at different things, and construct value vectorsdifferently.29', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Multi-headed attention•What if we want to look in multiple places in the sentence at once?𝑖•For word 𝑖, self-attention “looks” where 𝑥⊤𝑄⊤𝐾𝑥𝑗\\tis high, but maybe we want 𝑑× to focus on different 𝑗\\tfor different reasons?•We’ll define multiple attention “heads” through multiple Q,K,V matrices𝑑•Let,\\t𝑄ℓ,\\t𝐾ℓ,\\t𝑉ℓ\\t∈\\tℝ\\tℎ, where ℎ\\tis the number of attention heads, and ℓ\\trangesfrom 1 to ℎ. 𝑋𝑄=𝑋𝑄 Single-head attention(just the query matrix) 𝑋 Multi-head attention(just two heads here) 𝑄1\\t𝑄2\\t=𝑋𝑄1\\t𝑋𝑄2 Same amount of computation as single-head self- attention! 30', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Residual connections [He et al., 2016]•Residual connections are a trick to help models train better.•Instead of 𝑋(𝑖)\\t=\\tLayer(𝑋\\t𝑖−1\\t)\\t(where 𝑖\\trepresents the layer) •We let 𝑋(𝑖)\\t=\\t𝑋(𝑖−1)\\t+\\tLayer(𝑋\\t𝑖−1\\t)\\t(so we only have to learn “the residual”from the previous layer) •Residual connections are thought to make the loss landscape considerably smoother (thus easier training!) Layer𝑋(𝑖−1)\\t 𝑋(𝑖) Layer𝑋(𝑖−1)\\t 𝑋(𝑖)+ [no residuals] [residuals][Loss landscape visualization, Li et al., 2018, on a ResNet]31', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Layer normalization [Ba et al., 2016] ∗\\t𝛾\\t+\\t𝛽 Modulate by learned elementwise gain and bias32', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Layer normalization [Ba et al., 2016] 33', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Scaled Dot Product [Vaswani et al., 2017] 32', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Word Embeddings Position Representations+ Transformer Encoder [input sequence] Transformer Decoder WordEmbeddings PositionRepresentations+ Transformer Decoder [output sequence] [decoder attends to encoder states] Looking back at the whole model, zooming in on an Encoder block:[predictions!] 33', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] Word Embeddings Position Representations+ TransformerEncoder [input sequence] Transformer Decoder WordEmbeddings PositionRepresentations+ Transformer Decoder [output sequence] [decoder attends to encoder states] Looking back at the whole model, zooming in on an Encoder block: [predictions!] Multi-Head AttentionResidual + LayerNorm Feed-ForwardResidual + LayerNorm 34'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96ade0>, 'json_data': {'input': ['page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Language  Models  for  Information  Retrieval Soujanya Poria', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval  Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval  Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  4 What is a language model? “The goal of a language model is to assign a probability  to a sequence of words by means of a probability distribution” --Wikipedia', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  19 What can we do with a probability  distribution? P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25 • • • • • • P( ) = 0.25 P( ) = 0.5 P( ) = 0.25 x 0.25 x 0.25 P( ) = 0.25 x 0.25 x 0.25 P( ) = 0.25 x 0.50 x 0.25 P( ) = 0.25 x 0.50 x 0.25 x 0.50', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Defines a probability distribution over individual words ‣ P(singapore) = 2/20 ‣ P(university) = 4/20 ‣ P(of) = 4/20 ‣ P(technology) = 2/20 ‣ P(and) = 5/20 ‣ P(design) = 3/20 23 Unigram Language Model singapore singapore of of of of technology and university university university technology and and and and design design design university', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • It is called a unigram language model because we estimate (and predict) the likelihood of each word independent of any other word Assumes that words are independent! • • • • The probability of seeing “tarheels” is the same, even  if the preceding word is “carolina” Other language models take context into account Those work betterfor applications like speech  recognition or automatic language translation Unigram models work well for information retrieval 24 Unigram Language Model', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Sequences of words can be assigned a probability by  multiplying their individual probabilities: 25 Unigram Language Model P(Singapore universityof technology and design) = P(singapore) x P(university) x P(of) x P(technology) x  P(and) x P(design) = (2/20) x (4/20) x (4/20) x (2/20) x (5/20) x (3/20) = 0.000 015 P(singaporeuniveristy) =   P(singapore) x P(univeristy) =  (2/20) x (4/20) = 0.0 2', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • There are two important steps in language modeling ‣ ‣ estimation: observing text and estimating the  probability of each word prediction: using the language model to assign a  probability to a span of text 26 Unigram Language Model', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • Any span of text can be used to estimate a language  model And, given a language model, we can assign a  probability to any span of text ‣ ‣ ‣ ‣ ‣ a word a  sentence  a document  a corpus the entire web 27 Unigram Language Model', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • General estimation approach: ‣ ‣ ‣ ‣ tokenize/split the text into terms count the total number of term occurrences (N)  count the number of occurrences of each term (tft)  assign term t a probability equal to 28 Unigram Language Model Estimation Pt = t ft N', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  29 IMDB Corpus language model estimation (top 20 terms) term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  30 term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053 • What is the probabilityassociatedwith “artist of the year”? IMDB Corpus language model estimation (top 20 terms)', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  31 term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053 • What is more probable:“artist of the year”or “movie to the  year?” IMDB Corpus language model estimation (top 20 terms)', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  32 term tf N P(term) term tf N P(term) the 1586358 36989629 0.0429 year 250151 36989629 0.0068 a 854437 36989629 0.0231 he 242508 36989629 0.0066 and 822091 36989629 0.0222 movie 241551 36989629 0.0065 to 804137 36989629 0.0217 her 240448 36989629 0.0065 of 657059 36989629 0.0178 artist 236286 36989629 0.0064 in 472059 36989629 0.0128 character 234754 36989629 0.0063 is 395968 36989629 0.0107 cast 234202 36989629 0.0063 i 390282 36989629 0.0106 plot 234189 36989629 0.0063 his 328877 36989629 0.0089 for 207319 36989629 0.0056 with 253153 36989629 0.0068 that 197723 36989629 0.0053 • What is the most probable sequence“artist of the ”? IMDB Corpus language model estimation (top 20 terms)', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  35 Language Models • • A language model is a probability distribution defined  over a particular vocabulary In this analogy, each color represents a vocabulary term  and each ball represents a term occurrence in the text  used to estimate the language model P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  ... movies politics sports music nature P(RED) = 0.5 P(RED) = 0.05 P(RED) = 0.90 P(RED) = 0.00 P(RED) = 0.10 P(BLUE) = 0.25 P(BLUE) = 0.00 P(BLUE) = 0.10 P(BLUE) = 0.50 P(BLUE) = 0.80 P(ORANGE) = 0.25 P(ORANGE) = 0.95 P(ORANGE) = 0.00 P(ORANGE) = 0.50 P(ORANGE) = 0.10 36 Topic Models • • We can think of a topic as being defined by a language  model A high-probability of seeing certain words and a low- probability of seeing others', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  37 0 0.15 0.30 0.45 0.60 actress cast movie party political statecharacter election debate term probability Topic Models ???vs. ???', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  38 0 0.15 0.30 0.45 0.60 actress cast movie party political statecharacter election debate term probability Topic Models movies vs. politics', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  39 • • • • • Many factors affect whether a document satisfies a  particular user’s information need Topicality, novelty, freshness, authority, formatting,  reading level, assumed level of expertise, etc. Topical relevance: the document is on the same topic as  the query User relevance: everything else! Remember, our goal right now is to predict topical  relevance Topical Relevance', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  40 Document Language Models • The topic (or topics) discussed in a particular document  can be captured by its language model ... movies P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25 politics P(RED) = 0.05 P(BLUE) = 0.00 sports P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.95 P(ORANGE) = 0.00 music P(RED) = 0.00 P(BLUE) = 0.50 P(ORANGE) = 0.50 nature P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 What is this  document about?DocumentD232', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  41 Document Language Models • Estimating a document’s language model: 1. tokenize/split the document text into terms 2. count the number of times each term occurs (tft,D) 3. count the total number of term occurrences (ND) 4. assign term t a probability equal to: t ft,D   ND', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  42 Document Language Models • • P(t|D) = P(t|θD) = t ft,D ND The language model estimated from document D is   sometimes denoted as: θD The probability given to term t by the language model  estimated from document D is sometimes denoted as:', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  43 • • Movie: Rocky (1976)  Plot: Rocky Balboa is a struggling boxer trying to make the big time. Working in a meat factory in Philadelphia for a  pittance, he also earns extra cash as a debt collector. When heavyweight champion Apollo Creed visits  Philadelphia, his managers want to set up an exhibition match between Creed and a struggling boxer, touting the  fight as a chance for a \"nobody\" to become a \"somebody\". The match is supposed to be easily won by Creed, but  someone forgot to tell Rocky, who sees this as his only shot at the big time. Rocky Balboa is a small-time boxer  who lives in an apartment in Philadelphia, Pennsylvania, and his career has so far not gotten off the canvas. Rocky  earns a living by collecting debts for a loan shark named Gazzo, but Gazzo doesn\\'t think Rocky has the  viciousness it takes to beat up deadbeats. Rocky still boxes every once in a while to keep his boxing skills sharp,  and his ex-trainer, Mickey, believes he could\\'ve made it to the top if he was willing to work for it. Rocky, goes to a  pet store that sells pet supplies, and this is where he meets a young woman named Adrian, who is extremely shy,  with no ability to talk to men. Rocky befriends her .Adrain later surprised Rocky with a dog from the pet shop that  Rocky had befriended. Adrian\\'s brother Paulie, who works for a meat packing company, is thrilled that someone  has become interested in Adrian, and Adrian spends Thanksgiving with Rocky. Later ,they go to Rocky\\'s apartment,  where Adrian explains that she has never been in a man\\'s apartment before. Rocky sets her mind at ease, and they  become lovers. Current world heavyweight boxing champion Apollo Creed comes up with the idea of giving an  unknown a shot at the title. Apollo checks out the Philadelphia boxing scene, and chooses Rocky. Fight promoter  Jergens gets things in gear, and Rocky startstraining with Mickey. After a lot of training, Rocky is ready for the  match, and he wants to prove that he can go the distance with Apollo. The \\'Italian Stallion\\', Rocky Balboa, is an  aspiring boxer in downtown Philadelphia. His one chance to make a betterlife for himself is through his boxing  and Adrian, a girl who works in the local pet store.Through a publicity stunt, Rocky is set up to fight Apollo Creed,  the current heavyweight champion who is already set to win. But Rocky really needs to triumph, against all the  odds... Document Language Models', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  44 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms)', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  45 Document Language Models • • • Suppose we have a document D, with language model θD We can use this language model to determine the  probability of a particular sequence of text How? We multiple the probability associated with each  term in the sequence!', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  46 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms) • What is the probability given by this language model to  the sequence of text “rocky is a boxer”?', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  47 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms) • What is the probability given by this language model to  the sequence of text “a boxer is a pet”?', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  48 term tft,D ND P(term|D) term tft,D ND P(term|D) a 22 420 0.05238 creed 5 420 0.01190 rocky 19 420 0.04524 philadelphia 5 420 0.01190 to 18 420 0.04286 has 4 420 0.00952 the 17 420 0.04048 pet 4 420 0.00952 is 11 420 0.02619 boxing 4 420 0.00952 and 10 420 0.02381 up 4 420 0.00952 in 10 420 0.02381 an 4 420 0.00952 for 7 420 0.01667 boxer 4 420 0.00952 his 7 420 0.01667 s 3 420 0.00714 he 6 420 0.01429 balboa 3 420 0.00714 Document Language Models language model estimation (top 20 terms) • What is the probability given by this language model to  the sequence of text “a boxer is a dog”?', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  49 Query -Likelihood Retrieval Model • • Objective: rank documents based on the probability that  they are on the same topic as the query Solution: ‣ ‣ Score each document (denoted by D) according to the probability given by its language model to the query (denoted by Q) Rank documents in descending order of score n score(Q, D) = P(Q|θD) = ∏P(qi|θD) i=1', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  50 Query -Likelihood Retrieval Model • Every document in the collection is associated with a  language model • Let denote the language model associated with document D • • θD You can think of θD as a “black -box”: given a word, it  outputs a probability θDrocky 0.04524 Let P(t|θD ) denote the probability given by θD to term t', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  51 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00 • • Each document is scored according the probability that it  “generated” the query What does it mean for a document to “generate” the  query?', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  52 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00 • Query = • Which would be the top-ranked document and what  would be its score?', 'page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  53 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00 • Query = • Which would be the top-ranked document and what  would be its score?', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Query = • Which would be the top-ranked document and what  would be its score? 54 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • Query = • Which would be the top-ranked document and what  would be its score? 55 Query -Likelihood Model back to our analogy D6 P(RED) = 0.10 P(BLUE) = 0.80 P(ORANGE) = 0.10 D1 P(RED) = 0.50 P(BLUE) = 0.25 P(ORANGE) = 0.25 D2 P(RED) = 0.25 P(BLUE) = 0.25 P(ORANGE) = 0.50 D3 P(RED) = 0.90 P(BLUE) = 0.10 P(ORANGE) = 0.00 D5 P(RED) = 0.50 P(BLUE) = 0.50 P(ORANGE) = 0.00', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Query -Likelihood Retrieval Model D1 D5 D4 D3 D2 DM Q “rockyvs.apollo   creed” :: P(Q|θD1 ) = 0.001 P(Q|θD2 ) = 0.001 P(Q|θD3 ) = 0.0234 P(Q|θD4 ) = 0.621 P(Q|θD5 ) = 0.00345 :: P(Q|θDM ) = 0.3453 56', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  57 Query -Likelihood Retrieval Model n score(Q, D) = P(Q|θD) = ∏P(qi|θD) i=1 score(rocky vs apollo creed, D5) = P(rocky|θD5 ) ×P(vs|θD5 ) ×P(apollo|θD5 ) ×P(creed|θD5 )', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  58 Query -Likelihood Retrieval Model • • Because we are multiplying query-term probabilities,  the longer the query, the lower the document scores  (from all documents) Is this a problem?', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  59 Query -Likelihood Retrieval Model • • • Because we are multiplying query-term probabilities,  the longer the query, the lower the document scores  (from all documents) Is this a problem? No, because we’re scoring documents for the same  query', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  60 Query -Likelihood Retrieval Model • • n score(Q, D) = P(Q|θD) = ∏P(qi|θD) i=1 There are (at least) two issues with this scoring function What are they?', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  61 Query -Likelihood Retrieval Model • • A document with a single missing query-term will  receive a score of zero (similar to boolean AND) Where is IDF? ‣ Don’t we want to suppress the contribution of terms  that are frequent in the document, but frequent in  general (appear in many documents)?', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Outline Introduction to language modeling  Language modeling for information retrieval  Query -likelihood Retrieval Model  Smoothing Pseudo-relevance feedback and priors', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  63 • When estimating probabilities, we tend to ... ‣ Over-estimate the probability of observed outcomes ‣ Under-estimate the probability of unobserved  outcomes • The goal of smoothing is to ... ‣ ‣ Decrease the probability of observed outcomes  Increase the probability of unobserved outcomes • • It’s usually a good idea You probably already know this concept! Smoothing Probability Estimates', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  66 P(RED) = 0.5 P(BLUE) = 0.25 P(ORANGE) = 0.25 P( YELLOW ) = 0.00 P(GREEN ) = 0.00 Smoothing Probability Estimates • • • Suppose that in reality this bag is a sample from a  different, bigger bag ... And, our goal is to estimate the probabilities of that  bigger bag ... And, we know that the bigger bag has red, blue, orange,  yellow, and green balls.', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  67 P(RED) = (10/20)   P(BLUE) = (5/20)   P(ORANGE) = (5/20)  P(YELLOW) = (0/20)  P(GREEN) = (0/20) Smoothing Probability Estimates • • Do we really want to assign YELLOWand GREENballs  a zero probability? What else can we do?', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  P(RED) = (11/25)   P(BLUE) = (6/25)   P(ORANGE) = (6/25)  P( YELLOW ) = (1/25)  P(GREEN ) = (1/25) 68 Add -One Smoothing • • • • We could add one ball of each color to the bag This gives a small probability to unobserved outcomes  (YELLOWand GREEN) As a result, it also reduces the probability of observed  outcomes (RED, BLUE, ORANGE) by a small amount Very common solution (also called ‘discounting’)', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  P(GREEN ) = (1/25) 69 Add -One Smoothing • Gives a small probability to unobserved outcomes  (YELLOWand GREEN) and reduces the probability of  observed outcomes (RED, BLUE, ORANGE) by a small amount P(RED) = (10/20)   P(BLUE) = (5/20)   P(ORANGE) = (5/20)  P(YELLOW) = (0/20)  P(GREEN) = (0/20) P(RED) = (11/25)   P(BLUE) = (6/25)   P(ORANGE) = (6/25)  P( YELLOW ) = (1/25)', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  70 • • Movie: Rocky (1976)  Plot: Rocky Balboa is a struggling boxer trying to make the big time. Working in a meat factory in Philadelphia for a  pittance, he also earns extra cash as a debt collector. When heavyweight champion Apollo Creed visits  Philadelphia, his managers want to set up an exhibition match between Creed and a struggling boxer, touting the  fight as a chance for a \"nobody\" to become a \"somebody\". The match is supposed to be easily won by Creed, but  someone forgot to tell Rocky, who sees this as his only shot at the big time. Rocky Balboa is a small-time boxer  who lives in an apartment in Philadelphia, Pennsylvania, and his career has so far not gotten off the canvas. Rocky  earns a living by collecting debts for a loan shark named Gazzo, but Gazzo doesn\\'t think Rocky has the  viciousness it takes to beat up deadbeats. Rocky still boxes every once in a while to keep his boxing skills sharp,  and his ex-trainer, Mickey, believes he could\\'ve made it to the top if he was willing to work for it. Rocky, goes to a  pet store that sells pet supplies, and this is where he meets a young woman named Adrian, who is extremely shy,  with no ability to talk to men. Rocky befriends her .Adrain later surprised Rocky with a dog from the pet shop that  Rocky had befriended. Adrian\\'s brother Paulie, who works for a meat packing company, is thrilled that someone  has become interested in Adrian, and Adrian spends Thanksgiving with Rocky. Later ,they go to Rocky\\'s apartment,  where Adrian explains that she has never been in a man\\'s apartment before. Rocky sets her mind at ease, and they  become lovers. Current world heavyweight boxing champion Apollo Creed comes up with the idea of giving an  unknown a shot at the title. Apollo checks out the Philadelphia boxing scene, and chooses Rocky. Fight promoter  Jergens gets things in gear, and Rocky startstraining with Mickey. After a lot of training, Rocky is ready for the  match, and he wants to prove that he can go the distance with Apollo. The \\'Italian Stallion\\', Rocky Balboa, is an  aspiring boxer in downtown Philadelphia. His one chance to make a betterlife for himself is through his boxing  and Adrian, a girl who works in the local pet store.Through a publicity stunt, Rocky is set up to fight Apollo Creed,  the current heavyweight champion who is already set to win. But Rocky really needs to triumph, against all the  odds... Smoothing Probability Estimates', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  71 • • • • • Smoothing Probability Estimates for document language models We can view a document as words sampled from the  author’s mind High-frequency words (e.g., rocky, apollo, boxing) are  important Low-frequency words (e.g., shot, befriended, checks) are  arbitrary The author chose these, but could have easily chosen  others So, we want to allocate some probability to unobserved  indexed-terms and discount some probability from those  that appear in the document', 'page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  72 • • • • In theory, we could use add-one smoothing To do this, we would add each indexed-term once into  each document ‣ Conceptually! Then, we would compute its language model  probabilities In practice, a more effective approach to smoothing for  information retrieval is called linear interpolation Smoothing Probability Estimates for document language models', 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  73 Linear Interpolation Smoothing • • • Let θD denote the language model associated with  document D Let θC denote the language model associated with the  entire collection Using linear interpolation, the probability given by the  document language model to term t is: P(t|D) = αP(t|θD) + (1 − α)P(t|θC)', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  74 Linear Interpolation Smoothing P(t|D) = αP(t|θD) + (1 − α)P(t|θC) the probabilitygiven  to the term by the  documentlanguage  model the probabilitygiven  to the term by the  collectionlanguage  model', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  75 Linear Interpolation Smoothing P(t|D) = αP(t|θD) + (1 − α)P(t|θC) everyoneof thesenumbers  is between0 and 1,so P(t|D)   is between0 and 1', 'page_label: 56 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • • As before, a document’s score is given by the probability  that it “generated” the query As before, this is given by multiplying the individual  query-term probabilities However, the probabilities are obtained using the  linearly interpolated language model 76 n score(Q, D) = ∏(αP(qi|θD) + (1 − α)P(qi|θC)) i=1 Query Likelihood Retrieval Model with linear interpolation smoothing', 'page_label: 57 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  • • • • Linear interpolation helps us avoid zero-probabilities Remember, because we’re multiplying probabilities, if a document is missing a single query-term it will be given a score of zero! Linear interpolation smoothing has another added  benefit, though it’s not obvious Let’s start with an example 77 Query Likelihood Retrieval Model with linear interpolation smoothing', 'page_label: 58 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  78 Query Likelihood Retrieval Model • • no smoothing Query: apple ipad Two documents (D1 and D2), each with 50 term  occurrences D1 (ND1=50) D2 (ND2=50) apple 2/50= 0.04 3/50= 0.06 ipad 3/50= 0.06 2/50= 0.04 score (0.04x 0.06) = 0.0024 (0.06x 0.04) = 0.0024', 'page_label: 59 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  79 Query Likelihood Retrieval Model • • no smoothing Query: apple ipad Two documents (D1 and D2), each with 50 term  occurrences • Whi ch query-term is more important: apple or ipad? D1 (ND1=50) D2 (ND2=50) apple 2/50= 0.04 3/50= 0.06 ipad 3/50= 0.06 2/50= 0.04 score (0.04x 0.06) = 0.0024 (0.06x 0.04) = 0.0024', 'page_label: 60 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  80 Query Likelihood Retrieval Model no smoothing • • A term is descriptive of the document if it occurs many  times in the document But, not if it occurs many times in the document and  also occurs frequently in the collection', 'page_label: 61 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  81 Query Likelihood Retrieval Model D1 (ND1=50) D2 (ND2=50) apple 2/50= 0.04 3/50= 0.06 ipad 3/50= 0.06 2/50= 0.04 score (0.04x 0.06) = 0.0024 (0.06x 0.04) = 0.0024 • • no smoothing Query: apple ipad Two documents (D1 and D2), each with 50 term  occurrences • Without smoothing, the query -likelihood model ignores  how frequently the term occurs in general!', 'page_label: 62 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  82 Query Likelihood Retrieval Model with linear interpolation smoothing • • • • Suppose the corpus has 1,000,000 term-occurrences apple occurs 200 / 1,000,000 times ipad occurs 100 / 1,000,000 times   Therefore: P(apple|θC) = 200 1000000 = 0.0002 P(ipad|θC) = 100 1000000 = 0.0001', 'page_label: 63 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  83 Query Likelihood Retrieval Model D1 (ND1=50) D2 (ND2=50) P(apple|D) 0.04 0.06 P(apple|C) 0.0002 0.0002 score(apple) 0.0201 0.0301 P(ipad|D) 0.06 0.04 P(ipad|C) 0.0001 0.0001 score(ipad) 0.03005 0.02005 totalscore 0.000604005 0.000603505 with linear interpolation smoothing n score(Q, D) = ∏(αP(qi|θD) + (1 − α)P(qi|θC)) i=1 α= 0.50', 'page_label: 64 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  84 Query Likelihood Retrieval Model with linear interpolation smoothing • • Linear interpolation smoothing does not only avoid zero  probabilities ... It also introduces an IDF -like scoring of documents ‣ • terms are that are less frequent in the entire  collection have a higher contribution to a document’s  score Yes, but we’ve only seen an example. Where is the  mathematical proof!?', 'page_label: 65 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  85 Query Likelihood Retrieval Model with linear interpolation smoothing', 'page_label: 66 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05-QueryLikelihoodModel(1).pdf  Extend the unigram model to  bigrams', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Parametric Language Modeling : Transformers', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Parametric Language Modeling•Can we do better than tf-idf?•We need parametric language modeling.•Set a learnable objective.•Use this objective to tune the parameters with gradience descent.•Question is – what network to use?•RNN?•Transformer?', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Lecture Plan 3 1.From recurrence (RNN) to attention-based NLP models2.Introducing the Transformer model3.Great results with Transformers', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  As oflastweek:recurrent models for (most) NLP!•Circa 2016, the de facto strategy in NLP is toencode sentences with a bidirectional LSTM:(for example, the source sentence in a translation) •Define your output (parse, sentence, summary) as a sequence, and use an LSTM to generate it. •Use attention to allow flexible access to memory 4', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Issues with recurrent models: Linear interaction distance•RNNs are unrolled “left-to-right”.•This encodes linear locality: a useful heuristic!•Nearby words often affect each other’s meanings•Problem: RNNs take O(sequence length) steps fordistant word pairs to interact.O(sequence length) tastypizza The chef who …  was 5', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Issues with recurrent models: Linear interaction distance•O(sequence length) steps for distant word pairs to interact means:•Hard to learn long-distance dependencies (because of gradient problems!)•Linear order of words is “baked in”; we already know linear order isn’t the right way to think about sentences… The chef who … was Info of chef has gone through O(sequence length) many layers!6', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Issues with recurrent models: Lack of parallelizability•Forward and backward passes have O(sequence length)unparallelizable operations•GPUs can perform a bunch of independent computations at once!•But future RNN hidden states can’t be computed in full before past RNNhidden states have been computed•Inhibits training on very large datasets! h1 h201  T hTT-1 1223 Numbers indicate min # of steps before a state can be computed7', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  If not recurrence, then what? How about attention?•Attention treats each word’s representation as a query to access and incorporate information from a set of values.•Number of unparallelizable operations does not increase sequence length.•Maximum interaction distance: O(1), since all words interact at every layer! attention embedding0 0 0 0 0 000h1h2 hT 2 222222 2attention1 1111111 All words attendto all words in previous layer; most arrows here are omitted8', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Self-Attention 11', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Self-attention as an NLP building block 𝑤1The 𝑞1𝑘1\\t 𝑣1 𝑤2chef 𝑞2 𝑤3who 𝑤𝑇food 𝑘𝑇𝑞𝑇𝑣𝑇… 𝑞1𝑘1\\t 𝑣1𝑘2𝑞2 𝑞3𝑣2\\t 𝑘3\\t 𝑣3 𝑘𝑇𝑞𝑇𝑣𝑇…self-attention𝑘2\\t 𝑣2\\t 𝑘3\\t𝑞3\\t𝑣3 •In the diagram at the right, we have stacked self-attention blocks, like we might stack LSTM layers.•Can self-attention be a drop-inreplacement for recurrence?•No. It has a few issues, whichwe’ll go through.•First, self-attention is an operation on sets. It has no inherent notion of order. self-attention Self-attention doesn’t know the order of its inputs.10', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order! Barriers and solutions for Self-Attention as a building blockSolutions 11', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Fixing the first self-attention problem: sequence order 12', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  •Pros:•Periodicity indicates that maybe “absolute position” isn’t as important•Maybe can extrapolate to longer sequences as periods restart!•Cons:•Not learnable; also the extrapolation doesn’t really work! •Sinusoidal position representations: concatenate sinusoidal functions of varying periods:sin(𝑖/100002∗1/𝑑)\\tcos(𝑖/100002∗1/𝑑)𝑝𝑖\\t= 𝑑 Position representation vectors through sinusoids sin(𝑖/100002∗2/𝑑) 𝑑cos(𝑖/100002∗2/𝑑) Image: https://timodenk.com/blog/linear-relationships-in-the-transformers-positional-encoding/ Index in the sequence Dimension 15', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  •Learned absolute position representations: Let all 𝑝𝑖\\tbe learnable parameters! Learn a matrix 𝑝\\t∈\\tℝ𝑑×𝑇, and let each 𝑝𝑖\\tbe a column of that matrix!•Pros:•Flexibility: each position gets to be learned to fit the data•Cons:•Definitely can’t extrapolate to indices outside 1,\\t…\\t,\\t𝑇.•Most systems use this!•Sometimes people try more flexible representations of position:•Relative linear position attention [Shaw et al., 2018]•Dependency syntax-based position [Wang et al., 2019]14 Position representation vectors learned from scratch', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order!•No nonlinearities for deeplearning! It’s all just weightedaverages Barriers and solutions for Self-Attention as a building blockSolutions•Add position representations to the inputs 15', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Adding nonlinearities in self-attention•Note that there are no elementwise nonlinearities in self-attention; stacking more self-attention layers just re-averages value vectors•Easy fix: add a feed-forward networkto post-process each output vector.𝑚𝑖\\t=\\t𝑀𝐿𝑃\\toutput𝑖=\\t𝑊2\\t∗\\tReLU\\t𝑊1\\t×\\toutput𝑖\\t+\\t𝑏1+\\t𝑏2 𝑤1The𝑤2chef𝑤3who𝑤𝑇food…Intuition: the FF network processes the result of attention FF FF FFself-attentionFF…FF FF FFself-attentionFF 16', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order!•No nonlinearities for deep learning magic! It’s all just weighted averages•Need to ensure we don’t “look at the future” when predicting a sequence•Like in machine translation•Or language modeling Barriers and solutions for Self-Attention as a building blockSolutions•Add position representations to the inputs•Easy fix: apply the same feedforward network to each self- attention output. 17', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Masking the future in self-attention•To use self-attention in decoders, we need to ensure we can’t peek at the future.•At every timestep, we could change the set of keys and queries to include only past words. (Inefficient!)•To enable parallelization, we mask out attention to future words by setting attention scores to −∞. \\t The chef [START] who −∞ For encoding these words We can look at these (not greyed out) words −∞\\t −∞\\t −∞−∞\\t −∞ −∞\\t −∞\\t −∞\\t −∞ 20 [The matrix of 𝑒𝑖𝑗\\tvalues]', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Masking the future in self-attention•To use self-attention in decoders, we need to ensure we can’t peek at the future.•At every timestep, we could change the set of keys and queries to include only past words. (Inefficient!)•To enable parallelization, we mask out attention to future words by setting attention scores to −∞. −∞−∞−∞−∞−∞−∞−∞−∞−∞ −∞ The chef who [START] For encoding these words We can look at these (not greyed out) words 19', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Barriers•Doesn’t have an inherentnotion of order!•No nonlinearities for deep learning magic! It’s all just weighted averages•Need to ensure we don’t “look at the future” when predicting a sequence•Like in machine translation•Or language modeling Barriers and solutions for Self-Attention as a building blockSolutions•Add position representations to the inputs•Easy fix: apply the same feedforward network to each self- attention output.•Mask out the future by artificiallysetting attention weights to 0! 20', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  •Self-attention:•the basis of the method.•Position representations:•Specify the sequence order, since self-attention is an unordered function of its inputs.•Nonlinearities:•At the output of the self-attention block•Frequently implemented as a simple feed-forward network.•Masking:•In order to parallelize operations while not looking at the future.•Keeps information about the future from “leaking” to the past.•That’s it! But this is not the Transformer model we’ve been hearing about.21 Necessities for a self-attention building block:', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Outline 22 1.From recurrence (RNN) to attention-based NLP models2.Introducing the Transformer model3.Great results with Transformers', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Transformer Encoder Word Embeddings Position Representations+[input sequence] WordEmbeddings PositionRepresentations+[output sequence] Transformer Decoder [decoder attends to encoder states] Transformer Decoder First, let’s look at the Transformer Encoder and Decoder Blocks at a high level[predictions!] 23', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] 24 Next, let’s look at the Transformer Encoder and Decoder BlocksWhat’s left in a Transformer Encoder Block that we haven’t covered?1.Key-query-value attention: How do we get the 𝑘,\\t𝑞,\\t𝑣\\tvectors from a single word embedding?2.Multi-headed attention: Attend to multiple places in a single layer!3.Tricks to help with training!1.Residual connections2.Layer normalization3.Scaling the dot product4.These tricks don’t improve what the model is able to do; they help improve the training process. Both of these types of modeling improvements are very important!', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Key-Query-Value Attention 25 •We saw that self-attention is when keys, queries, and values come from the samesource. The Transformer does this in a particular way:•Let 𝑥1,\\t…\\t,\\t𝑥𝑇\\tbe input vectors to the Transformer encoder; 𝑥𝑖\\t∈\\tℝ𝑑 •Then keys, queries, values are:•𝑘𝑖\\t=\\t𝐾𝑥𝑖, where 𝐾\\t∈\\tℝ𝑑×𝑑\\tis the key matrix.•𝑞𝑖\\t=\\t𝑄𝑥𝑖, where Q\\t∈\\tℝ𝑑×𝑑\\tis the query matrix.•𝑣𝑖\\t=\\t𝑉𝑥𝑖, where V\\t∈\\tℝ𝑑×𝑑\\tis the value matrix.•These matrices allow different aspects of the 𝑥\\tvectors to be used/emphasized in each of the three roles.', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Key-Query-Value Attention•Let’s look at how key-query-value attention is computed, in matrices.•Let 𝑋\\t=\\t𝑥1;\\t…\\t;\\t𝑥𝑇\\t∈\\tℝ𝑇×𝑑\\tbe the concatenation of input vectors.•First, note that 𝑋𝐾\\t∈\\tℝ𝑇×𝑑, 𝑋𝑄\\t∈\\tℝ𝑇×𝑑, 𝑋𝑉\\t∈\\tℝ𝑇×𝑑.⊤•The output is defined as output\\t=\\tsoftmax\\t𝑋𝑄\\t𝑋𝐾\\t ×\\t𝑋𝑉. = 𝑋𝑄𝐾⊤\\t𝑋⊤∈\\tℝ𝑇×𝑇All pairs of attention scores! output\\t∈\\tℝ𝑇×𝑑= 𝐾⊤\\t𝑋⊤𝑋𝑄First, take the query-key dot products in one matrixmultiplication: 𝑋𝑄\\t𝑋𝐾⊤ Next, softmax, and compute the weighted average with another matrix multiplication.𝑋𝑄𝐾⊤\\t𝑋⊤softmax 𝑋𝑉 26', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Multi-headed attention•What if we want to look in multiple places in the sentence at once?𝑖•For word 𝑖, self-attention “looks” where 𝑥⊤𝑄⊤𝐾𝑥𝑗\\tis high, but maybe we want 𝑑× to focus on different 𝑗\\tfor different reasons?•We’ll define multiple attention “heads” through multiple Q,K,V matrices𝑑•Let,\\t𝑄ℓ,\\t𝐾ℓ,\\t𝑉ℓ\\t∈\\tℝ\\tℎ, where ℎ\\tis the number of attention heads, and ℓ\\trangesfrom 1 to ℎ.•Each attention head performs attention independently:ℓ•outputℓ\\t=\\tsoftmax\\t𝑋𝑄ℓ𝐾⊤𝑋⊤\\t∗\\t𝑋𝑉ℓ, where outputℓ\\t∈\\tℝ𝑑/ℎ•Then the outputs of all the heads are combined!•output\\t=\\t𝑌[output1;\\t…\\t;\\toutputℎ], where 𝑌\\t∈\\tℝ𝑑×𝑑 •Each head gets to “look” at different things, and construct value vectorsdifferently.29', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Multi-headed attention•What if we want to look in multiple places in the sentence at once?𝑖•For word 𝑖, self-attention “looks” where 𝑥⊤𝑄⊤𝐾𝑥𝑗\\tis high, but maybe we want 𝑑× to focus on different 𝑗\\tfor different reasons?•We’ll define multiple attention “heads” through multiple Q,K,V matrices𝑑•Let,\\t𝑄ℓ,\\t𝐾ℓ,\\t𝑉ℓ\\t∈\\tℝ\\tℎ, where ℎ\\tis the number of attention heads, and ℓ\\trangesfrom 1 to ℎ. 𝑋𝑄=𝑋𝑄 Single-head attention(just the query matrix) 𝑋 Multi-head attention(just two heads here) 𝑄1\\t𝑄2\\t=𝑋𝑄1\\t𝑋𝑄2 Same amount of computation as single-head self- attention! 30', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Residual connections [He et al., 2016]•Residual connections are a trick to help models train better.•Instead of 𝑋(𝑖)\\t=\\tLayer(𝑋\\t𝑖−1\\t)\\t(where 𝑖\\trepresents the layer) •We let 𝑋(𝑖)\\t=\\t𝑋(𝑖−1)\\t+\\tLayer(𝑋\\t𝑖−1\\t)\\t(so we only have to learn “the residual”from the previous layer) •Residual connections are thought to make the loss landscape considerably smoother (thus easier training!) Layer𝑋(𝑖−1)\\t 𝑋(𝑖) Layer𝑋(𝑖−1)\\t 𝑋(𝑖)+ [no residuals] [residuals][Loss landscape visualization, Li et al., 2018, on a ResNet]31', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Layer normalization [Ba et al., 2016] ∗\\t𝛾\\t+\\t𝛽 Modulate by learned elementwise gain and bias32', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Layer normalization [Ba et al., 2016] 33', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Scaled Dot Product [Vaswani et al., 2017] 32', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Word Embeddings Position Representations+ Transformer Encoder [input sequence] Transformer Decoder WordEmbeddings PositionRepresentations+ Transformer Decoder [output sequence] [decoder attends to encoder states] Looking back at the whole model, zooming in on an Encoder block:[predictions!] 33', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] Word Embeddings Position Representations+ TransformerEncoder [input sequence] Transformer Decoder WordEmbeddings PositionRepresentations+ Transformer Decoder [output sequence] [decoder attends to encoder states] Looking back at the whole model, zooming in on an Encoder block: [predictions!] Multi-Head AttentionResidual + LayerNorm Feed-ForwardResidual + LayerNorm 34'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      "close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c6b1710>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c6b1710>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c6b1710>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x149790a70> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x149790a70> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x149790a70> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c9d33d0>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c9d33d0>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c9d33d0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'488'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'987539'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'747ms'), (b'x-request-id', b'req_afedf9d914e72d312c00e83c42c77fe7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Uym_hqRJ1QgUcRhs99_j4TThyk98EXdunMrbRO9k8Zk-1731474648-1.0.1.1-Q9G_5f63uiSrEzVlIytUjvfvg_xU9ZhFs2yqdHlF8VOv4IELUMwrn6embQmxVHdN7wK6MZmsNp4E1xS4gM__Lg; path=/; expires=Wed, 13-Nov-24 05:40:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c41e30884a083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'488'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'987539'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'747ms'), (b'x-request-id', b'req_afedf9d914e72d312c00e83c42c77fe7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Uym_hqRJ1QgUcRhs99_j4TThyk98EXdunMrbRO9k8Zk-1731474648-1.0.1.1-Q9G_5f63uiSrEzVlIytUjvfvg_xU9ZhFs2yqdHlF8VOv4IELUMwrn6embQmxVHdN7wK6MZmsNp4E1xS4gM__Lg; path=/; expires=Wed, 13-Nov-24 05:40:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c41e30884a083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'488'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'987539'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'747ms'), (b'x-request-id', b'req_afedf9d914e72d312c00e83c42c77fe7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Uym_hqRJ1QgUcRhs99_j4TThyk98EXdunMrbRO9k8Zk-1731474648-1.0.1.1-Q9G_5f63uiSrEzVlIytUjvfvg_xU9ZhFs2yqdHlF8VOv4IELUMwrn6embQmxVHdN7wK6MZmsNp4E1xS4gM__Lg; path=/; expires=Wed, 13-Nov-24 05:40:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c41e30884a083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '488', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '987539', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '747ms', 'x-request-id': 'req_afedf9d914e72d312c00e83c42c77fe7', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=Uym_hqRJ1QgUcRhs99_j4TThyk98EXdunMrbRO9k8Zk-1731474648-1.0.1.1-Q9G_5f63uiSrEzVlIytUjvfvg_xU9ZhFs2yqdHlF8VOv4IELUMwrn6embQmxVHdN7wK6MZmsNp4E1xS4gM__Lg; path=/; expires=Wed, 13-Nov-24 05:40:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c41e30884a083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '488', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '987539', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '747ms', 'x-request-id': 'req_afedf9d914e72d312c00e83c42c77fe7', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=Uym_hqRJ1QgUcRhs99_j4TThyk98EXdunMrbRO9k8Zk-1731474648-1.0.1.1-Q9G_5f63uiSrEzVlIytUjvfvg_xU9ZhFs2yqdHlF8VOv4IELUMwrn6embQmxVHdN7wK6MZmsNp4E1xS4gM__Lg; path=/; expires=Wed, 13-Nov-24 05:40:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c41e30884a083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '488', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '987539', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '747ms', 'x-request-id': 'req_afedf9d914e72d312c00e83c42c77fe7', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=Uym_hqRJ1QgUcRhs99_j4TThyk98EXdunMrbRO9k8Zk-1731474648-1.0.1.1-Q9G_5f63uiSrEzVlIytUjvfvg_xU9ZhFs2yqdHlF8VOv4IELUMwrn6embQmxVHdN7wK6MZmsNp4E1xS4gM__Lg; path=/; expires=Wed, 13-Nov-24 05:40:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c41e30884a083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_afedf9d914e72d312c00e83c42c77fe7\n",
      "request_id: req_afedf9d914e72d312c00e83c42c77fe7\n",
      "request_id: req_afedf9d914e72d312c00e83c42c77fe7\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96b560>, 'json_data': {'input': ['page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Word Embeddings Position Representations+ [input sequence]WordEmbeddings PositionRepresentations+ Looking back at the whole model, zooming in on a Decoder block:Transformer Encoder [output sequence] [predictions!]Transformer DecoderResidual + LayerNorm Feed-Forward Residual + LayerNormMulti-Head Cross-Attention Residual + LayerNormMasked Multi-Head Self-Attention 35', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Word Embeddings Position Representations+ [input sequence]WordEmbeddings PositionRepresentations+ Transformer Decoder The only new part is attention from decoder to encoder. Like Transformer Encoder [output sequence] [predictions!] Residual + LayerNormFeed-ForwardResidual + LayerNorm Multi-Head Cross-AttentionResidual + LayerNormMasked Multi-Head Self-Attention 36', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Decoder: Cross-attention (details) 37 •We saw that self-attention is when keys, queries, and values come from the samesource.•In the decoder, we have attention that looks more like what we saw last week.•Let ℎ1,\\t…\\t,\\tℎ𝑇\\tbe output vectors from the Transformer encoder; 𝑥𝑖\\t∈\\tℝ𝑑•Let 𝑧1,\\t…\\t,\\t𝑧𝑇\\tbe input vectors from the Transformer decoder, 𝑧𝑖\\t∈\\tℝ𝑑•Then keys and values are drawn from the encoder (like a memory):•𝑘𝑖\\t=\\t𝐾ℎ𝑖, 𝑣𝑖\\t=\\t𝑉ℎ𝑖.•And the queries are drawn from the decoder, 𝑞𝑖\\t=\\t𝑄𝑧𝑖.', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Cross-attention (details)•Let’s look at how cross-attention is computed, in matrices.•Let H\\t=\\tℎ1;\\t…\\t;\\tℎ𝑇•Let Z\\t=\\t𝑧1;\\t…\\t;\\t𝑧𝑇∈\\tℝ𝑇×𝑑\\tbe the concatenation of encoder vectors.∈\\tℝ𝑇×𝑑\\tbe the concatenation of decoder vectors.⊤•The output is defined as output\\t=\\tsoftmax\\t𝑍𝑄\\t𝐻𝐾\\t ×\\t𝐻𝑉. = 𝑍𝑄𝐾⊤\\t𝐻⊤∈\\tℝ𝑇×𝑇All pairs of attention scores! output\\t∈\\tℝ𝑇×𝑑= 𝐾⊤\\t𝐻⊤𝑍𝑄First, take the query-key dot products in one matrixmultiplication: 𝑍𝑄\\t𝐻𝐾⊤ Next, softmax, and compute the weighted average with another matrix multiplication.𝑍𝑄𝐾⊤\\t𝐻⊤softmax 𝐻𝑉 38', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Outline 39 1.From recurrence (RNN) to attention-based NLP models2.Introducing the Transformer model3.Great results with Transformers', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Great Results with Transformers Not just better Machine Also more efficient toTranslation BLEU scores train! First, Machine Translation from the original Transformers paper! [Vaswani et al., 2017][Test sets: WMT 2014 English-German and English-French]40', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Great Results with Transformers Transformers all the way down. Next, document generation! The old standard [Liu et al., 2018]; WikiSum dataset41', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Great Results with Transformers [Liu et al., 2018] Before too long, most Transformers results also included pretraining.Transformers’ parallelizability allows for efficient pretraining, and have made them the de-facto standard.On this popular aggregatebenchmark, for example: All top models are Transformer (and pretraining)-based.More results Thursday when we discuss pretraining.44', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Information Retrieval  and Web Search IR Evaluation and  IR Standard Text Collections', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  IR Evaluation Measures 1) How fast does it index? – Number of bytes per second. 2) How fast does it search? – Latency as a function of queries per second. 3) What is the cost per query? – $/query. 4) What is the level of user happiness? – How can we quantify user happiness? measurable', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  User Happiness • Who is the user we are trying to make happy? – Web search engine: searcher. Success: Searcher ﬁnds  what she was looking for. Measure: rate of return to  this search engine. – Web search engine: advertiser. Success: Searcher  clicks on ad. Measure: clickthrough rate. – Ecommerce: seller. Success: Buyer buys something.  Measures: time to purchase, fraction of “conversions”  of searchers to buyers. – Ecommerce: seller. Success: Seller sells something.  Measure: proﬁt per item sold.', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Relevance as Proxy for User Happiness • User happiness ≈ the relevance of search results. • Relevance is assessed relative to the user need, not the  query. – Note: user need is translated into a query. – Information need: I am looking for information on  whether drinking red wine is more effective at reducing  your risk of heart attacks than white wine. – Query: red wine white wine heart attack – Assess whether the retrieved document addresses  the underlying need, not whether it has these words. • Binary Assessments: Relevant or Nonrelevant.', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Standard Methodology for Measuring  Relevance in IR • To measure relevance effectiveness of ad-hoc IR, we  need: 1. A document collection. 2. A suite of information needs, expressible as  queries. • Must be representative of actual user needs. • Sample from query logs, if available. 3. Binary assessments of either Relevant or  Nonrelevant for each query and each document. • Can be more nuanced, e.g., 0, 1, 2, 3, … • Use pooling, when it is unfeasible to assess every (q, d)  pair.', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Why System Evaluations? • Is a retrieval system producing the expected results? • There are many retrieval models/ algorithms/ systems,  which one is the best? • What is the best component for: – Ranking function (inner-product, cosine, …) – Term selection (stopword removal, stemming…) – Term weighting (TF, TF-IDF,…) • For a fair comparison: – Should be all evaluated using the same measures – Should be all evaluated on the same collection of documents – Should be all evaluated on the same set of questions', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  documents relevant of number Total retrieved documents relevant of Number  recall = retrieved  documents of number Total retrieved  documents relevant of  Number  precision = Relevant  documents Retrieved  documents Entire document  collection retrieved &  relevant not retrieved but  relevant retrieved &  irrelevant Not retrieved &  irrelevant retrieved not retrieved relevant irrelevant Precision and Recall', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Precision and Recall • Precision vs. Recall: – Precision = The ability to retrieve top-ranked documents that  are mostly relevant. – Recall = The ability of the search to find all of the relevant items  in the corpus. • Determining Recall can be difficult • Total number of  relevant items is sometimes not  available – use pooling – Sample across the database and perform relevance judgment  on these items. – Apply different retrieval algorithms to the same database for the  same query. The aggregate of relevant items is taken as the  total relevant set.', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Trade-off between Recall and Precision 10 1 Recall Precision The ideal Returns relevant documents but misses many useful ones too Returns most relevant documents but also  includes lots of   Irrelevant documents  Precision and Recall are inverse proportional', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  F-measure • One measure of performance that takes into account  both recall and precision. • Harmonic mean of recall and precision: • Compared to arithmetic mean, both need to be high for  harmonic mean to be high. PRRP PRF 11 22 + =+=', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Ranked Retrieval Measures • Binary relevance: – 11-point Interpolated Precision-Recall Curve – R-precision – Precision@K (P@K) and Recall@K (R@K) – Mean Average Precision (MAP) – Mean Reciprocal Rank (MRR) • Multiple levels of relevance: – Normalized Discounted Cumulative Gain (NDCG)', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  R=3/6=0.5;     P=3/4=0.75 Recall-Precision Curves An Example n doc # relevant 1 588 x 2 589 x 3 576 4 590 x 5 986 6 592 x 7 984 8 988 9 578 10 985 11 103 12 591 13 772 x 14 990 Let total # of relevant docs = 6 Check each new recall point: R=1/6=0.167; P=1/1=1 R=2/6=0.333; P=2/2=1 R=5/6=0.833; p=5/13=0.38 R=4/6=0.667; P=4/6=0.667 Missing one  relevant document. Never reach  100% recall', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Interpolating a  Recall/Precision Curve • Interpolate a precision  value for each standard  recall level: – rj = {0.0, 0.1, 0.2, 0.3,  0.4, 0.5, 0.6, 0.7, 0.8,  0.9, 1.0} – r0 = 0.0, r1 = 0.1, …,  r10=1.0', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Interpolating a Recall/Precision Curve Rationale for interpolation: The user is willing  to look at more stuff if both precision and  recall get better.', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Interpolating a Recall/Precision Curve • Compute interpolated  precision at recall  levels 0.0, 0.1, 0.2, . . . • Do this for each of the  queries in the  evaluation benchmark • Average over queries  The curve is typical of  performance levels at  TREC (more later).', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 1,  measured data points', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 1,  measured data points interpolation', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 2,  measured data points', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 2,  interpolation', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: averaging', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: area/result', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Accuracy • Why do we use complex measures like precision, recall,  and F?  • Why not something simple like accuracy?  • Accuracy is the fraction of decisions  (relevant/nonrelevant) that are correct.  • In terms of the contingency table above, accuracy = (TP  + TN)/(TP + FP + FN + TN).', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Accuracy • Simple trick to maximize accuracy in IR: always say no  and return nothing You then get 99.99% accuracy on  most queries.  • Searchers on the web (and in IR in general) want to find  something and have a certain tolerance for junk.  • It’s better to return some bad hits as long as you return  something.  – → We use precision, recall, and F for evaluation, not accuracy.', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Recall-criticality and precision-criticality • Inverse relationship between precision and recall forces  general systems to go for compromise between them. • But some tasks particularly need good precision  whereas others need good recall:', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Recall-criticality and precision-criticality', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Average Recall/Precision Curve • Typically average performance over a large set of  queries. • Compute average precision at each standard recall level  across all queries. • Plot average precision/recall curves to evaluate overall  system performance on a document/query corpus. • Average: – Micro-average: compute P/R/F once for the entire set of queries  – Macro-average: average of within-query precision/recall', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  How To Compare  Two or More Systems • The curve closest to the upper right-hand corner of  the graph indicates the best performance 0 0.2 0.4 0.6 0.8 1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Recall Precision NoStem Stem', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  R-precision • Precision at the R-th position in the ranking of results  for a query that has R relevant documents. n doc # relevant 1 588 x 2 589 x 3 576 4 590 x 5 986 6 592 x 7 984 8 988 9 578 10 985 11 103 12 591 13 772 x 14 990 What can we tell about the precision  and recall measures at the R-th  position in the ranking? A) Precision is smaller than recall B) Precision is larger than recall C) Precision and recall are the same', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  R-precision • Precision at the R-th position in the ranking of results  for a query that has R relevant documents. n doc # relevant 1 588 x 2 589 x 3 576 4 590 x 5 986 6 592 x 7 984 8 988 9 578 10 985 11 103 12 591 13 772 x 14 990 R = # of relevant docs = 6 R-Precision = 4/6 = 0.67', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Precision@K 1. Set a rank threshold K. 2. Compute % of documents relevant in top K. – Ignores documents ranked lower than K. • Example: – Prec@3 of 2/3 – Prec@4 of 2/4 – Prec@5 of 3/5 • In a similar way we have Recall@K', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Average Precision (MAP) 1. Consider rank position of each of the R relevant docs: – K1, K2, … KR 2. Compute Precision@K for each K1, K2, … KR. 3. Average precision = average of P@K.       Example:               has AvgPrec of • MAP is Average Precision across multiple queries. 76.05 3 3 2 1 1 3 1 \\uf0bb\\uf0f7 \\uf0f8 \\uf0f6\\uf0e7 \\uf0e8 \\uf0e6 ++\\uf0d7', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Exercise: Average Precision Assume a query with six relevant documents, and two systems that produce the following two rankings.  Which system is better according to the average precision?', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Average Precision (MAP) Average precision query 1 = (1.0+0.67+0.5+0.44+0.5)/5 = 0.62 Average precision query 2 = (0.5+0.4+0.43)/3 = 0.44 MAP = (0.62 + 0.44)/2 = 0.53', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Average Precision (MAP) • If a relevant document never gets retrieved, we assume  the precision corresponding to that relevant document  to be zero.  • MAP is macro-averaging: each query counts equally. • A commonly used measure in current IR research, along  with P/R/F', 'page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Reciprocal Rank • Consider rank position, K, of first relevant doc – Could be only clicked doc • Reciprocal Rank score = • MRR is the mean RR across multiple queries   K 1', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Multiple Levels of Relevance • Documents are rarely entirely relevant or non-relevant  to a query. • Many sources of graded relevance judgments: – Relevance judgments on a 5-point scale. – Averaging among multiple judges.', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Cummulative Gain • With graded relevance  judgments, we can compute  the gain at each rank. • Cumulative Gain at rank n: – Where reli is the graded  relevance of the document at  position i. n doc # relevance  (gain) CGn 1 588 1.0 1.0 2 589 0.6 1.6 3 576 0.0 1.6 4 590 0.8 2.4 5 986 0.0 2.4 6 592 1.0 3.4 7 984 0.0 3.4 8 988 0.0 3.4 9 578 0.0 3.4 10 985 0.0 3.4 11 103 0.0 3.4 12 591 0.0 3.4 13 772 0.2 3.6 14 990 0.0 3.6', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Discounted Cumulative Gain • Users care more about high- ranked documents, so we  discount results by  1/log2(rank) • Popular measures for  evaluating web search and  related tasks. • Discounted Cumulative Gain: n doc # rel  (gain) CGn logn DCGn 1 588 1.0 1.0 - 1.00 2 589 0.6 1.6 1.00 1.60 3 576 0.0 1.6 1.58 1.60 4 590 0.8 2.4 2.00 2.00 5 986 0.0 2.4 2.32 2.00 6 592 1.0 3.4 2.58 2.39 7 984 0.0 3.4 2.81 2.39 8 988 0.0 3.4 3.00 2.39 9 578 0.0 3.4 3.17 2.39 10 985 0.0 3.4 3.32 2.39 11 103 0.0 3.4 3.46 2.39 12 591 0.0 3.4 3.58 2.39 13 772 0.2 3.6 3.70 2.44 14 990 0.0 3.6 3.81 2.44', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Normalized Discounted  Cumulative Gain (NDCG) • To compare DCGs, normalize values so that an ideal  ranking would have a Normalized DCG of 1.0. • Ideal ranking: n doc # rel  (gain) CGn logn DCGn 1 588 1.0 1.0 0.00 1.00 2 589 0.6 1.6 1.00 1.60 3 576 0.0 1.6 1.58 1.60 4 590 0.8 2.4 2.00 2.00 5 986 0.0 2.4 2.32 2.00 6 592 1.0 3.4 2.58 2.39 7 984 0.0 3.4 2.81 2.39 8 988 0.0 3.4 3.00 2.39 9 578 0.0 3.4 3.17 2.39 10 985 0.0 3.4 3.32 2.39 11 103 0.0 3.4 3.46 2.39 12 591 0.0 3.4 3.58 2.39 13 772 0.2 3.6 3.70 2.44 14 990 0.0 3.6 3.81 2.44 n doc # rel  (gain) CGn logn IDCGn 1 588 1.0 1.0 0.00 1.00 2 592 1.0 2.0 1.00 2.00 3 590 0.8 2.8 1.58 2.50 4 589 0.6 3.4 2.00 2.80 5 772 0.2 3.6 2.32 2.89 6 576 0.0 3.6 2.58 2.89 7 986 0.0 3.6 2.81 2.89 8 984 0.0 3.6 3.00 2.89 9 988 0.0 3.6 3.17 2.89 10 578 0.0 3.6 3.32 2.89 11 985 0.0 3.6 3.46 2.89 12 103 0.0 3.6 3.58 2.89 13 591 0.0 3.6 3.70 2.89 14 990 0.0 3.6 3.81 2.89', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Normalized Discounted  Cumulative Gain (NDCG) • Normalize by DCG of the  ideal ranking: – NDCG ≤ 1 at all ranks. • NDCG is now comparable  across different queries: – Useful for contrasting  queries with varying  numbers of relevant results. – Quite popular for Web  search.', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Evaluation with Clickthrough Data # of clicks received Strong position bias, so absolute click rates unreliable', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Pairwise Relative Ratings • Pairs of the form: DocA better than DocB for a query – Doesn’t mean that DocA relevant to query • Rather than assess a rank-ordering with respect to per- doc relevance assessments • Assess in terms of conformance with historical pairwise  preferences recorded from user clicks', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Comparing two rankings to a baseline  ranking • Given a set of pairwise preferences P • We want to measure two rankings A and B • Define a proximity measure between A and P – And likewise, between B and P • Want to declare the ranking with better proximity to be  the winner • Proximity measure should reward agreements with P  and penalize disagreements', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Kendall-tau Distance to Compare Rankings • Generate all pairs for each ranking • Let X be the number of agreements between a ranking  (say A) and P • Let Y be the number of disagreements • Then the Kendall tau distance between A and P is  (X-Y)/(X+Y)', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Exercise • Assume perfect ranking P = (1, 2, 3, 4) • Assume two candidate rankings A = (1, 3, 2, 4) and B =  (4, 1, 2, 3) • Which candidate ranking is closer to the perfect ranking  according to Kendall-tau?', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  A/B Testing at Web Search Engines  • Can exploit an existing user base to provide useful  feedback on a single innovation • Randomly send a small fraction (1−10%) of incoming  users to a variant of the system that includes a single  change. – Have most users use the old system • Judge effectiveness by measuring change in clickthrough:  the percentage of users that click on the top result (or  any result on the first page) • Probably the evaluation methodology that large search  engines trust the most', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Amazon Mechanical Turk Testing • https://requester.mturk.com/', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Standard Methodology for Measuring  Relevance in IR • To measure relevance effectiveness of ad-hoc IR, we  need: 1. A document collection. 2. A suite of information needs, expressible as  queries. • Must be representative of actual user needs. • Sample from query logs, if available. 3. Binary assessments of either Relevant or  Nonrelevant for each query and each document. • Can be more nuanced, e.g., 0, 1, 2, 3, … • Use pooling, when it is unfeasible to assess every (q, d)  pair.', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Early Test Collections • Previous experiments were based on the SMART  collection which is fairly small.  (ftp://ftp.cs.cornell.edu/pub/smart)      Collection Number Of Number Of Raw Size       Name   Documents Queries  (Mbytes)       CACM 3,204    64  1.5       CISI  1,460  112  1.3       CRAN  1,400  225  1.6       MED  1,033    30  1.1       TIME    425    83  1.5  • Different researchers used different test collections and  evaluation techniques.', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  The TREC Benchmark • TREC: Text REtrieval Conference (http://trec.nist.gov/) – Originated from the TIPSTER program sponsored by Defense  Advanced Research Projects Agency (DARPA). – Became an annual conference in 1992, co-sponsored by the      National Institute of Standards and Technology (NIST) and   DARPA. – Participants are given parts of a standard set of documents and  TOPICS (from which queries have to be derived) in  different  stages for training and testing. – Participants submit the P/R values for the final document and  query corpus and present their results at  the conference.', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  TREC Objectives • Provide a common ground for comparing different IR  techniques. – Same set of documents and queries, and same evaluation  method • Sharing of resources and experiences in developing the  benchmark. – With major sponsorship from government to develop large  benchmark collections • Encourage participation from industry and academia. • Development of new evaluation techniques, particularly  for new applications. – Retrieval, routing/filtering, non-English collection, web-based  collection, question answering', 'page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  TREC Advantages • Large scale (compared to a few MB in the SMART  Collection). • Relevance judgments provided. • Under continuous development with support from the  U.S. Government. • Wide participation: – TREC 1: 28 papers 360 pages. – TREC 4: 37 papers 560 pages. – TREC 7: 61 papers 600 pages.  – TREC 8: 74 papers.', 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  TREC Tasks • Ad hoc: New questions are being asked on a static set  of data.  • Routing: Same questions are being asked, but new  information is being searched. (news clipping, library  profiling). • New tasks added after TREC 5: – Interactive, multilingual, natural language, multiple database  merging, filtering, very large corpus (20 GB, 7.5 million  documents), question answering.', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  The TREC Collection • Both long and short documents (from a few hundred  to over one thousand unique terms in a document). – Both SGML documents and SGML queries contain many  different kinds of information (fields). – Generation of the formal queries (Boolean, Vector Space,  etc.) is the responsibility of the system. • A system may be very good at ranking, but if it generates poor  queries from the topic, its final P/R would be poor. • Test documents consist of:      WSJ Wall Street Journal articles (1986 -1992)  550 M       AP   Associate Press Newswire (1989)     514 M      ZIFF Computer Select Disks (Ziff -Davis Publishing) 493 M       FR   Federal Register    469 M       DOE Abstracts from Department of Energy reports 190 M', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Sample SGML Document <DOC>  <DOCNO> WSJ870324-0001 </DOCNO>  <HL> John Blair Is Near Accord To Sell Unit, Sources Say </HL>  <DD> 03/24/87</DD>  <SO> WALL STREET JOURNAL (J) </SO> <IN> REL TENDER OFFERS, MERGERS, ACQUISITIONS (TNM) MARKETING,  ADVERTISING (MKT) TELECOMMUNICATIONS, BROADCASTING,  TELEPHONE, TELEGRAPH (TEL) </IN>  <DATELINE> NEW YORK </DATELINE>  <TEXT>      John Blair &amp; Co. is close to an agreement to sell its TV station  advertising representation operation and program production unit to an  investor group led by James  H. Rosenfield, a former CBS Inc. executive,  industry sources said. Industry sources put the value of the proposed  acquisition at more than $100 million. ...  </TEXT>  </DOC>', \"page_label: 56 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Sample SGML Query <top>  <head> Tipster Topic Description  <num> Number: 066  <dom> Domain: Science and Technology  <title> Topic: Natural Language Processing  <desc> Description: Document will identify a type of natural language  processing technology which is being developed or marketed in the U.S.  <narr> Narrative: A relevant document will identify a company or institution  developing or marketing a natural language processing technology, identify  the technology, and identify one of more features of the company's  product. <con> Concept(s):  1. natural language processing ;2. translation, language,  dictionary <fac> Factor(s):  <nat> Nationality: U.S.</nat> </fac>  <def> Definitions(s):  </top>\", 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  INFORMATION RETRIEVAL  Soujanya Poria', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Syllabus•Week 1 – Introduction to IR, Boolean and ranked retrieval.•Week 2 – Locally Sensitive Hashing•Week 3 –  Probabilistic IR / BM-25•Week 4 – Relevance feedback and IR Evaluation•Week 5 – Index Creation & Compression•Week 6 – Transformers and Language Models•Week 7 – Term Break•Week 8 – Midterm•Week 9 – Knowledge guided retrieval from LLM', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Syllabus•Week 10 – Learning to Rank•Week 11 – LLM-based IR’s Safety Measurement•Week 12 – Pagerank Algorithm•Week 13 – Project Presentation', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Words of Wisdom!•I have just crossed my 30  😁 – stop calling me Prof. Call me SJ. How cool it is  😁•My handwriting is horrible  🥲–Tell me when you do not understand what I wrote on the whiteboard.•Getting good marks is super easy!–Focus on learning and applying new things.•Ask me 100 of questions!', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  What can you expect in this course?•You use Google everyday: learn how it works!•Learn how the new Bing search works!•Learn how you can use machine learning and AI tools to mine your desired information from the web!•Clear your misconception: IR is not just web scraping!•Opportunity to participate in cool projects!', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Book to readhttp://nlp.stanford.edu/IR-book/pdf/00front.pdf', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  INFORMATION RETRIEVAL Boolean retrieval', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Typical IR task•Input:–A large collection of unstructured text documents.–A user query expressed as text.•Output:–A ranked list of documents that are relevant to the query. IR SystemQuery String DocumentcorpusRankedDocuments1. Doc12. Doc23. Doc3    .    .', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Generative IR task•Input:–A large collection of unstructured text documents.–A user query expressed as text.•Output:–A textual response with user’s desired information.', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Boolean  Typical IR task•Input:–A large collection of unstructured text documents.–A user query expressed as text.•Output:–A ranked list of documents that are relevant to the query. IR SystemQuery String DocumentcorpusRankedDocuments1. Doc12. Doc23. Doc3    .    .', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Boolean retrieval•Information Need: Which plays by Shakespeare mention Brutus and Caesar, but not Calpurnia?•Boolean Query: Brutus AND Caesar AND NOT Calpurnia•Possible search procedure:–Linear scan through all documents (Shakespeare’s collected works).–Compile list of documents that contain Brutus and Caesar, but not Calpurnia.–Advantage: simple, it works for moderately sized corpora.–Disadvantage: need to do linear scan for every query Þ slow for large corpora.', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Term-document incidence matrices Antony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony1 1 0 0 0 1Brutus1 1 0 1 0 0Caesar1 1 0 1 1 1Calpurnia0 1 0 0 0 0Cleopatra1 0 0 0 0 0mercy1 0 1 1 1 1worser1 0 1 1 1 0 1 if document contains word, 0 otherwise •Precompute a data structure that makes search fast for every query.', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Term-document incidence matrix M Brutus AND Caesar AND NOT CalpurniaQuery =  Antony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony1 1 0 0 0 1Brutus1 1 0 1 0 0Caesar1 1 0 1 1 1Calpurnia0 1 0 0 0 0Cleopatra1 0 0 0 0 0mercy1 0 1 1 1 1worser1 0 1 1 1 0 Answer = M(Brutus) Ù M(Caesar) Ù¬ M(Calpurnia) = 1 1 0 1 0 0 Ù 1 1 0 1 1 1 Ù 1 0 1 1 1 1 = 1 0 0 1 0 0 Þ Anthony and Cleopatra, Hamlet       110100 Ù110111 Ù101111100100', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Answers to Query•Antony and Cleopatra, Act III, Scene ii Agrippa [Aside to DOMITIUS ENOBARBUS]: Why, Enobarbus,                           When Antony found Julius Caesar dead,                             He cried almost to roaring; and he wept                            When at Philippi he found Brutus slain. •Hamlet, Act III, Scene ii Lord Polonius: I did enact Julius Caesar I was killed i’ the      Capitol; Brutus killed me.', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Scalability: Dense Format•Assume:–Corpus has 1 million documents.–Each document is about 1,000 words long.–Each word takes 6 bytes, on average.–Of  the 1 billion word tokens 500,000 are unique. •Then:–Corpus storage takes:•1M * 1, 000 * 6 = 6GB–Term-Document incidence matrix would take:•500,000 * 1,000,000 = 0.5 * 1012 bits', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Scalability: Sparse Format•Of the 500 billion entries, at most 1 billion are non-zero.Þ at least 99.8% of the entries are zero.Þ use a sparse representation to reduce storage size! •Store only non-zero entries Þ Inverted Index.', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index for Boolean Retrieval •Map each term to a posting list of documents containing  it–Identify each document by a numerical docID.–Dictionary of terms usually in memory.–Posting list:•linked lists of variable-sized array, if in memory.•contiguous run of postings, if on disk.Brutus CalpurniaCaesar124561657132124113145173 231 174 54101 DictionaryPostings', \"page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 1•Assemble sequence of átoken, docIDñ pairs.–assume text has been tokenized  17 I did enact JuliusCaesar I was killed i' the Capitol; Brutus killed me. Doc 1 So let it be withCaesar. The nobleBrutus hath told youCaesar was ambitious Doc 2\", 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 2•Sort by terms, then by docIDs.', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 3•Merge multiple term entries per document.•Split into dictionary and posting lists.–keep posting lists sorted, for efficient query processing. •Add document frequency information:–useful for efficient query processing.–also useful later in document ranking.', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 3', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Processing: AND•Consider processing the query:Brutus AND Caesar–Locate Brutus in the Dictionary;•Retrieve its postings.–Locate Caesar in the Dictionary;•Retrieve its postings.–“Merge” the two postings (intersect the document sets): 1283424816326412358132128 BrutusCaesar', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Processing: AND Merge Algorithm', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Processing: OR•Exercise: Adapt the merge algorithm for the query: Brutus OR Caesar', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Optimization:What is the best order for query processing?•Consider a query that is an AND of n terms.1283424 8163264123581321BrutusCaesarCalpurnia1316 Query: Brutus AND Calpurnia AND Caesar –  For each of the n terms, get its postings, then AND them together.–  Process in order of increasing freq:•  start with smallest set, then keep cutting further.•  use document frequencies stored in the dictionary.Þ execute the query as (Calpurnia AND Brutus) AND Caesar', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Optimization•Exercise: recommend a query processing order for:–(tangerine OR trees) AND    (marmalade OR skies) AND    (kaleidoscope OR eyes)–which two terms should we process first? Term Freq     eyes 213312   kaleidoscope 87009   marmalade 107913   skies 271658   tangerine 46653   trees 316812', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  INFORMATION RETRIEVAL IR models: Vector Space Model', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Information Retrieval  and Web SearchIR models: Vector Space Model [Note: Some slides in this set were adapted from an IR course taught by Ray Mooney at UT Austin (who in turn adapted them from Joydeep Ghosh), and from an IR course taught by Chris Manning at Stanford)', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Ranked Retrieval•Thus far, our queries have all been Boolean–Documents either match or don’t•Good for expert users with precise understanding of their needs and the collection–Also good for applications: Applications can easily consume 1000s of results•Not good for the majority of users–Most users incapable of writing Boolean queries (or they are, but they think it’s too much work)–Most users don’t want to wade through 1000s of results•This is particularly true of Web search Ch. 6', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Problem with Boolean Search•Boolean queries often result in either too few (=0) or too many (1000s) results.•Query 1: “standard user dlink 650” → 200,000 hits•Query 2: “standard user dlink 650 no card found”: 0 hits•It takes a lot of skill to come up with a query that produces a manageable number of hits.–AND gives too few; OR gives too many•Hard to tune precision vs. recall:–AND operator tends to produce high precision but low recall.–OR operator gives low precision but high recall.–Difficult/impossible to find satisfactory middle ground. Ch. 6', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Ranked Retrieval Models•Rather than a set of documents satisfying a query expression, in ranked retrieval, the system returns an ordering over the (top) documents in the collection for a query•Free text queries: Rather than a query language of operators and expressions, the user’s query is just one or more words in a human language•In principle, there are two separate choices here, but in practice, ranked retrieval has normally been associated with free text queries and vice versa', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Not a Problem in Ranked Retrieval•When a system produces a ranked result set, large result sets are not an issue–Indeed, the size of the result set is not an issue–We just show the top k ( ≈ 10) results–We don’t overwhelm the user–Premise: the ranking algorithm works Ch. 6', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Scoring as the Basis of Ranked Retrieval•We wish to return in order the documents most likely to be useful to the searcher•How can we rank-order the documents in the collection with respect to a query?•Assign a score – say in [0, 1] – to each document•This score measures how well the document and the query “match” Ch. 6', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Query-document Matching Scores•We need a way of assigning a score to a query/document pair•Let’s start with a one-term query•If the query term does not occur in the document: score should be 0•The more frequent the query term in the document, the higher the score (should be)', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Take 1: Jaccard coefficient•Jaccard: A commonly used measure of overlap of two sets A and B•Jaccard(A,B) = |A ∩ B| / |A ∪ B|•Jaccard(A,A) = 1•Jaccard(A,B) = 0 if A ∩ B = 0•A and B don’t have to be the same size.•Always assigns a number between 0 and 1. Ch. 6', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Jaccard Coefficient: Scoring ExampleAssume the following query:•Query: march of dimesAnd the following two documents:•Document 1: caesar died in march•Document 2: the long march Ch. 6 According to the Jaccard coeficient, which document is more similar to the query (assume no stopword removal):A)Doc 1 B)Doc 2C)Both documents have the same similarity'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96b560>, 'json_data': {'input': ['page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Word Embeddings Position Representations+ [input sequence]WordEmbeddings PositionRepresentations+ Looking back at the whole model, zooming in on a Decoder block:Transformer Encoder [output sequence] [predictions!]Transformer DecoderResidual + LayerNorm Feed-Forward Residual + LayerNormMulti-Head Cross-Attention Residual + LayerNormMasked Multi-Head Self-Attention 35', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Word Embeddings Position Representations+ [input sequence]WordEmbeddings PositionRepresentations+ Transformer Decoder The only new part is attention from decoder to encoder. Like Transformer Encoder [output sequence] [predictions!] Residual + LayerNormFeed-ForwardResidual + LayerNorm Multi-Head Cross-AttentionResidual + LayerNormMasked Multi-Head Self-Attention 36', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Decoder: Cross-attention (details) 37 •We saw that self-attention is when keys, queries, and values come from the samesource.•In the decoder, we have attention that looks more like what we saw last week.•Let ℎ1,\\t…\\t,\\tℎ𝑇\\tbe output vectors from the Transformer encoder; 𝑥𝑖\\t∈\\tℝ𝑑•Let 𝑧1,\\t…\\t,\\t𝑧𝑇\\tbe input vectors from the Transformer decoder, 𝑧𝑖\\t∈\\tℝ𝑑•Then keys and values are drawn from the encoder (like a memory):•𝑘𝑖\\t=\\t𝐾ℎ𝑖, 𝑣𝑖\\t=\\t𝑉ℎ𝑖.•And the queries are drawn from the decoder, 𝑞𝑖\\t=\\t𝑄𝑧𝑖.', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Cross-attention (details)•Let’s look at how cross-attention is computed, in matrices.•Let H\\t=\\tℎ1;\\t…\\t;\\tℎ𝑇•Let Z\\t=\\t𝑧1;\\t…\\t;\\t𝑧𝑇∈\\tℝ𝑇×𝑑\\tbe the concatenation of encoder vectors.∈\\tℝ𝑇×𝑑\\tbe the concatenation of decoder vectors.⊤•The output is defined as output\\t=\\tsoftmax\\t𝑍𝑄\\t𝐻𝐾\\t ×\\t𝐻𝑉. = 𝑍𝑄𝐾⊤\\t𝐻⊤∈\\tℝ𝑇×𝑇All pairs of attention scores! output\\t∈\\tℝ𝑇×𝑑= 𝐾⊤\\t𝐻⊤𝑍𝑄First, take the query-key dot products in one matrixmultiplication: 𝑍𝑄\\t𝐻𝐾⊤ Next, softmax, and compute the weighted average with another matrix multiplication.𝑍𝑄𝐾⊤\\t𝐻⊤softmax 𝐻𝑉 38', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Outline 39 1.From recurrence (RNN) to attention-based NLP models2.Introducing the Transformer model3.Great results with Transformers', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Great Results with Transformers Not just better Machine Also more efficient toTranslation BLEU scores train! First, Machine Translation from the original Transformers paper! [Vaswani et al., 2017][Test sets: WMT 2014 English-German and English-French]40', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Great Results with Transformers Transformers all the way down. Next, document generation! The old standard [Liu et al., 2018]; WikiSum dataset41', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Great Results with Transformers [Liu et al., 2018] Before too long, most Transformers results also included pretraining.Transformers’ parallelizability allows for efficient pretraining, and have made them the de-facto standard.On this popular aggregatebenchmark, for example: All top models are Transformer (and pretraining)-based.More results Thursday when we discuss pretraining.44', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Information Retrieval  and Web Search IR Evaluation and  IR Standard Text Collections', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  IR Evaluation Measures 1) How fast does it index? – Number of bytes per second. 2) How fast does it search? – Latency as a function of queries per second. 3) What is the cost per query? – $/query. 4) What is the level of user happiness? – How can we quantify user happiness? measurable', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  User Happiness • Who is the user we are trying to make happy? – Web search engine: searcher. Success: Searcher ﬁnds  what she was looking for. Measure: rate of return to  this search engine. – Web search engine: advertiser. Success: Searcher  clicks on ad. Measure: clickthrough rate. – Ecommerce: seller. Success: Buyer buys something.  Measures: time to purchase, fraction of “conversions”  of searchers to buyers. – Ecommerce: seller. Success: Seller sells something.  Measure: proﬁt per item sold.', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Relevance as Proxy for User Happiness • User happiness ≈ the relevance of search results. • Relevance is assessed relative to the user need, not the  query. – Note: user need is translated into a query. – Information need: I am looking for information on  whether drinking red wine is more effective at reducing  your risk of heart attacks than white wine. – Query: red wine white wine heart attack – Assess whether the retrieved document addresses  the underlying need, not whether it has these words. • Binary Assessments: Relevant or Nonrelevant.', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Standard Methodology for Measuring  Relevance in IR • To measure relevance effectiveness of ad-hoc IR, we  need: 1. A document collection. 2. A suite of information needs, expressible as  queries. • Must be representative of actual user needs. • Sample from query logs, if available. 3. Binary assessments of either Relevant or  Nonrelevant for each query and each document. • Can be more nuanced, e.g., 0, 1, 2, 3, … • Use pooling, when it is unfeasible to assess every (q, d)  pair.', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Why System Evaluations? • Is a retrieval system producing the expected results? • There are many retrieval models/ algorithms/ systems,  which one is the best? • What is the best component for: – Ranking function (inner-product, cosine, …) – Term selection (stopword removal, stemming…) – Term weighting (TF, TF-IDF,…) • For a fair comparison: – Should be all evaluated using the same measures – Should be all evaluated on the same collection of documents – Should be all evaluated on the same set of questions', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  documents relevant of number Total retrieved documents relevant of Number  recall = retrieved  documents of number Total retrieved  documents relevant of  Number  precision = Relevant  documents Retrieved  documents Entire document  collection retrieved &  relevant not retrieved but  relevant retrieved &  irrelevant Not retrieved &  irrelevant retrieved not retrieved relevant irrelevant Precision and Recall', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Precision and Recall • Precision vs. Recall: – Precision = The ability to retrieve top-ranked documents that  are mostly relevant. – Recall = The ability of the search to find all of the relevant items  in the corpus. • Determining Recall can be difficult • Total number of  relevant items is sometimes not  available – use pooling – Sample across the database and perform relevance judgment  on these items. – Apply different retrieval algorithms to the same database for the  same query. The aggregate of relevant items is taken as the  total relevant set.', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Trade-off between Recall and Precision 10 1 Recall Precision The ideal Returns relevant documents but misses many useful ones too Returns most relevant documents but also  includes lots of   Irrelevant documents  Precision and Recall are inverse proportional', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  F-measure • One measure of performance that takes into account  both recall and precision. • Harmonic mean of recall and precision: • Compared to arithmetic mean, both need to be high for  harmonic mean to be high. PRRP PRF 11 22 + =+=', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Ranked Retrieval Measures • Binary relevance: – 11-point Interpolated Precision-Recall Curve – R-precision – Precision@K (P@K) and Recall@K (R@K) – Mean Average Precision (MAP) – Mean Reciprocal Rank (MRR) • Multiple levels of relevance: – Normalized Discounted Cumulative Gain (NDCG)', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  R=3/6=0.5;     P=3/4=0.75 Recall-Precision Curves An Example n doc # relevant 1 588 x 2 589 x 3 576 4 590 x 5 986 6 592 x 7 984 8 988 9 578 10 985 11 103 12 591 13 772 x 14 990 Let total # of relevant docs = 6 Check each new recall point: R=1/6=0.167; P=1/1=1 R=2/6=0.333; P=2/2=1 R=5/6=0.833; p=5/13=0.38 R=4/6=0.667; P=4/6=0.667 Missing one  relevant document. Never reach  100% recall', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Interpolating a  Recall/Precision Curve • Interpolate a precision  value for each standard  recall level: – rj = {0.0, 0.1, 0.2, 0.3,  0.4, 0.5, 0.6, 0.7, 0.8,  0.9, 1.0} – r0 = 0.0, r1 = 0.1, …,  r10=1.0', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Interpolating a Recall/Precision Curve Rationale for interpolation: The user is willing  to look at more stuff if both precision and  recall get better.', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Interpolating a Recall/Precision Curve • Compute interpolated  precision at recall  levels 0.0, 0.1, 0.2, . . . • Do this for each of the  queries in the  evaluation benchmark • Average over queries  The curve is typical of  performance levels at  TREC (more later).', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 1,  measured data points', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 1,  measured data points interpolation', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 2,  measured data points', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 2,  interpolation', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: averaging', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: area/result', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Accuracy • Why do we use complex measures like precision, recall,  and F?  • Why not something simple like accuracy?  • Accuracy is the fraction of decisions  (relevant/nonrelevant) that are correct.  • In terms of the contingency table above, accuracy = (TP  + TN)/(TP + FP + FN + TN).', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Accuracy • Simple trick to maximize accuracy in IR: always say no  and return nothing You then get 99.99% accuracy on  most queries.  • Searchers on the web (and in IR in general) want to find  something and have a certain tolerance for junk.  • It’s better to return some bad hits as long as you return  something.  – → We use precision, recall, and F for evaluation, not accuracy.', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Recall-criticality and precision-criticality • Inverse relationship between precision and recall forces  general systems to go for compromise between them. • But some tasks particularly need good precision  whereas others need good recall:', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Recall-criticality and precision-criticality', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Average Recall/Precision Curve • Typically average performance over a large set of  queries. • Compute average precision at each standard recall level  across all queries. • Plot average precision/recall curves to evaluate overall  system performance on a document/query corpus. • Average: – Micro-average: compute P/R/F once for the entire set of queries  – Macro-average: average of within-query precision/recall', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  How To Compare  Two or More Systems • The curve closest to the upper right-hand corner of  the graph indicates the best performance 0 0.2 0.4 0.6 0.8 1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Recall Precision NoStem Stem', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  R-precision • Precision at the R-th position in the ranking of results  for a query that has R relevant documents. n doc # relevant 1 588 x 2 589 x 3 576 4 590 x 5 986 6 592 x 7 984 8 988 9 578 10 985 11 103 12 591 13 772 x 14 990 What can we tell about the precision  and recall measures at the R-th  position in the ranking? A) Precision is smaller than recall B) Precision is larger than recall C) Precision and recall are the same', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  R-precision • Precision at the R-th position in the ranking of results  for a query that has R relevant documents. n doc # relevant 1 588 x 2 589 x 3 576 4 590 x 5 986 6 592 x 7 984 8 988 9 578 10 985 11 103 12 591 13 772 x 14 990 R = # of relevant docs = 6 R-Precision = 4/6 = 0.67', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Precision@K 1. Set a rank threshold K. 2. Compute % of documents relevant in top K. – Ignores documents ranked lower than K. • Example: – Prec@3 of 2/3 – Prec@4 of 2/4 – Prec@5 of 3/5 • In a similar way we have Recall@K', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Average Precision (MAP) 1. Consider rank position of each of the R relevant docs: – K1, K2, … KR 2. Compute Precision@K for each K1, K2, … KR. 3. Average precision = average of P@K.       Example:               has AvgPrec of • MAP is Average Precision across multiple queries. 76.05 3 3 2 1 1 3 1 \\uf0bb\\uf0f7 \\uf0f8 \\uf0f6\\uf0e7 \\uf0e8 \\uf0e6 ++\\uf0d7', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Exercise: Average Precision Assume a query with six relevant documents, and two systems that produce the following two rankings.  Which system is better according to the average precision?', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Average Precision (MAP) Average precision query 1 = (1.0+0.67+0.5+0.44+0.5)/5 = 0.62 Average precision query 2 = (0.5+0.4+0.43)/3 = 0.44 MAP = (0.62 + 0.44)/2 = 0.53', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Average Precision (MAP) • If a relevant document never gets retrieved, we assume  the precision corresponding to that relevant document  to be zero.  • MAP is macro-averaging: each query counts equally. • A commonly used measure in current IR research, along  with P/R/F', 'page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Reciprocal Rank • Consider rank position, K, of first relevant doc – Could be only clicked doc • Reciprocal Rank score = • MRR is the mean RR across multiple queries   K 1', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Multiple Levels of Relevance • Documents are rarely entirely relevant or non-relevant  to a query. • Many sources of graded relevance judgments: – Relevance judgments on a 5-point scale. – Averaging among multiple judges.', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Cummulative Gain • With graded relevance  judgments, we can compute  the gain at each rank. • Cumulative Gain at rank n: – Where reli is the graded  relevance of the document at  position i. n doc # relevance  (gain) CGn 1 588 1.0 1.0 2 589 0.6 1.6 3 576 0.0 1.6 4 590 0.8 2.4 5 986 0.0 2.4 6 592 1.0 3.4 7 984 0.0 3.4 8 988 0.0 3.4 9 578 0.0 3.4 10 985 0.0 3.4 11 103 0.0 3.4 12 591 0.0 3.4 13 772 0.2 3.6 14 990 0.0 3.6', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Discounted Cumulative Gain • Users care more about high- ranked documents, so we  discount results by  1/log2(rank) • Popular measures for  evaluating web search and  related tasks. • Discounted Cumulative Gain: n doc # rel  (gain) CGn logn DCGn 1 588 1.0 1.0 - 1.00 2 589 0.6 1.6 1.00 1.60 3 576 0.0 1.6 1.58 1.60 4 590 0.8 2.4 2.00 2.00 5 986 0.0 2.4 2.32 2.00 6 592 1.0 3.4 2.58 2.39 7 984 0.0 3.4 2.81 2.39 8 988 0.0 3.4 3.00 2.39 9 578 0.0 3.4 3.17 2.39 10 985 0.0 3.4 3.32 2.39 11 103 0.0 3.4 3.46 2.39 12 591 0.0 3.4 3.58 2.39 13 772 0.2 3.6 3.70 2.44 14 990 0.0 3.6 3.81 2.44', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Normalized Discounted  Cumulative Gain (NDCG) • To compare DCGs, normalize values so that an ideal  ranking would have a Normalized DCG of 1.0. • Ideal ranking: n doc # rel  (gain) CGn logn DCGn 1 588 1.0 1.0 0.00 1.00 2 589 0.6 1.6 1.00 1.60 3 576 0.0 1.6 1.58 1.60 4 590 0.8 2.4 2.00 2.00 5 986 0.0 2.4 2.32 2.00 6 592 1.0 3.4 2.58 2.39 7 984 0.0 3.4 2.81 2.39 8 988 0.0 3.4 3.00 2.39 9 578 0.0 3.4 3.17 2.39 10 985 0.0 3.4 3.32 2.39 11 103 0.0 3.4 3.46 2.39 12 591 0.0 3.4 3.58 2.39 13 772 0.2 3.6 3.70 2.44 14 990 0.0 3.6 3.81 2.44 n doc # rel  (gain) CGn logn IDCGn 1 588 1.0 1.0 0.00 1.00 2 592 1.0 2.0 1.00 2.00 3 590 0.8 2.8 1.58 2.50 4 589 0.6 3.4 2.00 2.80 5 772 0.2 3.6 2.32 2.89 6 576 0.0 3.6 2.58 2.89 7 986 0.0 3.6 2.81 2.89 8 984 0.0 3.6 3.00 2.89 9 988 0.0 3.6 3.17 2.89 10 578 0.0 3.6 3.32 2.89 11 985 0.0 3.6 3.46 2.89 12 103 0.0 3.6 3.58 2.89 13 591 0.0 3.6 3.70 2.89 14 990 0.0 3.6 3.81 2.89', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Normalized Discounted  Cumulative Gain (NDCG) • Normalize by DCG of the  ideal ranking: – NDCG ≤ 1 at all ranks. • NDCG is now comparable  across different queries: – Useful for contrasting  queries with varying  numbers of relevant results. – Quite popular for Web  search.', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Evaluation with Clickthrough Data # of clicks received Strong position bias, so absolute click rates unreliable', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Pairwise Relative Ratings • Pairs of the form: DocA better than DocB for a query – Doesn’t mean that DocA relevant to query • Rather than assess a rank-ordering with respect to per- doc relevance assessments • Assess in terms of conformance with historical pairwise  preferences recorded from user clicks', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Comparing two rankings to a baseline  ranking • Given a set of pairwise preferences P • We want to measure two rankings A and B • Define a proximity measure between A and P – And likewise, between B and P • Want to declare the ranking with better proximity to be  the winner • Proximity measure should reward agreements with P  and penalize disagreements', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Kendall-tau Distance to Compare Rankings • Generate all pairs for each ranking • Let X be the number of agreements between a ranking  (say A) and P • Let Y be the number of disagreements • Then the Kendall tau distance between A and P is  (X-Y)/(X+Y)', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Exercise • Assume perfect ranking P = (1, 2, 3, 4) • Assume two candidate rankings A = (1, 3, 2, 4) and B =  (4, 1, 2, 3) • Which candidate ranking is closer to the perfect ranking  according to Kendall-tau?', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  A/B Testing at Web Search Engines  • Can exploit an existing user base to provide useful  feedback on a single innovation • Randomly send a small fraction (1−10%) of incoming  users to a variant of the system that includes a single  change. – Have most users use the old system • Judge effectiveness by measuring change in clickthrough:  the percentage of users that click on the top result (or  any result on the first page) • Probably the evaluation methodology that large search  engines trust the most', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Amazon Mechanical Turk Testing • https://requester.mturk.com/', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Standard Methodology for Measuring  Relevance in IR • To measure relevance effectiveness of ad-hoc IR, we  need: 1. A document collection. 2. A suite of information needs, expressible as  queries. • Must be representative of actual user needs. • Sample from query logs, if available. 3. Binary assessments of either Relevant or  Nonrelevant for each query and each document. • Can be more nuanced, e.g., 0, 1, 2, 3, … • Use pooling, when it is unfeasible to assess every (q, d)  pair.', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Early Test Collections • Previous experiments were based on the SMART  collection which is fairly small.  (ftp://ftp.cs.cornell.edu/pub/smart)      Collection Number Of Number Of Raw Size       Name   Documents Queries  (Mbytes)       CACM 3,204    64  1.5       CISI  1,460  112  1.3       CRAN  1,400  225  1.6       MED  1,033    30  1.1       TIME    425    83  1.5  • Different researchers used different test collections and  evaluation techniques.', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  The TREC Benchmark • TREC: Text REtrieval Conference (http://trec.nist.gov/) – Originated from the TIPSTER program sponsored by Defense  Advanced Research Projects Agency (DARPA). – Became an annual conference in 1992, co-sponsored by the      National Institute of Standards and Technology (NIST) and   DARPA. – Participants are given parts of a standard set of documents and  TOPICS (from which queries have to be derived) in  different  stages for training and testing. – Participants submit the P/R values for the final document and  query corpus and present their results at  the conference.', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  TREC Objectives • Provide a common ground for comparing different IR  techniques. – Same set of documents and queries, and same evaluation  method • Sharing of resources and experiences in developing the  benchmark. – With major sponsorship from government to develop large  benchmark collections • Encourage participation from industry and academia. • Development of new evaluation techniques, particularly  for new applications. – Retrieval, routing/filtering, non-English collection, web-based  collection, question answering', 'page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  TREC Advantages • Large scale (compared to a few MB in the SMART  Collection). • Relevance judgments provided. • Under continuous development with support from the  U.S. Government. • Wide participation: – TREC 1: 28 papers 360 pages. – TREC 4: 37 papers 560 pages. – TREC 7: 61 papers 600 pages.  – TREC 8: 74 papers.', 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  TREC Tasks • Ad hoc: New questions are being asked on a static set  of data.  • Routing: Same questions are being asked, but new  information is being searched. (news clipping, library  profiling). • New tasks added after TREC 5: – Interactive, multilingual, natural language, multiple database  merging, filtering, very large corpus (20 GB, 7.5 million  documents), question answering.', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  The TREC Collection • Both long and short documents (from a few hundred  to over one thousand unique terms in a document). – Both SGML documents and SGML queries contain many  different kinds of information (fields). – Generation of the formal queries (Boolean, Vector Space,  etc.) is the responsibility of the system. • A system may be very good at ranking, but if it generates poor  queries from the topic, its final P/R would be poor. • Test documents consist of:      WSJ Wall Street Journal articles (1986 -1992)  550 M       AP   Associate Press Newswire (1989)     514 M      ZIFF Computer Select Disks (Ziff -Davis Publishing) 493 M       FR   Federal Register    469 M       DOE Abstracts from Department of Energy reports 190 M', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Sample SGML Document <DOC>  <DOCNO> WSJ870324-0001 </DOCNO>  <HL> John Blair Is Near Accord To Sell Unit, Sources Say </HL>  <DD> 03/24/87</DD>  <SO> WALL STREET JOURNAL (J) </SO> <IN> REL TENDER OFFERS, MERGERS, ACQUISITIONS (TNM) MARKETING,  ADVERTISING (MKT) TELECOMMUNICATIONS, BROADCASTING,  TELEPHONE, TELEGRAPH (TEL) </IN>  <DATELINE> NEW YORK </DATELINE>  <TEXT>      John Blair &amp; Co. is close to an agreement to sell its TV station  advertising representation operation and program production unit to an  investor group led by James  H. Rosenfield, a former CBS Inc. executive,  industry sources said. Industry sources put the value of the proposed  acquisition at more than $100 million. ...  </TEXT>  </DOC>', \"page_label: 56 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Sample SGML Query <top>  <head> Tipster Topic Description  <num> Number: 066  <dom> Domain: Science and Technology  <title> Topic: Natural Language Processing  <desc> Description: Document will identify a type of natural language  processing technology which is being developed or marketed in the U.S.  <narr> Narrative: A relevant document will identify a company or institution  developing or marketing a natural language processing technology, identify  the technology, and identify one of more features of the company's  product. <con> Concept(s):  1. natural language processing ;2. translation, language,  dictionary <fac> Factor(s):  <nat> Nationality: U.S.</nat> </fac>  <def> Definitions(s):  </top>\", 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  INFORMATION RETRIEVAL  Soujanya Poria', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Syllabus•Week 1 – Introduction to IR, Boolean and ranked retrieval.•Week 2 – Locally Sensitive Hashing•Week 3 –  Probabilistic IR / BM-25•Week 4 – Relevance feedback and IR Evaluation•Week 5 – Index Creation & Compression•Week 6 – Transformers and Language Models•Week 7 – Term Break•Week 8 – Midterm•Week 9 – Knowledge guided retrieval from LLM', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Syllabus•Week 10 – Learning to Rank•Week 11 – LLM-based IR’s Safety Measurement•Week 12 – Pagerank Algorithm•Week 13 – Project Presentation', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Words of Wisdom!•I have just crossed my 30  😁 – stop calling me Prof. Call me SJ. How cool it is  😁•My handwriting is horrible  🥲–Tell me when you do not understand what I wrote on the whiteboard.•Getting good marks is super easy!–Focus on learning and applying new things.•Ask me 100 of questions!', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  What can you expect in this course?•You use Google everyday: learn how it works!•Learn how the new Bing search works!•Learn how you can use machine learning and AI tools to mine your desired information from the web!•Clear your misconception: IR is not just web scraping!•Opportunity to participate in cool projects!', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Book to readhttp://nlp.stanford.edu/IR-book/pdf/00front.pdf', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  INFORMATION RETRIEVAL Boolean retrieval', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Typical IR task•Input:–A large collection of unstructured text documents.–A user query expressed as text.•Output:–A ranked list of documents that are relevant to the query. IR SystemQuery String DocumentcorpusRankedDocuments1. Doc12. Doc23. Doc3    .    .', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Generative IR task•Input:–A large collection of unstructured text documents.–A user query expressed as text.•Output:–A textual response with user’s desired information.', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Boolean  Typical IR task•Input:–A large collection of unstructured text documents.–A user query expressed as text.•Output:–A ranked list of documents that are relevant to the query. IR SystemQuery String DocumentcorpusRankedDocuments1. Doc12. Doc23. Doc3    .    .', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Boolean retrieval•Information Need: Which plays by Shakespeare mention Brutus and Caesar, but not Calpurnia?•Boolean Query: Brutus AND Caesar AND NOT Calpurnia•Possible search procedure:–Linear scan through all documents (Shakespeare’s collected works).–Compile list of documents that contain Brutus and Caesar, but not Calpurnia.–Advantage: simple, it works for moderately sized corpora.–Disadvantage: need to do linear scan for every query Þ slow for large corpora.', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Term-document incidence matrices Antony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony1 1 0 0 0 1Brutus1 1 0 1 0 0Caesar1 1 0 1 1 1Calpurnia0 1 0 0 0 0Cleopatra1 0 0 0 0 0mercy1 0 1 1 1 1worser1 0 1 1 1 0 1 if document contains word, 0 otherwise •Precompute a data structure that makes search fast for every query.', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Term-document incidence matrix M Brutus AND Caesar AND NOT CalpurniaQuery =  Antony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony1 1 0 0 0 1Brutus1 1 0 1 0 0Caesar1 1 0 1 1 1Calpurnia0 1 0 0 0 0Cleopatra1 0 0 0 0 0mercy1 0 1 1 1 1worser1 0 1 1 1 0 Answer = M(Brutus) Ù M(Caesar) Ù¬ M(Calpurnia) = 1 1 0 1 0 0 Ù 1 1 0 1 1 1 Ù 1 0 1 1 1 1 = 1 0 0 1 0 0 Þ Anthony and Cleopatra, Hamlet       110100 Ù110111 Ù101111100100', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Answers to Query•Antony and Cleopatra, Act III, Scene ii Agrippa [Aside to DOMITIUS ENOBARBUS]: Why, Enobarbus,                           When Antony found Julius Caesar dead,                             He cried almost to roaring; and he wept                            When at Philippi he found Brutus slain. •Hamlet, Act III, Scene ii Lord Polonius: I did enact Julius Caesar I was killed i’ the      Capitol; Brutus killed me.', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Scalability: Dense Format•Assume:–Corpus has 1 million documents.–Each document is about 1,000 words long.–Each word takes 6 bytes, on average.–Of  the 1 billion word tokens 500,000 are unique. •Then:–Corpus storage takes:•1M * 1, 000 * 6 = 6GB–Term-Document incidence matrix would take:•500,000 * 1,000,000 = 0.5 * 1012 bits', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Scalability: Sparse Format•Of the 500 billion entries, at most 1 billion are non-zero.Þ at least 99.8% of the entries are zero.Þ use a sparse representation to reduce storage size! •Store only non-zero entries Þ Inverted Index.', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index for Boolean Retrieval •Map each term to a posting list of documents containing  it–Identify each document by a numerical docID.–Dictionary of terms usually in memory.–Posting list:•linked lists of variable-sized array, if in memory.•contiguous run of postings, if on disk.Brutus CalpurniaCaesar124561657132124113145173 231 174 54101 DictionaryPostings', \"page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 1•Assemble sequence of átoken, docIDñ pairs.–assume text has been tokenized  17 I did enact JuliusCaesar I was killed i' the Capitol; Brutus killed me. Doc 1 So let it be withCaesar. The nobleBrutus hath told youCaesar was ambitious Doc 2\", 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 2•Sort by terms, then by docIDs.', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 3•Merge multiple term entries per document.•Split into dictionary and posting lists.–keep posting lists sorted, for efficient query processing. •Add document frequency information:–useful for efficient query processing.–also useful later in document ranking.', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 3', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Processing: AND•Consider processing the query:Brutus AND Caesar–Locate Brutus in the Dictionary;•Retrieve its postings.–Locate Caesar in the Dictionary;•Retrieve its postings.–“Merge” the two postings (intersect the document sets): 1283424816326412358132128 BrutusCaesar', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Processing: AND Merge Algorithm', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Processing: OR•Exercise: Adapt the merge algorithm for the query: Brutus OR Caesar', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Optimization:What is the best order for query processing?•Consider a query that is an AND of n terms.1283424 8163264123581321BrutusCaesarCalpurnia1316 Query: Brutus AND Calpurnia AND Caesar –  For each of the n terms, get its postings, then AND them together.–  Process in order of increasing freq:•  start with smallest set, then keep cutting further.•  use document frequencies stored in the dictionary.Þ execute the query as (Calpurnia AND Brutus) AND Caesar', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Optimization•Exercise: recommend a query processing order for:–(tangerine OR trees) AND    (marmalade OR skies) AND    (kaleidoscope OR eyes)–which two terms should we process first? Term Freq     eyes 213312   kaleidoscope 87009   marmalade 107913   skies 271658   tangerine 46653   trees 316812', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  INFORMATION RETRIEVAL IR models: Vector Space Model', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Information Retrieval  and Web SearchIR models: Vector Space Model [Note: Some slides in this set were adapted from an IR course taught by Ray Mooney at UT Austin (who in turn adapted them from Joydeep Ghosh), and from an IR course taught by Chris Manning at Stanford)', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Ranked Retrieval•Thus far, our queries have all been Boolean–Documents either match or don’t•Good for expert users with precise understanding of their needs and the collection–Also good for applications: Applications can easily consume 1000s of results•Not good for the majority of users–Most users incapable of writing Boolean queries (or they are, but they think it’s too much work)–Most users don’t want to wade through 1000s of results•This is particularly true of Web search Ch. 6', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Problem with Boolean Search•Boolean queries often result in either too few (=0) or too many (1000s) results.•Query 1: “standard user dlink 650” → 200,000 hits•Query 2: “standard user dlink 650 no card found”: 0 hits•It takes a lot of skill to come up with a query that produces a manageable number of hits.–AND gives too few; OR gives too many•Hard to tune precision vs. recall:–AND operator tends to produce high precision but low recall.–OR operator gives low precision but high recall.–Difficult/impossible to find satisfactory middle ground. Ch. 6', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Ranked Retrieval Models•Rather than a set of documents satisfying a query expression, in ranked retrieval, the system returns an ordering over the (top) documents in the collection for a query•Free text queries: Rather than a query language of operators and expressions, the user’s query is just one or more words in a human language•In principle, there are two separate choices here, but in practice, ranked retrieval has normally been associated with free text queries and vice versa', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Not a Problem in Ranked Retrieval•When a system produces a ranked result set, large result sets are not an issue–Indeed, the size of the result set is not an issue–We just show the top k ( ≈ 10) results–We don’t overwhelm the user–Premise: the ranking algorithm works Ch. 6', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Scoring as the Basis of Ranked Retrieval•We wish to return in order the documents most likely to be useful to the searcher•How can we rank-order the documents in the collection with respect to a query?•Assign a score – say in [0, 1] – to each document•This score measures how well the document and the query “match” Ch. 6', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Query-document Matching Scores•We need a way of assigning a score to a query/document pair•Let’s start with a one-term query•If the query term does not occur in the document: score should be 0•The more frequent the query term in the document, the higher the score (should be)', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Take 1: Jaccard coefficient•Jaccard: A commonly used measure of overlap of two sets A and B•Jaccard(A,B) = |A ∩ B| / |A ∪ B|•Jaccard(A,A) = 1•Jaccard(A,B) = 0 if A ∩ B = 0•A and B don’t have to be the same size.•Always assigns a number between 0 and 1. Ch. 6', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Jaccard Coefficient: Scoring ExampleAssume the following query:•Query: march of dimesAnd the following two documents:•Document 1: caesar died in march•Document 2: the long march Ch. 6 According to the Jaccard coeficient, which document is more similar to the query (assume no stopword removal):A)Doc 1 B)Doc 2C)Both documents have the same similarity'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96b560>, 'json_data': {'input': ['page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Word Embeddings Position Representations+ [input sequence]WordEmbeddings PositionRepresentations+ Looking back at the whole model, zooming in on a Decoder block:Transformer Encoder [output sequence] [predictions!]Transformer DecoderResidual + LayerNorm Feed-Forward Residual + LayerNormMulti-Head Cross-Attention Residual + LayerNormMasked Multi-Head Self-Attention 35', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder-Decoder [Vaswani et al., 2017] TransformerEncoder Word Embeddings Position Representations+ [input sequence]WordEmbeddings PositionRepresentations+ Transformer Decoder The only new part is attention from decoder to encoder. Like Transformer Encoder [output sequence] [predictions!] Residual + LayerNormFeed-ForwardResidual + LayerNorm Multi-Head Cross-AttentionResidual + LayerNormMasked Multi-Head Self-Attention 36', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Decoder: Cross-attention (details) 37 •We saw that self-attention is when keys, queries, and values come from the samesource.•In the decoder, we have attention that looks more like what we saw last week.•Let ℎ1,\\t…\\t,\\tℎ𝑇\\tbe output vectors from the Transformer encoder; 𝑥𝑖\\t∈\\tℝ𝑑•Let 𝑧1,\\t…\\t,\\t𝑧𝑇\\tbe input vectors from the Transformer decoder, 𝑧𝑖\\t∈\\tℝ𝑑•Then keys and values are drawn from the encoder (like a memory):•𝑘𝑖\\t=\\t𝐾ℎ𝑖, 𝑣𝑖\\t=\\t𝑉ℎ𝑖.•And the queries are drawn from the decoder, 𝑞𝑖\\t=\\t𝑄𝑧𝑖.', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  The Transformer Encoder: Cross-attention (details)•Let’s look at how cross-attention is computed, in matrices.•Let H\\t=\\tℎ1;\\t…\\t;\\tℎ𝑇•Let Z\\t=\\t𝑧1;\\t…\\t;\\t𝑧𝑇∈\\tℝ𝑇×𝑑\\tbe the concatenation of encoder vectors.∈\\tℝ𝑇×𝑑\\tbe the concatenation of decoder vectors.⊤•The output is defined as output\\t=\\tsoftmax\\t𝑍𝑄\\t𝐻𝐾\\t ×\\t𝐻𝑉. = 𝑍𝑄𝐾⊤\\t𝐻⊤∈\\tℝ𝑇×𝑇All pairs of attention scores! output\\t∈\\tℝ𝑇×𝑑= 𝐾⊤\\t𝐻⊤𝑍𝑄First, take the query-key dot products in one matrixmultiplication: 𝑍𝑄\\t𝐻𝐾⊤ Next, softmax, and compute the weighted average with another matrix multiplication.𝑍𝑄𝐾⊤\\t𝐻⊤softmax 𝐻𝑉 38', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Outline 39 1.From recurrence (RNN) to attention-based NLP models2.Introducing the Transformer model3.Great results with Transformers', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Great Results with Transformers Not just better Machine Also more efficient toTranslation BLEU scores train! First, Machine Translation from the original Transformers paper! [Vaswani et al., 2017][Test sets: WMT 2014 English-German and English-French]40', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Great Results with Transformers Transformers all the way down. Next, document generation! The old standard [Liu et al., 2018]; WikiSum dataset41', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/05transformers.pdf  Great Results with Transformers [Liu et al., 2018] Before too long, most Transformers results also included pretraining.Transformers’ parallelizability allows for efficient pretraining, and have made them the de-facto standard.On this popular aggregatebenchmark, for example: All top models are Transformer (and pretraining)-based.More results Thursday when we discuss pretraining.44', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Information Retrieval  and Web Search IR Evaluation and  IR Standard Text Collections', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  IR Evaluation Measures 1) How fast does it index? – Number of bytes per second. 2) How fast does it search? – Latency as a function of queries per second. 3) What is the cost per query? – $/query. 4) What is the level of user happiness? – How can we quantify user happiness? measurable', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  User Happiness • Who is the user we are trying to make happy? – Web search engine: searcher. Success: Searcher ﬁnds  what she was looking for. Measure: rate of return to  this search engine. – Web search engine: advertiser. Success: Searcher  clicks on ad. Measure: clickthrough rate. – Ecommerce: seller. Success: Buyer buys something.  Measures: time to purchase, fraction of “conversions”  of searchers to buyers. – Ecommerce: seller. Success: Seller sells something.  Measure: proﬁt per item sold.', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Relevance as Proxy for User Happiness • User happiness ≈ the relevance of search results. • Relevance is assessed relative to the user need, not the  query. – Note: user need is translated into a query. – Information need: I am looking for information on  whether drinking red wine is more effective at reducing  your risk of heart attacks than white wine. – Query: red wine white wine heart attack – Assess whether the retrieved document addresses  the underlying need, not whether it has these words. • Binary Assessments: Relevant or Nonrelevant.', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Standard Methodology for Measuring  Relevance in IR • To measure relevance effectiveness of ad-hoc IR, we  need: 1. A document collection. 2. A suite of information needs, expressible as  queries. • Must be representative of actual user needs. • Sample from query logs, if available. 3. Binary assessments of either Relevant or  Nonrelevant for each query and each document. • Can be more nuanced, e.g., 0, 1, 2, 3, … • Use pooling, when it is unfeasible to assess every (q, d)  pair.', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Why System Evaluations? • Is a retrieval system producing the expected results? • There are many retrieval models/ algorithms/ systems,  which one is the best? • What is the best component for: – Ranking function (inner-product, cosine, …) – Term selection (stopword removal, stemming…) – Term weighting (TF, TF-IDF,…) • For a fair comparison: – Should be all evaluated using the same measures – Should be all evaluated on the same collection of documents – Should be all evaluated on the same set of questions', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  documents relevant of number Total retrieved documents relevant of Number  recall = retrieved  documents of number Total retrieved  documents relevant of  Number  precision = Relevant  documents Retrieved  documents Entire document  collection retrieved &  relevant not retrieved but  relevant retrieved &  irrelevant Not retrieved &  irrelevant retrieved not retrieved relevant irrelevant Precision and Recall', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Precision and Recall • Precision vs. Recall: – Precision = The ability to retrieve top-ranked documents that  are mostly relevant. – Recall = The ability of the search to find all of the relevant items  in the corpus. • Determining Recall can be difficult • Total number of  relevant items is sometimes not  available – use pooling – Sample across the database and perform relevance judgment  on these items. – Apply different retrieval algorithms to the same database for the  same query. The aggregate of relevant items is taken as the  total relevant set.', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Trade-off between Recall and Precision 10 1 Recall Precision The ideal Returns relevant documents but misses many useful ones too Returns most relevant documents but also  includes lots of   Irrelevant documents  Precision and Recall are inverse proportional', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  F-measure • One measure of performance that takes into account  both recall and precision. • Harmonic mean of recall and precision: • Compared to arithmetic mean, both need to be high for  harmonic mean to be high. PRRP PRF 11 22 + =+=', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Ranked Retrieval Measures • Binary relevance: – 11-point Interpolated Precision-Recall Curve – R-precision – Precision@K (P@K) and Recall@K (R@K) – Mean Average Precision (MAP) – Mean Reciprocal Rank (MRR) • Multiple levels of relevance: – Normalized Discounted Cumulative Gain (NDCG)', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  R=3/6=0.5;     P=3/4=0.75 Recall-Precision Curves An Example n doc # relevant 1 588 x 2 589 x 3 576 4 590 x 5 986 6 592 x 7 984 8 988 9 578 10 985 11 103 12 591 13 772 x 14 990 Let total # of relevant docs = 6 Check each new recall point: R=1/6=0.167; P=1/1=1 R=2/6=0.333; P=2/2=1 R=5/6=0.833; p=5/13=0.38 R=4/6=0.667; P=4/6=0.667 Missing one  relevant document. Never reach  100% recall', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Interpolating a  Recall/Precision Curve • Interpolate a precision  value for each standard  recall level: – rj = {0.0, 0.1, 0.2, 0.3,  0.4, 0.5, 0.6, 0.7, 0.8,  0.9, 1.0} – r0 = 0.0, r1 = 0.1, …,  r10=1.0', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Interpolating a Recall/Precision Curve Rationale for interpolation: The user is willing  to look at more stuff if both precision and  recall get better.', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Interpolating a Recall/Precision Curve • Compute interpolated  precision at recall  levels 0.0, 0.1, 0.2, . . . • Do this for each of the  queries in the  evaluation benchmark • Average over queries  The curve is typical of  performance levels at  TREC (more later).', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 1,  measured data points', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 1,  measured data points interpolation', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 2,  measured data points', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: Query 2,  interpolation', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: averaging', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Worked Example avg-11-pt prec: area/result', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Accuracy • Why do we use complex measures like precision, recall,  and F?  • Why not something simple like accuracy?  • Accuracy is the fraction of decisions  (relevant/nonrelevant) that are correct.  • In terms of the contingency table above, accuracy = (TP  + TN)/(TP + FP + FN + TN).', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Accuracy • Simple trick to maximize accuracy in IR: always say no  and return nothing You then get 99.99% accuracy on  most queries.  • Searchers on the web (and in IR in general) want to find  something and have a certain tolerance for junk.  • It’s better to return some bad hits as long as you return  something.  – → We use precision, recall, and F for evaluation, not accuracy.', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Recall-criticality and precision-criticality • Inverse relationship between precision and recall forces  general systems to go for compromise between them. • But some tasks particularly need good precision  whereas others need good recall:', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Recall-criticality and precision-criticality', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Average Recall/Precision Curve • Typically average performance over a large set of  queries. • Compute average precision at each standard recall level  across all queries. • Plot average precision/recall curves to evaluate overall  system performance on a document/query corpus. • Average: – Micro-average: compute P/R/F once for the entire set of queries  – Macro-average: average of within-query precision/recall', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  How To Compare  Two or More Systems • The curve closest to the upper right-hand corner of  the graph indicates the best performance 0 0.2 0.4 0.6 0.8 1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Recall Precision NoStem Stem', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  R-precision • Precision at the R-th position in the ranking of results  for a query that has R relevant documents. n doc # relevant 1 588 x 2 589 x 3 576 4 590 x 5 986 6 592 x 7 984 8 988 9 578 10 985 11 103 12 591 13 772 x 14 990 What can we tell about the precision  and recall measures at the R-th  position in the ranking? A) Precision is smaller than recall B) Precision is larger than recall C) Precision and recall are the same', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  R-precision • Precision at the R-th position in the ranking of results  for a query that has R relevant documents. n doc # relevant 1 588 x 2 589 x 3 576 4 590 x 5 986 6 592 x 7 984 8 988 9 578 10 985 11 103 12 591 13 772 x 14 990 R = # of relevant docs = 6 R-Precision = 4/6 = 0.67', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Precision@K 1. Set a rank threshold K. 2. Compute % of documents relevant in top K. – Ignores documents ranked lower than K. • Example: – Prec@3 of 2/3 – Prec@4 of 2/4 – Prec@5 of 3/5 • In a similar way we have Recall@K', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Average Precision (MAP) 1. Consider rank position of each of the R relevant docs: – K1, K2, … KR 2. Compute Precision@K for each K1, K2, … KR. 3. Average precision = average of P@K.       Example:               has AvgPrec of • MAP is Average Precision across multiple queries. 76.05 3 3 2 1 1 3 1 \\uf0bb\\uf0f7 \\uf0f8 \\uf0f6\\uf0e7 \\uf0e8 \\uf0e6 ++\\uf0d7', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Exercise: Average Precision Assume a query with six relevant documents, and two systems that produce the following two rankings.  Which system is better according to the average precision?', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Average Precision (MAP) Average precision query 1 = (1.0+0.67+0.5+0.44+0.5)/5 = 0.62 Average precision query 2 = (0.5+0.4+0.43)/3 = 0.44 MAP = (0.62 + 0.44)/2 = 0.53', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Average Precision (MAP) • If a relevant document never gets retrieved, we assume  the precision corresponding to that relevant document  to be zero.  • MAP is macro-averaging: each query counts equally. • A commonly used measure in current IR research, along  with P/R/F', 'page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Mean Reciprocal Rank • Consider rank position, K, of first relevant doc – Could be only clicked doc • Reciprocal Rank score = • MRR is the mean RR across multiple queries   K 1', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Multiple Levels of Relevance • Documents are rarely entirely relevant or non-relevant  to a query. • Many sources of graded relevance judgments: – Relevance judgments on a 5-point scale. – Averaging among multiple judges.', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Cummulative Gain • With graded relevance  judgments, we can compute  the gain at each rank. • Cumulative Gain at rank n: – Where reli is the graded  relevance of the document at  position i. n doc # relevance  (gain) CGn 1 588 1.0 1.0 2 589 0.6 1.6 3 576 0.0 1.6 4 590 0.8 2.4 5 986 0.0 2.4 6 592 1.0 3.4 7 984 0.0 3.4 8 988 0.0 3.4 9 578 0.0 3.4 10 985 0.0 3.4 11 103 0.0 3.4 12 591 0.0 3.4 13 772 0.2 3.6 14 990 0.0 3.6', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Discounted Cumulative Gain • Users care more about high- ranked documents, so we  discount results by  1/log2(rank) • Popular measures for  evaluating web search and  related tasks. • Discounted Cumulative Gain: n doc # rel  (gain) CGn logn DCGn 1 588 1.0 1.0 - 1.00 2 589 0.6 1.6 1.00 1.60 3 576 0.0 1.6 1.58 1.60 4 590 0.8 2.4 2.00 2.00 5 986 0.0 2.4 2.32 2.00 6 592 1.0 3.4 2.58 2.39 7 984 0.0 3.4 2.81 2.39 8 988 0.0 3.4 3.00 2.39 9 578 0.0 3.4 3.17 2.39 10 985 0.0 3.4 3.32 2.39 11 103 0.0 3.4 3.46 2.39 12 591 0.0 3.4 3.58 2.39 13 772 0.2 3.6 3.70 2.44 14 990 0.0 3.6 3.81 2.44', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Normalized Discounted  Cumulative Gain (NDCG) • To compare DCGs, normalize values so that an ideal  ranking would have a Normalized DCG of 1.0. • Ideal ranking: n doc # rel  (gain) CGn logn DCGn 1 588 1.0 1.0 0.00 1.00 2 589 0.6 1.6 1.00 1.60 3 576 0.0 1.6 1.58 1.60 4 590 0.8 2.4 2.00 2.00 5 986 0.0 2.4 2.32 2.00 6 592 1.0 3.4 2.58 2.39 7 984 0.0 3.4 2.81 2.39 8 988 0.0 3.4 3.00 2.39 9 578 0.0 3.4 3.17 2.39 10 985 0.0 3.4 3.32 2.39 11 103 0.0 3.4 3.46 2.39 12 591 0.0 3.4 3.58 2.39 13 772 0.2 3.6 3.70 2.44 14 990 0.0 3.6 3.81 2.44 n doc # rel  (gain) CGn logn IDCGn 1 588 1.0 1.0 0.00 1.00 2 592 1.0 2.0 1.00 2.00 3 590 0.8 2.8 1.58 2.50 4 589 0.6 3.4 2.00 2.80 5 772 0.2 3.6 2.32 2.89 6 576 0.0 3.6 2.58 2.89 7 986 0.0 3.6 2.81 2.89 8 984 0.0 3.6 3.00 2.89 9 988 0.0 3.6 3.17 2.89 10 578 0.0 3.6 3.32 2.89 11 985 0.0 3.6 3.46 2.89 12 103 0.0 3.6 3.58 2.89 13 591 0.0 3.6 3.70 2.89 14 990 0.0 3.6 3.81 2.89', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Normalized Discounted  Cumulative Gain (NDCG) • Normalize by DCG of the  ideal ranking: – NDCG ≤ 1 at all ranks. • NDCG is now comparable  across different queries: – Useful for contrasting  queries with varying  numbers of relevant results. – Quite popular for Web  search.', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Evaluation with Clickthrough Data # of clicks received Strong position bias, so absolute click rates unreliable', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Pairwise Relative Ratings • Pairs of the form: DocA better than DocB for a query – Doesn’t mean that DocA relevant to query • Rather than assess a rank-ordering with respect to per- doc relevance assessments • Assess in terms of conformance with historical pairwise  preferences recorded from user clicks', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Comparing two rankings to a baseline  ranking • Given a set of pairwise preferences P • We want to measure two rankings A and B • Define a proximity measure between A and P – And likewise, between B and P • Want to declare the ranking with better proximity to be  the winner • Proximity measure should reward agreements with P  and penalize disagreements', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Kendall-tau Distance to Compare Rankings • Generate all pairs for each ranking • Let X be the number of agreements between a ranking  (say A) and P • Let Y be the number of disagreements • Then the Kendall tau distance between A and P is  (X-Y)/(X+Y)', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Exercise • Assume perfect ranking P = (1, 2, 3, 4) • Assume two candidate rankings A = (1, 3, 2, 4) and B =  (4, 1, 2, 3) • Which candidate ranking is closer to the perfect ranking  according to Kendall-tau?', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  A/B Testing at Web Search Engines  • Can exploit an existing user base to provide useful  feedback on a single innovation • Randomly send a small fraction (1−10%) of incoming  users to a variant of the system that includes a single  change. – Have most users use the old system • Judge effectiveness by measuring change in clickthrough:  the percentage of users that click on the top result (or  any result on the first page) • Probably the evaluation methodology that large search  engines trust the most', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Amazon Mechanical Turk Testing • https://requester.mturk.com/', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Standard Methodology for Measuring  Relevance in IR • To measure relevance effectiveness of ad-hoc IR, we  need: 1. A document collection. 2. A suite of information needs, expressible as  queries. • Must be representative of actual user needs. • Sample from query logs, if available. 3. Binary assessments of either Relevant or  Nonrelevant for each query and each document. • Can be more nuanced, e.g., 0, 1, 2, 3, … • Use pooling, when it is unfeasible to assess every (q, d)  pair.', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Early Test Collections • Previous experiments were based on the SMART  collection which is fairly small.  (ftp://ftp.cs.cornell.edu/pub/smart)      Collection Number Of Number Of Raw Size       Name   Documents Queries  (Mbytes)       CACM 3,204    64  1.5       CISI  1,460  112  1.3       CRAN  1,400  225  1.6       MED  1,033    30  1.1       TIME    425    83  1.5  • Different researchers used different test collections and  evaluation techniques.', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  The TREC Benchmark • TREC: Text REtrieval Conference (http://trec.nist.gov/) – Originated from the TIPSTER program sponsored by Defense  Advanced Research Projects Agency (DARPA). – Became an annual conference in 1992, co-sponsored by the      National Institute of Standards and Technology (NIST) and   DARPA. – Participants are given parts of a standard set of documents and  TOPICS (from which queries have to be derived) in  different  stages for training and testing. – Participants submit the P/R values for the final document and  query corpus and present their results at  the conference.', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  TREC Objectives • Provide a common ground for comparing different IR  techniques. – Same set of documents and queries, and same evaluation  method • Sharing of resources and experiences in developing the  benchmark. – With major sponsorship from government to develop large  benchmark collections • Encourage participation from industry and academia. • Development of new evaluation techniques, particularly  for new applications. – Retrieval, routing/filtering, non-English collection, web-based  collection, question answering', 'page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  TREC Advantages • Large scale (compared to a few MB in the SMART  Collection). • Relevance judgments provided. • Under continuous development with support from the  U.S. Government. • Wide participation: – TREC 1: 28 papers 360 pages. – TREC 4: 37 papers 560 pages. – TREC 7: 61 papers 600 pages.  – TREC 8: 74 papers.', 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  TREC Tasks • Ad hoc: New questions are being asked on a static set  of data.  • Routing: Same questions are being asked, but new  information is being searched. (news clipping, library  profiling). • New tasks added after TREC 5: – Interactive, multilingual, natural language, multiple database  merging, filtering, very large corpus (20 GB, 7.5 million  documents), question answering.', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  The TREC Collection • Both long and short documents (from a few hundred  to over one thousand unique terms in a document). – Both SGML documents and SGML queries contain many  different kinds of information (fields). – Generation of the formal queries (Boolean, Vector Space,  etc.) is the responsibility of the system. • A system may be very good at ranking, but if it generates poor  queries from the topic, its final P/R would be poor. • Test documents consist of:      WSJ Wall Street Journal articles (1986 -1992)  550 M       AP   Associate Press Newswire (1989)     514 M      ZIFF Computer Select Disks (Ziff -Davis Publishing) 493 M       FR   Federal Register    469 M       DOE Abstracts from Department of Energy reports 190 M', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Sample SGML Document <DOC>  <DOCNO> WSJ870324-0001 </DOCNO>  <HL> John Blair Is Near Accord To Sell Unit, Sources Say </HL>  <DD> 03/24/87</DD>  <SO> WALL STREET JOURNAL (J) </SO> <IN> REL TENDER OFFERS, MERGERS, ACQUISITIONS (TNM) MARKETING,  ADVERTISING (MKT) TELECOMMUNICATIONS, BROADCASTING,  TELEPHONE, TELEGRAPH (TEL) </IN>  <DATELINE> NEW YORK </DATELINE>  <TEXT>      John Blair &amp; Co. is close to an agreement to sell its TV station  advertising representation operation and program production unit to an  investor group led by James  H. Rosenfield, a former CBS Inc. executive,  industry sources said. Industry sources put the value of the proposed  acquisition at more than $100 million. ...  </TEXT>  </DOC>', \"page_label: 56 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/06IREvaluation.pdf  Sample SGML Query <top>  <head> Tipster Topic Description  <num> Number: 066  <dom> Domain: Science and Technology  <title> Topic: Natural Language Processing  <desc> Description: Document will identify a type of natural language  processing technology which is being developed or marketed in the U.S.  <narr> Narrative: A relevant document will identify a company or institution  developing or marketing a natural language processing technology, identify  the technology, and identify one of more features of the company's  product. <con> Concept(s):  1. natural language processing ;2. translation, language,  dictionary <fac> Factor(s):  <nat> Nationality: U.S.</nat> </fac>  <def> Definitions(s):  </top>\", 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  INFORMATION RETRIEVAL  Soujanya Poria', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Syllabus•Week 1 – Introduction to IR, Boolean and ranked retrieval.•Week 2 – Locally Sensitive Hashing•Week 3 –  Probabilistic IR / BM-25•Week 4 – Relevance feedback and IR Evaluation•Week 5 – Index Creation & Compression•Week 6 – Transformers and Language Models•Week 7 – Term Break•Week 8 – Midterm•Week 9 – Knowledge guided retrieval from LLM', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Syllabus•Week 10 – Learning to Rank•Week 11 – LLM-based IR’s Safety Measurement•Week 12 – Pagerank Algorithm•Week 13 – Project Presentation', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Words of Wisdom!•I have just crossed my 30  😁 – stop calling me Prof. Call me SJ. How cool it is  😁•My handwriting is horrible  🥲–Tell me when you do not understand what I wrote on the whiteboard.•Getting good marks is super easy!–Focus on learning and applying new things.•Ask me 100 of questions!', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  What can you expect in this course?•You use Google everyday: learn how it works!•Learn how the new Bing search works!•Learn how you can use machine learning and AI tools to mine your desired information from the web!•Clear your misconception: IR is not just web scraping!•Opportunity to participate in cool projects!', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Book to readhttp://nlp.stanford.edu/IR-book/pdf/00front.pdf', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  INFORMATION RETRIEVAL Boolean retrieval', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Typical IR task•Input:–A large collection of unstructured text documents.–A user query expressed as text.•Output:–A ranked list of documents that are relevant to the query. IR SystemQuery String DocumentcorpusRankedDocuments1. Doc12. Doc23. Doc3    .    .', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Generative IR task•Input:–A large collection of unstructured text documents.–A user query expressed as text.•Output:–A textual response with user’s desired information.', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Boolean  Typical IR task•Input:–A large collection of unstructured text documents.–A user query expressed as text.•Output:–A ranked list of documents that are relevant to the query. IR SystemQuery String DocumentcorpusRankedDocuments1. Doc12. Doc23. Doc3    .    .', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Boolean retrieval•Information Need: Which plays by Shakespeare mention Brutus and Caesar, but not Calpurnia?•Boolean Query: Brutus AND Caesar AND NOT Calpurnia•Possible search procedure:–Linear scan through all documents (Shakespeare’s collected works).–Compile list of documents that contain Brutus and Caesar, but not Calpurnia.–Advantage: simple, it works for moderately sized corpora.–Disadvantage: need to do linear scan for every query Þ slow for large corpora.', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Term-document incidence matrices Antony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony1 1 0 0 0 1Brutus1 1 0 1 0 0Caesar1 1 0 1 1 1Calpurnia0 1 0 0 0 0Cleopatra1 0 0 0 0 0mercy1 0 1 1 1 1worser1 0 1 1 1 0 1 if document contains word, 0 otherwise •Precompute a data structure that makes search fast for every query.', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Term-document incidence matrix M Brutus AND Caesar AND NOT CalpurniaQuery =  Antony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony1 1 0 0 0 1Brutus1 1 0 1 0 0Caesar1 1 0 1 1 1Calpurnia0 1 0 0 0 0Cleopatra1 0 0 0 0 0mercy1 0 1 1 1 1worser1 0 1 1 1 0 Answer = M(Brutus) Ù M(Caesar) Ù¬ M(Calpurnia) = 1 1 0 1 0 0 Ù 1 1 0 1 1 1 Ù 1 0 1 1 1 1 = 1 0 0 1 0 0 Þ Anthony and Cleopatra, Hamlet       110100 Ù110111 Ù101111100100', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Answers to Query•Antony and Cleopatra, Act III, Scene ii Agrippa [Aside to DOMITIUS ENOBARBUS]: Why, Enobarbus,                           When Antony found Julius Caesar dead,                             He cried almost to roaring; and he wept                            When at Philippi he found Brutus slain. •Hamlet, Act III, Scene ii Lord Polonius: I did enact Julius Caesar I was killed i’ the      Capitol; Brutus killed me.', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Scalability: Dense Format•Assume:–Corpus has 1 million documents.–Each document is about 1,000 words long.–Each word takes 6 bytes, on average.–Of  the 1 billion word tokens 500,000 are unique. •Then:–Corpus storage takes:•1M * 1, 000 * 6 = 6GB–Term-Document incidence matrix would take:•500,000 * 1,000,000 = 0.5 * 1012 bits', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Scalability: Sparse Format•Of the 500 billion entries, at most 1 billion are non-zero.Þ at least 99.8% of the entries are zero.Þ use a sparse representation to reduce storage size! •Store only non-zero entries Þ Inverted Index.', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index for Boolean Retrieval •Map each term to a posting list of documents containing  it–Identify each document by a numerical docID.–Dictionary of terms usually in memory.–Posting list:•linked lists of variable-sized array, if in memory.•contiguous run of postings, if on disk.Brutus CalpurniaCaesar124561657132124113145173 231 174 54101 DictionaryPostings', \"page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 1•Assemble sequence of átoken, docIDñ pairs.–assume text has been tokenized  17 I did enact JuliusCaesar I was killed i' the Capitol; Brutus killed me. Doc 1 So let it be withCaesar. The nobleBrutus hath told youCaesar was ambitious Doc 2\", 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 2•Sort by terms, then by docIDs.', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 3•Merge multiple term entries per document.•Split into dictionary and posting lists.–keep posting lists sorted, for efficient query processing. •Add document frequency information:–useful for efficient query processing.–also useful later in document ranking.', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Inverted Index: Step 3', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Processing: AND•Consider processing the query:Brutus AND Caesar–Locate Brutus in the Dictionary;•Retrieve its postings.–Locate Caesar in the Dictionary;•Retrieve its postings.–“Merge” the two postings (intersect the document sets): 1283424816326412358132128 BrutusCaesar', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Processing: AND Merge Algorithm', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Processing: OR•Exercise: Adapt the merge algorithm for the query: Brutus OR Caesar', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Optimization:What is the best order for query processing?•Consider a query that is an AND of n terms.1283424 8163264123581321BrutusCaesarCalpurnia1316 Query: Brutus AND Calpurnia AND Caesar –  For each of the n terms, get its postings, then AND them together.–  Process in order of increasing freq:•  start with smallest set, then keep cutting further.•  use document frequencies stored in the dictionary.Þ execute the query as (Calpurnia AND Brutus) AND Caesar', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf  Query Optimization•Exercise: recommend a query processing order for:–(tangerine OR trees) AND    (marmalade OR skies) AND    (kaleidoscope OR eyes)–which two terms should we process first? Term Freq     eyes 213312   kaleidoscope 87009   marmalade 107913   skies 271658   tangerine 46653   trees 316812', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  INFORMATION RETRIEVAL IR models: Vector Space Model', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Information Retrieval  and Web SearchIR models: Vector Space Model [Note: Some slides in this set were adapted from an IR course taught by Ray Mooney at UT Austin (who in turn adapted them from Joydeep Ghosh), and from an IR course taught by Chris Manning at Stanford)', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Ranked Retrieval•Thus far, our queries have all been Boolean–Documents either match or don’t•Good for expert users with precise understanding of their needs and the collection–Also good for applications: Applications can easily consume 1000s of results•Not good for the majority of users–Most users incapable of writing Boolean queries (or they are, but they think it’s too much work)–Most users don’t want to wade through 1000s of results•This is particularly true of Web search Ch. 6', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Problem with Boolean Search•Boolean queries often result in either too few (=0) or too many (1000s) results.•Query 1: “standard user dlink 650” → 200,000 hits•Query 2: “standard user dlink 650 no card found”: 0 hits•It takes a lot of skill to come up with a query that produces a manageable number of hits.–AND gives too few; OR gives too many•Hard to tune precision vs. recall:–AND operator tends to produce high precision but low recall.–OR operator gives low precision but high recall.–Difficult/impossible to find satisfactory middle ground. Ch. 6', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Ranked Retrieval Models•Rather than a set of documents satisfying a query expression, in ranked retrieval, the system returns an ordering over the (top) documents in the collection for a query•Free text queries: Rather than a query language of operators and expressions, the user’s query is just one or more words in a human language•In principle, there are two separate choices here, but in practice, ranked retrieval has normally been associated with free text queries and vice versa', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Not a Problem in Ranked Retrieval•When a system produces a ranked result set, large result sets are not an issue–Indeed, the size of the result set is not an issue–We just show the top k ( ≈ 10) results–We don’t overwhelm the user–Premise: the ranking algorithm works Ch. 6', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Scoring as the Basis of Ranked Retrieval•We wish to return in order the documents most likely to be useful to the searcher•How can we rank-order the documents in the collection with respect to a query?•Assign a score – say in [0, 1] – to each document•This score measures how well the document and the query “match” Ch. 6', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Query-document Matching Scores•We need a way of assigning a score to a query/document pair•Let’s start with a one-term query•If the query term does not occur in the document: score should be 0•The more frequent the query term in the document, the higher the score (should be)', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Take 1: Jaccard coefficient•Jaccard: A commonly used measure of overlap of two sets A and B•Jaccard(A,B) = |A ∩ B| / |A ∪ B|•Jaccard(A,A) = 1•Jaccard(A,B) = 0 if A ∩ B = 0•A and B don’t have to be the same size.•Always assigns a number between 0 and 1. Ch. 6', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Jaccard Coefficient: Scoring ExampleAssume the following query:•Query: march of dimesAnd the following two documents:•Document 1: caesar died in march•Document 2: the long march Ch. 6 According to the Jaccard coeficient, which document is more similar to the query (assume no stopword removal):A)Doc 1 B)Doc 2C)Both documents have the same similarity'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'204'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'989657'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'620ms'), (b'x-request-id', b'req_9421a6deb34c1300b86c3e007b740392'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c42080bf8a083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'204'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'989657'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'620ms'), (b'x-request-id', b'req_9421a6deb34c1300b86c3e007b740392'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c42080bf8a083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'204'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'989657'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'620ms'), (b'x-request-id', b'req_9421a6deb34c1300b86c3e007b740392'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c42080bf8a083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '204', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '989657', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '620ms', 'x-request-id': 'req_9421a6deb34c1300b86c3e007b740392', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c42080bf8a083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '204', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '989657', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '620ms', 'x-request-id': 'req_9421a6deb34c1300b86c3e007b740392', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c42080bf8a083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '204', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '989657', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '620ms', 'x-request-id': 'req_9421a6deb34c1300b86c3e007b740392', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c42080bf8a083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_9421a6deb34c1300b86c3e007b740392\n",
      "request_id: req_9421a6deb34c1300b86c3e007b740392\n",
      "request_id: req_9421a6deb34c1300b86c3e007b740392\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96b380>, 'json_data': {'input': ['page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Issues with Jaccard for Scoring•It does not consider term frequency (how many times a term occurs in a document)•Rare terms in a collection are more informative than frequent terms. Jaccard does not consider this information•We need a more sophisticated way of normalizing for length Ch. 6', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Recall (from Boolean Retrieval): Binary Term-Document Incidence MatrixAntony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony1 1 0 0 0 1Brutus1 1 0 1 0 0Caesar1 1 0 1 1 1Calpurnia0 1 0 0 0 0Cleopatra1 0 0 0 0 0mercy1 0 1 1 1 1worser1 0 1 1 1 0 Each document is represented by a binary vector ∈ {0,1}|V| Sec. 6.2', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term-document Count Matrices•Consider the number of occurrences of a term in a document: –Each document is a count vector: a column below  Antony and Cleopatra Julius Caesar The Tempest Hamlet Othello Macbeth Antony 157 73 0 0 0 0 Brutus 4 157 0 1 0 0 Caesar 232 227 0 2 1 1 Calpurnia 0 10 0 0 0 0 Cleopatra 57 0 0 0 0 0 mercy 2 0 3 5 5 1 worser 2 0 1 1 1 0 Sec. 6.2', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Vector-Space Model•t distinct terms remain after preprocessing–Unique terms that form the VOCABULARY•These “orthogonal” terms form a vector space.          Dimension = t = |vocabulary| –2 terms à bi-dimensional; …; n-terms à n-dimensional•Each term, i,  in a document or query j, is given a real-valued weight, wij.•Both documents and queries are expressed as t-dimensional vectors:          dj = (w1j, w2j, …, wtj)', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Vector-Space ModelQuery as vector:•We regard query as short document•We return the documents ranked by the closeness of their vectors to the query, also represented as a vector. •Vector-space model was developed in the SMART system (Salton, c.1970) and standardly used by TREC participants and web IR systems', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Graphic RepresentationExample:D1 = 2T1 + 3T2 + 5T3D2 = 3T1 + 7T2 +   T3Q = 0T1 + 0T2 +  2T3 T3 T1 T2 D1 = 2T1+ 3T2 + 5T3 D2 = 3T1 + 7T2 +  T3 Q = 0T1 + 0T2 + 2T3 7 32 5 •Is D1 or D2 more similar to Q?•How to measure the degree of similarity? Distance? Angle? Projection?', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Collection Representation•A collection of n documents can be represented in the vector space model by a term-document matrix.•An entry in the matrix corresponds to the “weight” of a term in the document; zero means the term has no significance in the document or it simply doesn’t exist in the document.T1   T2    ….      TtD1    w11  w21   …      wt1D2 w12  w22   …      wt2 :       :      :               : :       :      :               :Dn    w1n  w2n   …      wtn', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Frequency tf•The term frequency tft,d of term t in document d is defined as the number of times that t occurs in d.•More frequent terms in a document are more important, i.e. more indicative of the topic.•May want to normalize term frequency (tf) :        tft,d   = ft,d  / max{ft,d}•We want to use tf when computing query-document match scores. But how?', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Frequency tf•Raw term frequency is not what we want:–A document with 10 occurrences of the term is more relevant than a document with 1 occurrence of the term.–But not 10 times more relevant.•Relevance does not increase proportionally with term frequency.', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Frequency•Rare terms are more informative than frequent terms–Recall stop words•Consider a term in the query that is rare in the collection (e.g., arachnocentric)•A document containing this term is very likely to be relevant to the query arachnocentric•→ We want a high weight for rare terms like arachnocentric. Sec. 6.2.1', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Frequency (continued)•Frequent terms are less informative than rare terms•Consider a query term that is frequent in the collection (e.g., high, increase, line)•A document containing such a term is more likely to be relevant than a document that doesn’t•But it’s not a sure indicator of relevance.•→ For frequent terms, we want high positive weights for words like high, increase, and line•But lower weights than for rare terms.•We will use document frequency (df) to capture this. Sec. 6.2.1', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Idf Weight•dft is the document frequency of t: the number of documents that contain t–dft is an inverse measure of the informativeness of t–dft £ N•We define the idf (inverse document frequency) of t by–We use log (N/dft) instead of N/dft to “dampen” the effect of idf.idft = log10 (N/dft)Sec. 6.2.1', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  idf example, suppose N = 1 millionterm dft idftcalpurnia 1animal 100sunday 1,000fly 10,000under 100,000the 1,000,000 There is one idf value for each term t in a collection. Sec. 6.2.1 )/df( log  idf 10 tt N=', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Collection vs. Document Frequency•The collection frequency of t is the number of occurrences of t in the collection, counting multiple occurrences.•Example: •Which word is a better search term (and should get a higher weight)? WordCollection frequencyDocument frequency insurance10440 3997try 9800 8760 Sec. 6.2.1', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  tf-idf Weighting•The tf-idf weight of a term is the product of its tf weight and its idf weight. •Best known weighting scheme in information retrieval–Theoretically proven to work well (Papineni, NAACL 2001)–Note: the “-” in tf-idf is a hyphen, not a minus sign!–Alternative names: tf.idf, tf x idf•Increases with the number of occurrences within a document•Increases with the rarity of the term in the collection wt,d=tft,d×log10(N/dft)Sec. 6.2.2', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Computing tf-idf: An ExampleGiven a document containing terms with given frequencies:    A(3), B(2), C(1)Assume collection contains 10,000 documents and document frequencies of these terms are:    A(50), B(2500), C(100)Then (assuming log10)A:  tf = 3/3;  idf = log(10000/50) = 2.3;     tf-idf = 2.3B:  tf = 2/3;  idf = log(10000/2500) = 0.60; tf-idf = 0.40C:  tf = 1/3;  idf = log(10000/100) = 2.0;   tf-idf = 0.66', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Binary → Count → Weight matrixAntony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony5.253.180 0 0 0.35Brutus1.216.10 1 0 0Caesar8.592.540 1.510.250Calpurnia0 1.540 0 0 0Cleopatra2.850 0 0 0 0mercy1.510 1.90.125.250.88worser1.370 0.114.150.251.95 Each document is now represented by a real-valued vector of tf-idf weights ∈ R|V| Sec. 6.3', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Documents as Vectors•So we have a |V|-dimensional vector space•Terms are axes of the space•Documents are points or vectors in this space•Very high-dimensional: tens of millions of dimensions when you apply this to a web search engine•These are very sparse vectors - most entries are zero. Sec. 6.3', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Query as Vector•Query vector is typically treated as a document and also tf-idf weighted.•Alternative is for the user to supply weights for the given query terms.', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Similarity Measure•We now have vectors for all documents in the collection, a vector for the query, how to compute similarity? •A similarity measure is a function that computes the degree of similarity between two vectors.•Using a similarity measure between the query and each document:–It is possible to rank the retrieved documents in the order of presumed relevance.–It is possible to enforce a certain threshold so that the size of the retrieved set can be controlled.', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  First Cut: Euclidean Distance•Distance between vectors d1 and d2 is the length of the vector |d1 – d2|.–Euclidean distance•Exercise: Determine the Euclidean distance between the vectors (0, 3, 2, 1, 10) and (2, 7, 1, 0, 0)•Why is this not a great idea?•We still haven’t dealt with the issue of length normalization–Long documents would be more similar to each other by virtue of length, not topic', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Second Cut: Manhattan Distance•Or “city block” measure–Based on the idea that generally in American cities you cannot follow a direct line between two points. •Uses the formula: •Exercise: Determine the Manhattan distance between the vectors (0, 3, 2, 1, 10) and (2, 7, 1, 0, 0) x y å = -= n i ii yxYXManhDist 1 ||),(', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Third Cut: Inner Product•Similarity between vectors for the document di and query q can be computed as the vector inner product:               sim(dj,q) = dj•q =      wij · wiq        where wij is the weight of term i in document j and wiq is the weight of term i in the query•For binary vectors, the inner product is the number of matched query terms in the document (size of intersection).•For weighted term vectors, it is the sum of the products of the weights of the matched terms. å = t i 1', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Properties of Inner Product•Favors long documents with a large number of unique terms.–Again, the issue of normalization•Measures how many terms matched but not how many terms are not matched.', 'page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  InnerProductExercise k1 k2 k3 q • dj  d1 1 0 1 ?  d2 1 0 0 ?  d3 0 1 1 ?  d4 1 0 0 ?  d5 1 1 1 ?  d6 1 1 0 ?  d7 0 1 0 ?        q 1 2 3', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity•Distance between vectors d1 and d2 captured by the cosine of the angle x between them.•Note – this is similarity, not distance t 1 d2 d1 t 3 t 2 θ', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity •Cosine of angle between two vectors•The denominator involves the lengths of the vectors•So the cosine measure is also known as the normalized inner product åå å == = = × = n i ki n i ji n i kiji kj kj kj ww ww dd dd ddsim 1 2 ,1 2 , 1 ,, ),( \\uf072\\uf072 \\uf072\\uf072 å = = n i jij wd 1 2 , Length \\uf072', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity Exercise•Exercise: Rank the following by decreasing cosine similarity:–(P1) Two documents that have only frequent words (the, a, an, of) in common.–(P2) Two documents that have no words in common.–(P3) Two documents that have many rare words in common (wingspan, tailfin). The ranking in decreasing order of their cosine similarity will be:A)P1, P3, P2B)P3, P2, P1C)P3, P1, P2', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity Example•Documents: Sense and Sensibility, Pride and Prejudice; Wuthering Heights  •cos(SaS,PaP) ≈ 0.789 × 0.832 + 0.515 × 0.555 + 0.335 × 0.0 + 0.0 × 0.0 ≈ 0.94•cos(SaS,WH) ≈ 0.79•cos(PaP,WH) ≈ 0.69 termSaSPaPWHaffection11558 20jealous10 7 11gossip2 0 6wuthering0 0 38 termSaSPaPWHaffection0.7890.8320.524jealous0.5150.5550.465gossip0.33500.405wuthering0 00.588 Why do we have cos(SaS,PaP) > cos(SaS,WH)?', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity vs. Inner Product•Cosine similarity measures the cosine of the angle between two vectors.•Inner product normalized by the vector lengths.    D1 = 2T1 + 3T2 + 5T3     CosSim(D1 , Q) = 10 / Ö(4+9+25)(0+0+4) = 0.81D2 = 3T1 + 7T2 + 1T3     CosSim(D2 , Q) =  2 / Ö(9+49+1)(0+0+4) = 0.13 Q = 0T1 + 0T2 + 2T3 q2 t3 t1 t2 D1 D2 Qq1 D1 is 6 times better than D2 using cosine similarity but only 5 times better using inner product. å å å = = = • × × = × t i t i t i ww ww qd qd iqij iqij j j 1 1 22 1 )( \\uf072\\uf072 \\uf072\\uf072 CosSim(dj, q) = qd j \\uf072\\uf072 •InnerProduct(dj, q) =', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  ExerciseConsider the following four documents:•Doc1: apple orange banana peach•Doc2: orange orange apple apple•Doc3: banana tangerine peach•Doc4: peach peach apple bananaAnd the query:•Query: apple peach tangerineAssume no pre-processing (i.e., no normalization, no case-folding, no stopword-removal, no stemming), and a tfidf weighting scheme (tf not normalized, log based 10 for idf).1. Write the vector representations for each of the four documents and for the query.2. Determine the cosine similarities between each document and the query, and rank the documents.', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Comments on Vector Space Models•Simple, mathematically based approach. •Considers both local (tf) and global (idf) word occurrence frequencies.•Provides partial matching and ranked results.•Tends to work quite well in practice despite obvious weaknesses.•Allows efficient implementation for large document collections.', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Problems with Vector Space Model•Missing semantic information (e.g. word sense).•Missing syntactic information (e.g. phrase structure, word order, proximity information).•Assumption of term independence•Lacks the control of a Boolean model (e.g., requiring a term to appear in a document).–Given a two-term query “A B”, may prefer a document containing A frequently but not B, over a document that contains both A and B, but both less frequently.', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Evaluation of IR ModelsPrecision & Recall', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Standard Evaluation Measures w x y z n2 = w + y n1 = w + x N relevant not relevant retrievednot retrievedStart with a CONTINGENCY table', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Precision and Recall Recall: Precision: w w+y w+x w From all the documents that are relevant out there,how many did the IR system retrieve? From all the documents that are retrieved by the IR system, how many are relevant?', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Precision and Recall for a Set of Queries•For each query, determine the retrieved documents and the relevant documents  •Calculate–Macro-average: average the P/R/F calculated for the individual queries–Micro-average: sum all/relevant documents for individual queries, and calculate P/R/F only once', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Weighting Approaches', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Graphic RepresentationExample:D1 = 2T1 + 3T2 + 5T3D2 = 3T1 + 7T2 +   T3Q = 0T1 + 0T2 +  2T3 T3 T1 T2 D1 = 2T1+ 3T2 + 5T3 D2 = 3T1 + 7T2 +  T3 Q = 0T1 + 0T2 + 2T3 7 32 5 •Is D1 or D2 more similar to Q?•How to measure the degree of similarity? Distance? Angle? Projection?', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Collection Representation•A collection of n documents can be represented in the vector space model by a term-document matrix.•An entry in the matrix corresponds to the “weight” of a term in the document; zero means the term has no significance in the document or it simply doesn’t exist in the document.T1   T2    ….      TtD1    w11  w21   …      wt1D2 w12  w22   …      wt2 :       :      :               : :       :      :               :Dn    w1n  w2n   …      wtn', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Salton & Buckley•Experiments with term weighting approaches•Six collections, 1,800 term weighting approaches–287 combinations found to be distinct•Comparative evaluations using:–Ranking: the lower the better–Best weighting scheme has a rank of 1•Average search precision:–Average of precisions for recall points of 0.25, 0.50, 0.75•Average across queries:–Macro-average: average of the average search precisions', \"page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  IR Test Collections•CACM (articles from 'Communications of the ACM journal)•CISI (articles about information sciences)•CRAN (abstracts from aeronautics articles)•INSPEC (articles in computer engineering)•MED (medical articles) •NPL (articles about electrical engineering)\", 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  IR Collections', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Weighting Components', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Sample Weighting Schemes', 'page_label: 56 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Performance Results', 'page_label: 57 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Lessons Learned•Term weighting DOES matter•Query vector:–Term frequency•Use n for short queries•Use t for longer queries that require better discrimination among terms–Document frequency•Use f –Do not do normalization with query length', 'page_label: 58 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Lessons Learned•Document vectors:–Term-frequency:•For technical vocabulary (e.g., CRAN) use n•For more varied vocabulary, use t•For short document vectors, use b–Document frequency:•Inverse document-frequency f is similar to probabilistic term weight p: typically use f•For dynamic collections with many changes in the document collection makeup, use x–Normalization:•Typically use c (in particular when there is high deviation in vector length)•For short documents with homogenous length, use x', 'page_label: 59 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Vector Space Model Implementation', 'page_label: 60 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Naïve ImplementationConvert all documents in collection D to TF.IDF weighted vectors, dj, for keyword vocabulary V.Convert query to a tf-idf-weighted vector q.For each dj in D do      Compute score sj = cosSim(dj, q)Sort documents by decreasing score.Present top ranked documents to the user.Time complexity:  O(|V|·|D|)   Bad for large V & D !|V| = 10,000; |D| = 100,000; |V|·|D| = 1,000,000,000', 'page_label: 61 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Practical Implementation•Based on  the observation that documents containing none of the query keywords do not affect the final ranking•Try to identify only those documents that contain at least one query keyword•Actual implementation of an inverted index', 'page_label: 62 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 1: Preprocessing•Implement the preprocessing functions:–For tokenization–For stop word removal–For stemming •Input: Documents that are read one by one from the collection•Output: Tokens to be added to the index–No punctuation, no stop-words, stemmed', 'page_label: 63 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2: Indexing•Build an inverted index, with an entry for each word in the vocabulary •Input: Tokens obtained from the preprocessing module•Output: An inverted index for fast access', 'page_label: 64 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2 (continued)•Many data structures are appropriate for fast access•We need:–One entry for each word in the vocabulary–For each such entry:•Keep a list of all the documents where it appears together with the corresponding frequency à TF–For each such entry, keep the total number of occurrences in all documents:•à IDF', 'page_label: 65 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2 (continued) system computerdatabase scienceD2, 4D5, 2 D1, 3D7, 4Index termsdf32 41 Dj, tfj Index filelists •••', 'page_label: 66 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2 (continued)•TF and IDF for each token can be computed in one pass •Cosine similarity also requires document lengths•Need a second pass to compute document vector lengths–Remember that the length of a document vector is the square-root of sum of the squares of the weights of its tokens.–Remember the weight of a token is: TF * IDF–Therefore, must wait until IDFs are known (and therefore until all documents are indexed) before document lengths can be determined.•Do a second pass over all documents: keep a list or hashtable with all document id-s, and for each document determine its length.', 'page_label: 67 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Time Complexity of Indexing•Complexity of creating vector and indexing a document of n tokens is O(n).•So indexing |D| such documents is O(|D| n).•Computing token IDFs can be done during the same first pass•Computing vector lengths is also O(|D| n).•Complete process is O(|D| n), which is also the complexity of just reading in the corpus.', 'page_label: 68 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 3: Retrieval •Use inverted index (from step 2) to find the limited set of documents that contain at least one of the query words.•Incrementally compute cosine similarity of each indexed document as query words are processed one by one.–If tf is normalized for the query, may need to first read all the query tokens•To accumulate a total score for each retrieved document, store retrieved documents in a hashtable (or another search data structure), where the document id is the key, and the partial accumulated score is the value.•Input: Query and Inverted Index (from Step 2)•Output: Similarity values between query and documents', 'page_label: 69 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 4: Ranking•Sort the search structure including the retrieved documents based on the value of cosine similarity•Return the documents in descending order of their relevance •Input: Similarity values between query and documents•Output: Ranked list of documented in reversed order of their relevance', 'page_label: 70 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Tfidf vectorizerIn the class, we learnt how to convert a document into a vector using tf-idf. While implementing a function for tf-idfis very easy, you can do that also using a library. Follow the code below.', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Information Retrieval and  Web SearchWord Representations', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Why Word Representations?•Computing with words–How similar is ‘car’ to ‘vehicle’? –How about ‘car’ to ‘wheel’?–How about ’car’ to ‘moon’?–How far is ‘man’ from ‘woman’?–How about ‘king’ from ‘queen’? •Mathematical representations of words, typically as vectors, that allow for computations–Measure similarity / distance between words', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Embeddings for IR•Compute similarity between query and documents using embedding vectors•Sum up all the embeddings to create one embedding for the document; one embedding for the query•Compute inner product or cosine similarity between these vectors•Note: embeddings are not transferable across spaces–The entries in the vector of embeddings have meaning only in the space where they were learned!', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Representations in IR/NLP•Core component in large number of IR tasks and applicationsQuery: ISTD SUTD But what if the words do not actually occur in the documents?', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Representations in IR/NLPQuestion answering:Q: “How tall is Mt. Everest?”Candidate A: “The official height of Mount Everest is 29029 feet” “tall” is similar to “height”', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  •Plagiarism detection Word Representations in IR/NLP', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Kulkarni, Al-Rfou, Perozzi, Skiena 2015 Word Representations in IR/NLP•Word meaning changes over time•Historical linguistics', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Core intuition:“You shall know a word by the company it keeps!”•Firth (1957)•Example:A bottle of tesgüino is on the tableEverybody likes tesgüinoTesgüino makes you drunkWe make tesgüino out of corn.•From context words humans can guess tesgüino means–an alcoholic beverage like beer•Two words are similar if they have similar word contexts.', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Vector RepresentationsSparse vector representations1.Vector space model2.Mutual-information co-occurrence matrices3.Explicit Semantic AnalysisDense vector representations:3.Singular value decomposition4.Neural network models (skip-grams, CBOW)', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Vector Space Model', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Term-Document MatrixAntony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony5.253.180 0 0 0.35Brutus1.216.10 1 0 0Caesar8.592.540 1.510.250Calpurnia0 1.540 0 0 0Cleopatra2.850 0 0 0 0mercy1.510 1.90.125.250.88worser1.370 0.114.150.251.95 Each word is now represented by a real-valued vector of tf-idf weights ∈ R|D| Sec. 6.3', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Co-occurrence Matrices', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word-Word or Word-Context Matrices•Instead of entire documents, use smaller contexts–Paragraph–Window of ± 4 words•A word is now defined by a vector over counts of context words•Instead of each vector being of length D•Each vector is now of length |V|•The word-word matrix is |V|x|V|', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word-Word MatrixSample contexts ± 7 words aardvarkcomputerdatapinchresultsugar…apricot0 0 0 1 0 1pineapple0 0 0 1 0 1digital0 2 1 0 1 0information0 1 6 0 4 0 19.1 • W ORDS AND V ECTORS 3 tors of numbers representing the terms (words) that occur within the collection (Salton, 1971) . In information retrieval these numbers are called the term weight ,aterm weight function of the term’s frequency in the document. More generally, the term-document matrix X has V rows (one for each word type in the vocabulary) and D columns (one for each document in the collection). Each column represents a document. A query is also represented by a vector q of length | V | . We go about ﬁnding the most relevant document to query by ﬁnding the document whose vector is most similar to the query; later in the chapter we’ll introduce some of the components of this process: the tf-idf term weighting, and the cosine similarity metric. But now let’s turn to the insight of vector semantics for representing the meaning of words . The idea is that we can also represent each word by a vector, now a row vector representing the counts of the word’s occurrence in each document. Thus the vectors for fool [37,58,1,5] and clown [5,117,0,0] are more similar to each other (occurring more in the comedies) while battle [1,1,8,15] and soldier [2,2,12,36] are more similar to each other (occurring less in the comedies). More commonly used for vector semantics than this term-document matrix is an alternative formulation, the term-term matrix , more commonly called the word-term-term matrix word matrix oro the term-context matrix , in which the columns are labeled by words rather than documents. This matrix is thus of dimensionality | V | ⇥ | V | and each cell records the number of times the row (target) word and the column (context) word co-occur in some context in some training corpus. The context could be the document, in which case the cell represents the number of times the two words appear in the same document. It is most common, however, to use smaller contexts, such as a window around the word, for example of 4 words to the left and 4 words to the right, in which case the cell represents the number of times (in some training corpus) the column word occurs in such a ± 4 word window around the row word. For example here are 7-word windows surrounding four sample words from the Brown corpus (just one example of each word): sugar, a sliced lemon, a tablespoonful of apricot preserve or jam, a pinch each of, their enjoyment. Cautiously she sampled her ﬁrst pineapple and another fruit whose taste she likened well suited to programming on the digital computer . In ﬁnding the optimal R-stage policy from for the purpose of gathering data and information necessary for the study authorized in the For each word we collect the counts (from the windows around each occurrence) of the occurrences of context words. Fig. 17.2 shows a selection from the word-word co-occurrence matrix computed from the Brown corpus for these four words. aardvark ... computer data pinch result sugar ... apricot 0 ... 0 0 10 1 pineapple 0 ... 0 0 10 1 digital 0 ... 2 10 10 information 0 ... 1 60 40 Figure 19.2 Co-occurrence vectors for four words, computed from the Brown corpus, showing only six of the dimensions (hand-picked for pedagogical purposes). Note that a real vector would be vastly more sparse. The shading in Fig. 17.2 makes clear the intuition that the two words apricot and pineapple are more similar (both pinch and sugar tend to occur in their window) while digital and information are more similar. Note that | V | , the length of the vector, is generally the size of the vocabulary, usually between 10,000 and 50,000 words (using the most frequent words in the … … •Two words are similar in meaning if their context vectors are similar', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word-word Matrix•We showed only 4x6, but the real matrix is 50,000 x 50,000–Very sparse•The size of windows depends on your goals–The shorter the windows , the more syntactic the representation± 1-3 very syntacticy–The longer the windows, the more semantic the representation± 4-10 more semanticy', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Pointwise Mutual Information Pointwise mutual information: Do events x and y co-occur more than if they were independent? PMI between two words:  (Church & Hanks 1989) Do words x and y co-occur more than if they were independent?  PMI𝑤𝑜𝑟𝑑!,𝑤𝑜𝑟𝑑\"=log\"𝑃(𝑤𝑜𝑟𝑑!,𝑤𝑜𝑟𝑑\")𝑃𝑤𝑜𝑟𝑑!𝑃(𝑤𝑜𝑟𝑑\") PMI(X,Y)=log2P(x,y)P(x)P(y)•Raw word frequency is not a great measure of association between words–It’s very skewed•“the” and “of” are very frequent, but maybe not the most discriminative', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Positive Pointwise Mutual Information–PMI ranges from −∞\\tto\\t+∞–But the negative values are problematic•Unreliable without very large corpora•It’s not clear people are good at “unrelatedness”–We just replace negative PMI values by 0–Positive PMI (PPMI) between word1 and word2:PPMI𝑤𝑜𝑟𝑑\",𝑤𝑜𝑟𝑑#=maxlog#𝑃(𝑤𝑜𝑟𝑑\",𝑤𝑜𝑟𝑑#)𝑃𝑤𝑜𝑟𝑑\"𝑃(𝑤𝑜𝑟𝑑#),0', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  PPMI on a Term-Context Matrix•Matrix F with W rows (words) and C columns (contexts)•fij is # of times wi occurs in context cj pij=fijfijj=1C∑i=1W∑pi*=fijj=1C∑fijj=1C∑i=1W∑p*j=fiji=1W∑fijj=1C∑i=1W∑pmiij=log2pijpi*p*jppmiij=pmiijif  pmiij>00otherwise!\"#$#', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  pij=fijfijj=1C∑i=1W∑pi*=fijj=1C∑fijj=1C∑i=1W∑p*j=fiji=1W∑fijj=1C∑i=1W∑What is PPMI(information,data)? pmiij=log2pijpi*p*jppmiij=pmiijif  pmiij>00otherwise!\"#$#', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  p(w,context)p(w)computerdatapinchresultsugarapricot0.000.000.050.000.050.11pineapple0.000.000.050.000.050.11digital0.110.050.000.050.000.21information0.050.320.000.210.000.58p(context)0.160.370.110.260.11 pij=fijfijj=1C∑i=1W∑', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  pmiij=log2pijpi*p*j p(w,context)p(w)computerdatapinchresultsugarapricot0.000.000.050.000.050.11pineapple0.000.000.050.000.050.11digital0.110.050.000.050.000.21information0.050.320.000.210.000.58p(context)0.160.370.110.260.11 PPMI(w,context)computerdatapinchresultsugarapricot1 1 2.251 2.25pineapple1 1 2.251 2.25digital1.660.001 0.001information0.000.571 0.471', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Weighting PMI•PMI is biased toward infrequent events–Very rare words have very high PMI values•Solution–Use Laplace smoothing', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Example: Add-two SmoothingAdd#2%Smoothed%Count(w,context)computerdatapinchresultsugarapricot2 2 3 2 3pineapple2 2 3 2 3digital4 3 2 3 2information3 8 2 6 2p(w,context),[add02]p(w)computerdatapinchresultsugarapricot0.030.030.050.030.050.20pineapple0.030.030.050.030.050.20digital0.070.050.030.050.030.24information0.050.140.030.100.030.36p(context)0.190.250.170.220.17', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  PPMI versus Add-2 Smoothed PPMI PPMI(w,context).[add22]computerdatapinchresultsugarapricot0.000.000.560.000.56pineapple0.000.000.560.000.56digital0.620.000.000.000.00information0.000.580.000.370.00 PPMI(w,context)computerdatapinchresultsugarapricot1 1 2.251 2.25pineapple1 1 2.251 2.25digital1.660.001 0.001information0.000.571 0.471', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis•Determine the extent to which each word is associated with every concept (article) of Wikipedia via term frequency or some other method.•For a text, sum up the associated concept vectors for a composite text concept vector.•Compare the texts using a standard vector similarity measure', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis Example•Word1: height•Word2: tallGlossary of cue sports termsAmerican Football StrategyBaseballBoston Red SoxWord1:2 0 6 3Word2:0 1 10 2', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis Example•Text1: The dog caught the red ball.•Text2: A Labrador played in the park. •Can also be adapted to cross-language information retrieval Glossary of cue sports termsAmerican Football StrategyBaseballBoston Red SoxText1:27140 48 52Text2:10 17 10 7', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Singular Value Decomposition', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Sparse versus Dense Vectors•PPMI vectors are–long (length |V|= 20,000 to 50,000)–sparse (most elements are zero)•Alternative: learn vectors which are–short (length 200-1000)–dense (most elements are non-zero)', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  •Why dense vectors?–Short vectors may be easier to use as features in machine learning (less weights to tune)–Dense vectors may generalize better than storing explicit counts–They may do better at capturing synonymy:•car and automobile are synonyms; but are represented as distinct dimensions; this fails to capture similarity between a word with car as a neighbor and a word with automobile as a neighbor Sparse versus Dense Vectors', \"page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Singular Value Decomposition•For any matrix X, with t rows and d columns, there exist matrices T0, S0 and D0', such that:•X = T0S0D0‘•T0 and D0 are the matrices of left and right singular vectors•S0 is the diagonal matrix of singular values\", \"page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Dimensions of Matrices X = T0 D0'S0 t x t t x m m x tm x m\", 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Reduced Rank•S0 can be chosen so that the diagonal elements are positive and decreasing in magnitude.  Keep the first k and set the others to zero.  •Delete the zero rows and columns of S0 and the corresponding rows and columns of T0 and D0. •Interpretation: If value of k is selected well, expectation is that X retains the semantic information, but eliminates noise from synonymy and recognizes dependence', \"page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Dimensionality  Reduction X = t x t t x k k x tk x k k is the number of latent concepts  (typically 300 ~ 500)X ~ X = TSD' T S D'^\", 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  SVD Applied to PPMI Word-Word Matrix 19.3 • D ENSE V ECTORS AND SVD 13 Singular Value Decomposition (SVD) is a method for ﬁnding the most impor- tant dimensions of a data set, those dimensions along which the data varies the most. It can be applied to any rectangular matrix and in language processing it was ﬁrst applied to the task of generating embeddings from term-document matrices by Deer- wester et al. (1988) in a model called Latent Semantic Indexing . In this section let’s look just at its application to a square term-context matrix M with | V | rows (one for each word) and columns (one for each context word) SVD factorizes M into the product of three square | V | ⇥ | V | matrices W , S , and C T . In W each row still represents a word, but the columns do not; each column now represents a dimension in a latent space, such that the | V | column vectors are orthogonal to each other and the columns are ordered by the amount of variance in the original dataset each accounts for. S is a diagonal | V | ⇥ | V | matrix, with singular values along the diagonal, expressing the importance of each dimension. The | V | ⇥ | V | matrix C T still represents contexts, but the rows now represent the new latent dimensions and the | V | row vectors are orthogonal to each other. By using only the ﬁrst k dimensions, of W, S, and C instead of all | V | dimen- sions, the product of these 3 matrices becomes a least-squares approximation to the original M . Since the ﬁrst dimensions encode the most variance, one way to view the reconstruction is thus as modeling the most important information in the original dataset. SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s V 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 C 3 7 7 7 7 7 5 | V | ⇥ | V | Taking only the top k dimensions after SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ k 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M .', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M . 3 3 Note that early systems often instead weighted W k by the singular values, using the product W k · S k as an embedding instead of just the matrix W k , but this weighting leads to signiﬁcantly worse embeddings (Levy et al., 2015) .', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Truncated SVD – Keep K Dimensions 19.3 • D ENSE V ECTORS AND SVD 13 Singular Value Decomposition (SVD) is a method for ﬁnding the most impor- tant dimensions of a data set, those dimensions along which the data varies the most. It can be applied to any rectangular matrix and in language processing it was ﬁrst applied to the task of generating embeddings from term-document matrices by Deer- wester et al. (1988) in a model called Latent Semantic Indexing . In this section let’s look just at its application to a square term-context matrix M with | V | rows (one for each word) and columns (one for each context word) SVD factorizes M into the product of three square | V | ⇥ | V | matrices W , S , and C T . In W each row still represents a word, but the columns do not; each column now represents a dimension in a latent space, such that the | V | column vectors are orthogonal to each other and the columns are ordered by the amount of variance in the original dataset each accounts for. S is a diagonal | V | ⇥ | V | matrix, with singular values along the diagonal, expressing the importance of each dimension. The | V | ⇥ | V | matrix C T still represents contexts, but the rows now represent the new latent dimensions and the | V | row vectors are orthogonal to each other. By using only the ﬁrst k dimensions, of W, S, and C instead of all | V | dimen- sions, the product of these 3 matrices becomes a least-squares approximation to the original M . Since the ﬁrst dimensions encode the most variance, one way to view the reconstruction is thus as modeling the most important information in the original dataset. SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s V 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 C 3 7 7 7 7 7 5 | V | ⇥ | V | Taking only the top k dimensions after SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ k 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M .', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M . 3 3 Note that early systems often instead weighted W k by the singular values, using the product W k · S k as an embedding instead of just the matrix W k , but this weighting leads to signiﬁcantly worse embeddings (Levy et al., 2015) .', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Truncated SVD Produces Embeddings•Each row of W matrix is a k-dimensional representation of each word w•Generally we keep the top k dimensions, but some experiments suggest that getting rid of the top 1 dimension or  even the top 50 dimensions is helpful (Lapesa and Evert 2014). 19.3 • D ENSE V ECTORS AND SVD 13 Singular Value Decomposition (SVD) is a method for ﬁnding the most impor- tant dimensions of a data set, those dimensions along which the data varies the most. It can be applied to any rectangular matrix and in language processing it was ﬁrst applied to the task of generating embeddings from term-document matrices by Deer- wester et al. (1988) in a model called Latent Semantic Indexing . In this section let’s look just at its application to a square term-context matrix M with | V | rows (one for each word) and columns (one for each context word) SVD factorizes M into the product of three square | V | ⇥ | V | matrices W , S , and C T . In W each row still represents a word, but the columns do not; each column now represents a dimension in a latent space, such that the | V | column vectors are orthogonal to each other and the columns are ordered by the amount of variance in the original dataset each accounts for. S is a diagonal | V | ⇥ | V | matrix, with singular values along the diagonal, expressing the importance of each dimension. The | V | ⇥ | V | matrix C T still represents contexts, but the rows now represent the new latent dimensions and the | V | row vectors are orthogonal to each other. By using only the ﬁrst k dimensions, of W, S, and C instead of all | V | dimen- sions, the product of these 3 matrices becomes a least-squares approximation to the original M . Since the ﬁrst dimensions encode the most variance, one way to view the reconstruction is thus as modeling the most important information in the original dataset. SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s V 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 C 3 7 7 7 7 7 5 | V | ⇥ | V | Taking only the top k dimensions after SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ k 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word.'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96b380>, 'json_data': {'input': ['page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Issues with Jaccard for Scoring•It does not consider term frequency (how many times a term occurs in a document)•Rare terms in a collection are more informative than frequent terms. Jaccard does not consider this information•We need a more sophisticated way of normalizing for length Ch. 6', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Recall (from Boolean Retrieval): Binary Term-Document Incidence MatrixAntony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony1 1 0 0 0 1Brutus1 1 0 1 0 0Caesar1 1 0 1 1 1Calpurnia0 1 0 0 0 0Cleopatra1 0 0 0 0 0mercy1 0 1 1 1 1worser1 0 1 1 1 0 Each document is represented by a binary vector ∈ {0,1}|V| Sec. 6.2', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term-document Count Matrices•Consider the number of occurrences of a term in a document: –Each document is a count vector: a column below  Antony and Cleopatra Julius Caesar The Tempest Hamlet Othello Macbeth Antony 157 73 0 0 0 0 Brutus 4 157 0 1 0 0 Caesar 232 227 0 2 1 1 Calpurnia 0 10 0 0 0 0 Cleopatra 57 0 0 0 0 0 mercy 2 0 3 5 5 1 worser 2 0 1 1 1 0 Sec. 6.2', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Vector-Space Model•t distinct terms remain after preprocessing–Unique terms that form the VOCABULARY•These “orthogonal” terms form a vector space.          Dimension = t = |vocabulary| –2 terms à bi-dimensional; …; n-terms à n-dimensional•Each term, i,  in a document or query j, is given a real-valued weight, wij.•Both documents and queries are expressed as t-dimensional vectors:          dj = (w1j, w2j, …, wtj)', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Vector-Space ModelQuery as vector:•We regard query as short document•We return the documents ranked by the closeness of their vectors to the query, also represented as a vector. •Vector-space model was developed in the SMART system (Salton, c.1970) and standardly used by TREC participants and web IR systems', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Graphic RepresentationExample:D1 = 2T1 + 3T2 + 5T3D2 = 3T1 + 7T2 +   T3Q = 0T1 + 0T2 +  2T3 T3 T1 T2 D1 = 2T1+ 3T2 + 5T3 D2 = 3T1 + 7T2 +  T3 Q = 0T1 + 0T2 + 2T3 7 32 5 •Is D1 or D2 more similar to Q?•How to measure the degree of similarity? Distance? Angle? Projection?', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Collection Representation•A collection of n documents can be represented in the vector space model by a term-document matrix.•An entry in the matrix corresponds to the “weight” of a term in the document; zero means the term has no significance in the document or it simply doesn’t exist in the document.T1   T2    ….      TtD1    w11  w21   …      wt1D2 w12  w22   …      wt2 :       :      :               : :       :      :               :Dn    w1n  w2n   …      wtn', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Frequency tf•The term frequency tft,d of term t in document d is defined as the number of times that t occurs in d.•More frequent terms in a document are more important, i.e. more indicative of the topic.•May want to normalize term frequency (tf) :        tft,d   = ft,d  / max{ft,d}•We want to use tf when computing query-document match scores. But how?', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Frequency tf•Raw term frequency is not what we want:–A document with 10 occurrences of the term is more relevant than a document with 1 occurrence of the term.–But not 10 times more relevant.•Relevance does not increase proportionally with term frequency.', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Frequency•Rare terms are more informative than frequent terms–Recall stop words•Consider a term in the query that is rare in the collection (e.g., arachnocentric)•A document containing this term is very likely to be relevant to the query arachnocentric•→ We want a high weight for rare terms like arachnocentric. Sec. 6.2.1', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Frequency (continued)•Frequent terms are less informative than rare terms•Consider a query term that is frequent in the collection (e.g., high, increase, line)•A document containing such a term is more likely to be relevant than a document that doesn’t•But it’s not a sure indicator of relevance.•→ For frequent terms, we want high positive weights for words like high, increase, and line•But lower weights than for rare terms.•We will use document frequency (df) to capture this. Sec. 6.2.1', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Idf Weight•dft is the document frequency of t: the number of documents that contain t–dft is an inverse measure of the informativeness of t–dft £ N•We define the idf (inverse document frequency) of t by–We use log (N/dft) instead of N/dft to “dampen” the effect of idf.idft = log10 (N/dft)Sec. 6.2.1', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  idf example, suppose N = 1 millionterm dft idftcalpurnia 1animal 100sunday 1,000fly 10,000under 100,000the 1,000,000 There is one idf value for each term t in a collection. Sec. 6.2.1 )/df( log  idf 10 tt N=', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Collection vs. Document Frequency•The collection frequency of t is the number of occurrences of t in the collection, counting multiple occurrences.•Example: •Which word is a better search term (and should get a higher weight)? WordCollection frequencyDocument frequency insurance10440 3997try 9800 8760 Sec. 6.2.1', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  tf-idf Weighting•The tf-idf weight of a term is the product of its tf weight and its idf weight. •Best known weighting scheme in information retrieval–Theoretically proven to work well (Papineni, NAACL 2001)–Note: the “-” in tf-idf is a hyphen, not a minus sign!–Alternative names: tf.idf, tf x idf•Increases with the number of occurrences within a document•Increases with the rarity of the term in the collection wt,d=tft,d×log10(N/dft)Sec. 6.2.2', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Computing tf-idf: An ExampleGiven a document containing terms with given frequencies:    A(3), B(2), C(1)Assume collection contains 10,000 documents and document frequencies of these terms are:    A(50), B(2500), C(100)Then (assuming log10)A:  tf = 3/3;  idf = log(10000/50) = 2.3;     tf-idf = 2.3B:  tf = 2/3;  idf = log(10000/2500) = 0.60; tf-idf = 0.40C:  tf = 1/3;  idf = log(10000/100) = 2.0;   tf-idf = 0.66', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Binary → Count → Weight matrixAntony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony5.253.180 0 0 0.35Brutus1.216.10 1 0 0Caesar8.592.540 1.510.250Calpurnia0 1.540 0 0 0Cleopatra2.850 0 0 0 0mercy1.510 1.90.125.250.88worser1.370 0.114.150.251.95 Each document is now represented by a real-valued vector of tf-idf weights ∈ R|V| Sec. 6.3', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Documents as Vectors•So we have a |V|-dimensional vector space•Terms are axes of the space•Documents are points or vectors in this space•Very high-dimensional: tens of millions of dimensions when you apply this to a web search engine•These are very sparse vectors - most entries are zero. Sec. 6.3', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Query as Vector•Query vector is typically treated as a document and also tf-idf weighted.•Alternative is for the user to supply weights for the given query terms.', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Similarity Measure•We now have vectors for all documents in the collection, a vector for the query, how to compute similarity? •A similarity measure is a function that computes the degree of similarity between two vectors.•Using a similarity measure between the query and each document:–It is possible to rank the retrieved documents in the order of presumed relevance.–It is possible to enforce a certain threshold so that the size of the retrieved set can be controlled.', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  First Cut: Euclidean Distance•Distance between vectors d1 and d2 is the length of the vector |d1 – d2|.–Euclidean distance•Exercise: Determine the Euclidean distance between the vectors (0, 3, 2, 1, 10) and (2, 7, 1, 0, 0)•Why is this not a great idea?•We still haven’t dealt with the issue of length normalization–Long documents would be more similar to each other by virtue of length, not topic', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Second Cut: Manhattan Distance•Or “city block” measure–Based on the idea that generally in American cities you cannot follow a direct line between two points. •Uses the formula: •Exercise: Determine the Manhattan distance between the vectors (0, 3, 2, 1, 10) and (2, 7, 1, 0, 0) x y å = -= n i ii yxYXManhDist 1 ||),(', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Third Cut: Inner Product•Similarity between vectors for the document di and query q can be computed as the vector inner product:               sim(dj,q) = dj•q =      wij · wiq        where wij is the weight of term i in document j and wiq is the weight of term i in the query•For binary vectors, the inner product is the number of matched query terms in the document (size of intersection).•For weighted term vectors, it is the sum of the products of the weights of the matched terms. å = t i 1', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Properties of Inner Product•Favors long documents with a large number of unique terms.–Again, the issue of normalization•Measures how many terms matched but not how many terms are not matched.', 'page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  InnerProductExercise k1 k2 k3 q • dj  d1 1 0 1 ?  d2 1 0 0 ?  d3 0 1 1 ?  d4 1 0 0 ?  d5 1 1 1 ?  d6 1 1 0 ?  d7 0 1 0 ?        q 1 2 3', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity•Distance between vectors d1 and d2 captured by the cosine of the angle x between them.•Note – this is similarity, not distance t 1 d2 d1 t 3 t 2 θ', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity •Cosine of angle between two vectors•The denominator involves the lengths of the vectors•So the cosine measure is also known as the normalized inner product åå å == = = × = n i ki n i ji n i kiji kj kj kj ww ww dd dd ddsim 1 2 ,1 2 , 1 ,, ),( \\uf072\\uf072 \\uf072\\uf072 å = = n i jij wd 1 2 , Length \\uf072', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity Exercise•Exercise: Rank the following by decreasing cosine similarity:–(P1) Two documents that have only frequent words (the, a, an, of) in common.–(P2) Two documents that have no words in common.–(P3) Two documents that have many rare words in common (wingspan, tailfin). The ranking in decreasing order of their cosine similarity will be:A)P1, P3, P2B)P3, P2, P1C)P3, P1, P2', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity Example•Documents: Sense and Sensibility, Pride and Prejudice; Wuthering Heights  •cos(SaS,PaP) ≈ 0.789 × 0.832 + 0.515 × 0.555 + 0.335 × 0.0 + 0.0 × 0.0 ≈ 0.94•cos(SaS,WH) ≈ 0.79•cos(PaP,WH) ≈ 0.69 termSaSPaPWHaffection11558 20jealous10 7 11gossip2 0 6wuthering0 0 38 termSaSPaPWHaffection0.7890.8320.524jealous0.5150.5550.465gossip0.33500.405wuthering0 00.588 Why do we have cos(SaS,PaP) > cos(SaS,WH)?', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity vs. Inner Product•Cosine similarity measures the cosine of the angle between two vectors.•Inner product normalized by the vector lengths.    D1 = 2T1 + 3T2 + 5T3     CosSim(D1 , Q) = 10 / Ö(4+9+25)(0+0+4) = 0.81D2 = 3T1 + 7T2 + 1T3     CosSim(D2 , Q) =  2 / Ö(9+49+1)(0+0+4) = 0.13 Q = 0T1 + 0T2 + 2T3 q2 t3 t1 t2 D1 D2 Qq1 D1 is 6 times better than D2 using cosine similarity but only 5 times better using inner product. å å å = = = • × × = × t i t i t i ww ww qd qd iqij iqij j j 1 1 22 1 )( \\uf072\\uf072 \\uf072\\uf072 CosSim(dj, q) = qd j \\uf072\\uf072 •InnerProduct(dj, q) =', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  ExerciseConsider the following four documents:•Doc1: apple orange banana peach•Doc2: orange orange apple apple•Doc3: banana tangerine peach•Doc4: peach peach apple bananaAnd the query:•Query: apple peach tangerineAssume no pre-processing (i.e., no normalization, no case-folding, no stopword-removal, no stemming), and a tfidf weighting scheme (tf not normalized, log based 10 for idf).1. Write the vector representations for each of the four documents and for the query.2. Determine the cosine similarities between each document and the query, and rank the documents.', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Comments on Vector Space Models•Simple, mathematically based approach. •Considers both local (tf) and global (idf) word occurrence frequencies.•Provides partial matching and ranked results.•Tends to work quite well in practice despite obvious weaknesses.•Allows efficient implementation for large document collections.', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Problems with Vector Space Model•Missing semantic information (e.g. word sense).•Missing syntactic information (e.g. phrase structure, word order, proximity information).•Assumption of term independence•Lacks the control of a Boolean model (e.g., requiring a term to appear in a document).–Given a two-term query “A B”, may prefer a document containing A frequently but not B, over a document that contains both A and B, but both less frequently.', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Evaluation of IR ModelsPrecision & Recall', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Standard Evaluation Measures w x y z n2 = w + y n1 = w + x N relevant not relevant retrievednot retrievedStart with a CONTINGENCY table', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Precision and Recall Recall: Precision: w w+y w+x w From all the documents that are relevant out there,how many did the IR system retrieve? From all the documents that are retrieved by the IR system, how many are relevant?', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Precision and Recall for a Set of Queries•For each query, determine the retrieved documents and the relevant documents  •Calculate–Macro-average: average the P/R/F calculated for the individual queries–Micro-average: sum all/relevant documents for individual queries, and calculate P/R/F only once', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Weighting Approaches', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Graphic RepresentationExample:D1 = 2T1 + 3T2 + 5T3D2 = 3T1 + 7T2 +   T3Q = 0T1 + 0T2 +  2T3 T3 T1 T2 D1 = 2T1+ 3T2 + 5T3 D2 = 3T1 + 7T2 +  T3 Q = 0T1 + 0T2 + 2T3 7 32 5 •Is D1 or D2 more similar to Q?•How to measure the degree of similarity? Distance? Angle? Projection?', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Collection Representation•A collection of n documents can be represented in the vector space model by a term-document matrix.•An entry in the matrix corresponds to the “weight” of a term in the document; zero means the term has no significance in the document or it simply doesn’t exist in the document.T1   T2    ….      TtD1    w11  w21   …      wt1D2 w12  w22   …      wt2 :       :      :               : :       :      :               :Dn    w1n  w2n   …      wtn', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Salton & Buckley•Experiments with term weighting approaches•Six collections, 1,800 term weighting approaches–287 combinations found to be distinct•Comparative evaluations using:–Ranking: the lower the better–Best weighting scheme has a rank of 1•Average search precision:–Average of precisions for recall points of 0.25, 0.50, 0.75•Average across queries:–Macro-average: average of the average search precisions', \"page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  IR Test Collections•CACM (articles from 'Communications of the ACM journal)•CISI (articles about information sciences)•CRAN (abstracts from aeronautics articles)•INSPEC (articles in computer engineering)•MED (medical articles) •NPL (articles about electrical engineering)\", 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  IR Collections', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Weighting Components', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Sample Weighting Schemes', 'page_label: 56 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Performance Results', 'page_label: 57 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Lessons Learned•Term weighting DOES matter•Query vector:–Term frequency•Use n for short queries•Use t for longer queries that require better discrimination among terms–Document frequency•Use f –Do not do normalization with query length', 'page_label: 58 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Lessons Learned•Document vectors:–Term-frequency:•For technical vocabulary (e.g., CRAN) use n•For more varied vocabulary, use t•For short document vectors, use b–Document frequency:•Inverse document-frequency f is similar to probabilistic term weight p: typically use f•For dynamic collections with many changes in the document collection makeup, use x–Normalization:•Typically use c (in particular when there is high deviation in vector length)•For short documents with homogenous length, use x', 'page_label: 59 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Vector Space Model Implementation', 'page_label: 60 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Naïve ImplementationConvert all documents in collection D to TF.IDF weighted vectors, dj, for keyword vocabulary V.Convert query to a tf-idf-weighted vector q.For each dj in D do      Compute score sj = cosSim(dj, q)Sort documents by decreasing score.Present top ranked documents to the user.Time complexity:  O(|V|·|D|)   Bad for large V & D !|V| = 10,000; |D| = 100,000; |V|·|D| = 1,000,000,000', 'page_label: 61 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Practical Implementation•Based on  the observation that documents containing none of the query keywords do not affect the final ranking•Try to identify only those documents that contain at least one query keyword•Actual implementation of an inverted index', 'page_label: 62 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 1: Preprocessing•Implement the preprocessing functions:–For tokenization–For stop word removal–For stemming •Input: Documents that are read one by one from the collection•Output: Tokens to be added to the index–No punctuation, no stop-words, stemmed', 'page_label: 63 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2: Indexing•Build an inverted index, with an entry for each word in the vocabulary •Input: Tokens obtained from the preprocessing module•Output: An inverted index for fast access', 'page_label: 64 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2 (continued)•Many data structures are appropriate for fast access•We need:–One entry for each word in the vocabulary–For each such entry:•Keep a list of all the documents where it appears together with the corresponding frequency à TF–For each such entry, keep the total number of occurrences in all documents:•à IDF', 'page_label: 65 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2 (continued) system computerdatabase scienceD2, 4D5, 2 D1, 3D7, 4Index termsdf32 41 Dj, tfj Index filelists •••', 'page_label: 66 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2 (continued)•TF and IDF for each token can be computed in one pass •Cosine similarity also requires document lengths•Need a second pass to compute document vector lengths–Remember that the length of a document vector is the square-root of sum of the squares of the weights of its tokens.–Remember the weight of a token is: TF * IDF–Therefore, must wait until IDFs are known (and therefore until all documents are indexed) before document lengths can be determined.•Do a second pass over all documents: keep a list or hashtable with all document id-s, and for each document determine its length.', 'page_label: 67 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Time Complexity of Indexing•Complexity of creating vector and indexing a document of n tokens is O(n).•So indexing |D| such documents is O(|D| n).•Computing token IDFs can be done during the same first pass•Computing vector lengths is also O(|D| n).•Complete process is O(|D| n), which is also the complexity of just reading in the corpus.', 'page_label: 68 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 3: Retrieval •Use inverted index (from step 2) to find the limited set of documents that contain at least one of the query words.•Incrementally compute cosine similarity of each indexed document as query words are processed one by one.–If tf is normalized for the query, may need to first read all the query tokens•To accumulate a total score for each retrieved document, store retrieved documents in a hashtable (or another search data structure), where the document id is the key, and the partial accumulated score is the value.•Input: Query and Inverted Index (from Step 2)•Output: Similarity values between query and documents', 'page_label: 69 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 4: Ranking•Sort the search structure including the retrieved documents based on the value of cosine similarity•Return the documents in descending order of their relevance •Input: Similarity values between query and documents•Output: Ranked list of documented in reversed order of their relevance', 'page_label: 70 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Tfidf vectorizerIn the class, we learnt how to convert a document into a vector using tf-idf. While implementing a function for tf-idfis very easy, you can do that also using a library. Follow the code below.', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Information Retrieval and  Web SearchWord Representations', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Why Word Representations?•Computing with words–How similar is ‘car’ to ‘vehicle’? –How about ‘car’ to ‘wheel’?–How about ’car’ to ‘moon’?–How far is ‘man’ from ‘woman’?–How about ‘king’ from ‘queen’? •Mathematical representations of words, typically as vectors, that allow for computations–Measure similarity / distance between words', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Embeddings for IR•Compute similarity between query and documents using embedding vectors•Sum up all the embeddings to create one embedding for the document; one embedding for the query•Compute inner product or cosine similarity between these vectors•Note: embeddings are not transferable across spaces–The entries in the vector of embeddings have meaning only in the space where they were learned!', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Representations in IR/NLP•Core component in large number of IR tasks and applicationsQuery: ISTD SUTD But what if the words do not actually occur in the documents?', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Representations in IR/NLPQuestion answering:Q: “How tall is Mt. Everest?”Candidate A: “The official height of Mount Everest is 29029 feet” “tall” is similar to “height”', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  •Plagiarism detection Word Representations in IR/NLP', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Kulkarni, Al-Rfou, Perozzi, Skiena 2015 Word Representations in IR/NLP•Word meaning changes over time•Historical linguistics', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Core intuition:“You shall know a word by the company it keeps!”•Firth (1957)•Example:A bottle of tesgüino is on the tableEverybody likes tesgüinoTesgüino makes you drunkWe make tesgüino out of corn.•From context words humans can guess tesgüino means–an alcoholic beverage like beer•Two words are similar if they have similar word contexts.', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Vector RepresentationsSparse vector representations1.Vector space model2.Mutual-information co-occurrence matrices3.Explicit Semantic AnalysisDense vector representations:3.Singular value decomposition4.Neural network models (skip-grams, CBOW)', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Vector Space Model', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Term-Document MatrixAntony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony5.253.180 0 0 0.35Brutus1.216.10 1 0 0Caesar8.592.540 1.510.250Calpurnia0 1.540 0 0 0Cleopatra2.850 0 0 0 0mercy1.510 1.90.125.250.88worser1.370 0.114.150.251.95 Each word is now represented by a real-valued vector of tf-idf weights ∈ R|D| Sec. 6.3', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Co-occurrence Matrices', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word-Word or Word-Context Matrices•Instead of entire documents, use smaller contexts–Paragraph–Window of ± 4 words•A word is now defined by a vector over counts of context words•Instead of each vector being of length D•Each vector is now of length |V|•The word-word matrix is |V|x|V|', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word-Word MatrixSample contexts ± 7 words aardvarkcomputerdatapinchresultsugar…apricot0 0 0 1 0 1pineapple0 0 0 1 0 1digital0 2 1 0 1 0information0 1 6 0 4 0 19.1 • W ORDS AND V ECTORS 3 tors of numbers representing the terms (words) that occur within the collection (Salton, 1971) . In information retrieval these numbers are called the term weight ,aterm weight function of the term’s frequency in the document. More generally, the term-document matrix X has V rows (one for each word type in the vocabulary) and D columns (one for each document in the collection). Each column represents a document. A query is also represented by a vector q of length | V | . We go about ﬁnding the most relevant document to query by ﬁnding the document whose vector is most similar to the query; later in the chapter we’ll introduce some of the components of this process: the tf-idf term weighting, and the cosine similarity metric. But now let’s turn to the insight of vector semantics for representing the meaning of words . The idea is that we can also represent each word by a vector, now a row vector representing the counts of the word’s occurrence in each document. Thus the vectors for fool [37,58,1,5] and clown [5,117,0,0] are more similar to each other (occurring more in the comedies) while battle [1,1,8,15] and soldier [2,2,12,36] are more similar to each other (occurring less in the comedies). More commonly used for vector semantics than this term-document matrix is an alternative formulation, the term-term matrix , more commonly called the word-term-term matrix word matrix oro the term-context matrix , in which the columns are labeled by words rather than documents. This matrix is thus of dimensionality | V | ⇥ | V | and each cell records the number of times the row (target) word and the column (context) word co-occur in some context in some training corpus. The context could be the document, in which case the cell represents the number of times the two words appear in the same document. It is most common, however, to use smaller contexts, such as a window around the word, for example of 4 words to the left and 4 words to the right, in which case the cell represents the number of times (in some training corpus) the column word occurs in such a ± 4 word window around the row word. For example here are 7-word windows surrounding four sample words from the Brown corpus (just one example of each word): sugar, a sliced lemon, a tablespoonful of apricot preserve or jam, a pinch each of, their enjoyment. Cautiously she sampled her ﬁrst pineapple and another fruit whose taste she likened well suited to programming on the digital computer . In ﬁnding the optimal R-stage policy from for the purpose of gathering data and information necessary for the study authorized in the For each word we collect the counts (from the windows around each occurrence) of the occurrences of context words. Fig. 17.2 shows a selection from the word-word co-occurrence matrix computed from the Brown corpus for these four words. aardvark ... computer data pinch result sugar ... apricot 0 ... 0 0 10 1 pineapple 0 ... 0 0 10 1 digital 0 ... 2 10 10 information 0 ... 1 60 40 Figure 19.2 Co-occurrence vectors for four words, computed from the Brown corpus, showing only six of the dimensions (hand-picked for pedagogical purposes). Note that a real vector would be vastly more sparse. The shading in Fig. 17.2 makes clear the intuition that the two words apricot and pineapple are more similar (both pinch and sugar tend to occur in their window) while digital and information are more similar. Note that | V | , the length of the vector, is generally the size of the vocabulary, usually between 10,000 and 50,000 words (using the most frequent words in the … … •Two words are similar in meaning if their context vectors are similar', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word-word Matrix•We showed only 4x6, but the real matrix is 50,000 x 50,000–Very sparse•The size of windows depends on your goals–The shorter the windows , the more syntactic the representation± 1-3 very syntacticy–The longer the windows, the more semantic the representation± 4-10 more semanticy', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Pointwise Mutual Information Pointwise mutual information: Do events x and y co-occur more than if they were independent? PMI between two words:  (Church & Hanks 1989) Do words x and y co-occur more than if they were independent?  PMI𝑤𝑜𝑟𝑑!,𝑤𝑜𝑟𝑑\"=log\"𝑃(𝑤𝑜𝑟𝑑!,𝑤𝑜𝑟𝑑\")𝑃𝑤𝑜𝑟𝑑!𝑃(𝑤𝑜𝑟𝑑\") PMI(X,Y)=log2P(x,y)P(x)P(y)•Raw word frequency is not a great measure of association between words–It’s very skewed•“the” and “of” are very frequent, but maybe not the most discriminative', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Positive Pointwise Mutual Information–PMI ranges from −∞\\tto\\t+∞–But the negative values are problematic•Unreliable without very large corpora•It’s not clear people are good at “unrelatedness”–We just replace negative PMI values by 0–Positive PMI (PPMI) between word1 and word2:PPMI𝑤𝑜𝑟𝑑\",𝑤𝑜𝑟𝑑#=maxlog#𝑃(𝑤𝑜𝑟𝑑\",𝑤𝑜𝑟𝑑#)𝑃𝑤𝑜𝑟𝑑\"𝑃(𝑤𝑜𝑟𝑑#),0', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  PPMI on a Term-Context Matrix•Matrix F with W rows (words) and C columns (contexts)•fij is # of times wi occurs in context cj pij=fijfijj=1C∑i=1W∑pi*=fijj=1C∑fijj=1C∑i=1W∑p*j=fiji=1W∑fijj=1C∑i=1W∑pmiij=log2pijpi*p*jppmiij=pmiijif  pmiij>00otherwise!\"#$#', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  pij=fijfijj=1C∑i=1W∑pi*=fijj=1C∑fijj=1C∑i=1W∑p*j=fiji=1W∑fijj=1C∑i=1W∑What is PPMI(information,data)? pmiij=log2pijpi*p*jppmiij=pmiijif  pmiij>00otherwise!\"#$#', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  p(w,context)p(w)computerdatapinchresultsugarapricot0.000.000.050.000.050.11pineapple0.000.000.050.000.050.11digital0.110.050.000.050.000.21information0.050.320.000.210.000.58p(context)0.160.370.110.260.11 pij=fijfijj=1C∑i=1W∑', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  pmiij=log2pijpi*p*j p(w,context)p(w)computerdatapinchresultsugarapricot0.000.000.050.000.050.11pineapple0.000.000.050.000.050.11digital0.110.050.000.050.000.21information0.050.320.000.210.000.58p(context)0.160.370.110.260.11 PPMI(w,context)computerdatapinchresultsugarapricot1 1 2.251 2.25pineapple1 1 2.251 2.25digital1.660.001 0.001information0.000.571 0.471', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Weighting PMI•PMI is biased toward infrequent events–Very rare words have very high PMI values•Solution–Use Laplace smoothing', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Example: Add-two SmoothingAdd#2%Smoothed%Count(w,context)computerdatapinchresultsugarapricot2 2 3 2 3pineapple2 2 3 2 3digital4 3 2 3 2information3 8 2 6 2p(w,context),[add02]p(w)computerdatapinchresultsugarapricot0.030.030.050.030.050.20pineapple0.030.030.050.030.050.20digital0.070.050.030.050.030.24information0.050.140.030.100.030.36p(context)0.190.250.170.220.17', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  PPMI versus Add-2 Smoothed PPMI PPMI(w,context).[add22]computerdatapinchresultsugarapricot0.000.000.560.000.56pineapple0.000.000.560.000.56digital0.620.000.000.000.00information0.000.580.000.370.00 PPMI(w,context)computerdatapinchresultsugarapricot1 1 2.251 2.25pineapple1 1 2.251 2.25digital1.660.001 0.001information0.000.571 0.471', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis•Determine the extent to which each word is associated with every concept (article) of Wikipedia via term frequency or some other method.•For a text, sum up the associated concept vectors for a composite text concept vector.•Compare the texts using a standard vector similarity measure', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis Example•Word1: height•Word2: tallGlossary of cue sports termsAmerican Football StrategyBaseballBoston Red SoxWord1:2 0 6 3Word2:0 1 10 2', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis Example•Text1: The dog caught the red ball.•Text2: A Labrador played in the park. •Can also be adapted to cross-language information retrieval Glossary of cue sports termsAmerican Football StrategyBaseballBoston Red SoxText1:27140 48 52Text2:10 17 10 7', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Singular Value Decomposition', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Sparse versus Dense Vectors•PPMI vectors are–long (length |V|= 20,000 to 50,000)–sparse (most elements are zero)•Alternative: learn vectors which are–short (length 200-1000)–dense (most elements are non-zero)', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  •Why dense vectors?–Short vectors may be easier to use as features in machine learning (less weights to tune)–Dense vectors may generalize better than storing explicit counts–They may do better at capturing synonymy:•car and automobile are synonyms; but are represented as distinct dimensions; this fails to capture similarity between a word with car as a neighbor and a word with automobile as a neighbor Sparse versus Dense Vectors', \"page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Singular Value Decomposition•For any matrix X, with t rows and d columns, there exist matrices T0, S0 and D0', such that:•X = T0S0D0‘•T0 and D0 are the matrices of left and right singular vectors•S0 is the diagonal matrix of singular values\", \"page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Dimensions of Matrices X = T0 D0'S0 t x t t x m m x tm x m\", 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Reduced Rank•S0 can be chosen so that the diagonal elements are positive and decreasing in magnitude.  Keep the first k and set the others to zero.  •Delete the zero rows and columns of S0 and the corresponding rows and columns of T0 and D0. •Interpretation: If value of k is selected well, expectation is that X retains the semantic information, but eliminates noise from synonymy and recognizes dependence', \"page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Dimensionality  Reduction X = t x t t x k k x tk x k k is the number of latent concepts  (typically 300 ~ 500)X ~ X = TSD' T S D'^\", 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  SVD Applied to PPMI Word-Word Matrix 19.3 • D ENSE V ECTORS AND SVD 13 Singular Value Decomposition (SVD) is a method for ﬁnding the most impor- tant dimensions of a data set, those dimensions along which the data varies the most. It can be applied to any rectangular matrix and in language processing it was ﬁrst applied to the task of generating embeddings from term-document matrices by Deer- wester et al. (1988) in a model called Latent Semantic Indexing . In this section let’s look just at its application to a square term-context matrix M with | V | rows (one for each word) and columns (one for each context word) SVD factorizes M into the product of three square | V | ⇥ | V | matrices W , S , and C T . In W each row still represents a word, but the columns do not; each column now represents a dimension in a latent space, such that the | V | column vectors are orthogonal to each other and the columns are ordered by the amount of variance in the original dataset each accounts for. S is a diagonal | V | ⇥ | V | matrix, with singular values along the diagonal, expressing the importance of each dimension. The | V | ⇥ | V | matrix C T still represents contexts, but the rows now represent the new latent dimensions and the | V | row vectors are orthogonal to each other. By using only the ﬁrst k dimensions, of W, S, and C instead of all | V | dimen- sions, the product of these 3 matrices becomes a least-squares approximation to the original M . Since the ﬁrst dimensions encode the most variance, one way to view the reconstruction is thus as modeling the most important information in the original dataset. SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s V 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 C 3 7 7 7 7 7 5 | V | ⇥ | V | Taking only the top k dimensions after SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ k 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M .', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M . 3 3 Note that early systems often instead weighted W k by the singular values, using the product W k · S k as an embedding instead of just the matrix W k , but this weighting leads to signiﬁcantly worse embeddings (Levy et al., 2015) .', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Truncated SVD – Keep K Dimensions 19.3 • D ENSE V ECTORS AND SVD 13 Singular Value Decomposition (SVD) is a method for ﬁnding the most impor- tant dimensions of a data set, those dimensions along which the data varies the most. It can be applied to any rectangular matrix and in language processing it was ﬁrst applied to the task of generating embeddings from term-document matrices by Deer- wester et al. (1988) in a model called Latent Semantic Indexing . In this section let’s look just at its application to a square term-context matrix M with | V | rows (one for each word) and columns (one for each context word) SVD factorizes M into the product of three square | V | ⇥ | V | matrices W , S , and C T . In W each row still represents a word, but the columns do not; each column now represents a dimension in a latent space, such that the | V | column vectors are orthogonal to each other and the columns are ordered by the amount of variance in the original dataset each accounts for. S is a diagonal | V | ⇥ | V | matrix, with singular values along the diagonal, expressing the importance of each dimension. The | V | ⇥ | V | matrix C T still represents contexts, but the rows now represent the new latent dimensions and the | V | row vectors are orthogonal to each other. By using only the ﬁrst k dimensions, of W, S, and C instead of all | V | dimen- sions, the product of these 3 matrices becomes a least-squares approximation to the original M . Since the ﬁrst dimensions encode the most variance, one way to view the reconstruction is thus as modeling the most important information in the original dataset. SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s V 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 C 3 7 7 7 7 7 5 | V | ⇥ | V | Taking only the top k dimensions after SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ k 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M .', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M . 3 3 Note that early systems often instead weighted W k by the singular values, using the product W k · S k as an embedding instead of just the matrix W k , but this weighting leads to signiﬁcantly worse embeddings (Levy et al., 2015) .', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Truncated SVD Produces Embeddings•Each row of W matrix is a k-dimensional representation of each word w•Generally we keep the top k dimensions, but some experiments suggest that getting rid of the top 1 dimension or  even the top 50 dimensions is helpful (Lapesa and Evert 2014). 19.3 • D ENSE V ECTORS AND SVD 13 Singular Value Decomposition (SVD) is a method for ﬁnding the most impor- tant dimensions of a data set, those dimensions along which the data varies the most. It can be applied to any rectangular matrix and in language processing it was ﬁrst applied to the task of generating embeddings from term-document matrices by Deer- wester et al. (1988) in a model called Latent Semantic Indexing . In this section let’s look just at its application to a square term-context matrix M with | V | rows (one for each word) and columns (one for each context word) SVD factorizes M into the product of three square | V | ⇥ | V | matrices W , S , and C T . In W each row still represents a word, but the columns do not; each column now represents a dimension in a latent space, such that the | V | column vectors are orthogonal to each other and the columns are ordered by the amount of variance in the original dataset each accounts for. S is a diagonal | V | ⇥ | V | matrix, with singular values along the diagonal, expressing the importance of each dimension. The | V | ⇥ | V | matrix C T still represents contexts, but the rows now represent the new latent dimensions and the | V | row vectors are orthogonal to each other. By using only the ﬁrst k dimensions, of W, S, and C instead of all | V | dimen- sions, the product of these 3 matrices becomes a least-squares approximation to the original M . Since the ﬁrst dimensions encode the most variance, one way to view the reconstruction is thus as modeling the most important information in the original dataset. SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s V 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 C 3 7 7 7 7 7 5 | V | ⇥ | V | Taking only the top k dimensions after SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ k 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word.'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96b380>, 'json_data': {'input': ['page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Issues with Jaccard for Scoring•It does not consider term frequency (how many times a term occurs in a document)•Rare terms in a collection are more informative than frequent terms. Jaccard does not consider this information•We need a more sophisticated way of normalizing for length Ch. 6', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Recall (from Boolean Retrieval): Binary Term-Document Incidence MatrixAntony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony1 1 0 0 0 1Brutus1 1 0 1 0 0Caesar1 1 0 1 1 1Calpurnia0 1 0 0 0 0Cleopatra1 0 0 0 0 0mercy1 0 1 1 1 1worser1 0 1 1 1 0 Each document is represented by a binary vector ∈ {0,1}|V| Sec. 6.2', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term-document Count Matrices•Consider the number of occurrences of a term in a document: –Each document is a count vector: a column below  Antony and Cleopatra Julius Caesar The Tempest Hamlet Othello Macbeth Antony 157 73 0 0 0 0 Brutus 4 157 0 1 0 0 Caesar 232 227 0 2 1 1 Calpurnia 0 10 0 0 0 0 Cleopatra 57 0 0 0 0 0 mercy 2 0 3 5 5 1 worser 2 0 1 1 1 0 Sec. 6.2', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Vector-Space Model•t distinct terms remain after preprocessing–Unique terms that form the VOCABULARY•These “orthogonal” terms form a vector space.          Dimension = t = |vocabulary| –2 terms à bi-dimensional; …; n-terms à n-dimensional•Each term, i,  in a document or query j, is given a real-valued weight, wij.•Both documents and queries are expressed as t-dimensional vectors:          dj = (w1j, w2j, …, wtj)', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Vector-Space ModelQuery as vector:•We regard query as short document•We return the documents ranked by the closeness of their vectors to the query, also represented as a vector. •Vector-space model was developed in the SMART system (Salton, c.1970) and standardly used by TREC participants and web IR systems', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Graphic RepresentationExample:D1 = 2T1 + 3T2 + 5T3D2 = 3T1 + 7T2 +   T3Q = 0T1 + 0T2 +  2T3 T3 T1 T2 D1 = 2T1+ 3T2 + 5T3 D2 = 3T1 + 7T2 +  T3 Q = 0T1 + 0T2 + 2T3 7 32 5 •Is D1 or D2 more similar to Q?•How to measure the degree of similarity? Distance? Angle? Projection?', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Collection Representation•A collection of n documents can be represented in the vector space model by a term-document matrix.•An entry in the matrix corresponds to the “weight” of a term in the document; zero means the term has no significance in the document or it simply doesn’t exist in the document.T1   T2    ….      TtD1    w11  w21   …      wt1D2 w12  w22   …      wt2 :       :      :               : :       :      :               :Dn    w1n  w2n   …      wtn', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Frequency tf•The term frequency tft,d of term t in document d is defined as the number of times that t occurs in d.•More frequent terms in a document are more important, i.e. more indicative of the topic.•May want to normalize term frequency (tf) :        tft,d   = ft,d  / max{ft,d}•We want to use tf when computing query-document match scores. But how?', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Frequency tf•Raw term frequency is not what we want:–A document with 10 occurrences of the term is more relevant than a document with 1 occurrence of the term.–But not 10 times more relevant.•Relevance does not increase proportionally with term frequency.', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Frequency•Rare terms are more informative than frequent terms–Recall stop words•Consider a term in the query that is rare in the collection (e.g., arachnocentric)•A document containing this term is very likely to be relevant to the query arachnocentric•→ We want a high weight for rare terms like arachnocentric. Sec. 6.2.1', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Frequency (continued)•Frequent terms are less informative than rare terms•Consider a query term that is frequent in the collection (e.g., high, increase, line)•A document containing such a term is more likely to be relevant than a document that doesn’t•But it’s not a sure indicator of relevance.•→ For frequent terms, we want high positive weights for words like high, increase, and line•But lower weights than for rare terms.•We will use document frequency (df) to capture this. Sec. 6.2.1', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Idf Weight•dft is the document frequency of t: the number of documents that contain t–dft is an inverse measure of the informativeness of t–dft £ N•We define the idf (inverse document frequency) of t by–We use log (N/dft) instead of N/dft to “dampen” the effect of idf.idft = log10 (N/dft)Sec. 6.2.1', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  idf example, suppose N = 1 millionterm dft idftcalpurnia 1animal 100sunday 1,000fly 10,000under 100,000the 1,000,000 There is one idf value for each term t in a collection. Sec. 6.2.1 )/df( log  idf 10 tt N=', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Collection vs. Document Frequency•The collection frequency of t is the number of occurrences of t in the collection, counting multiple occurrences.•Example: •Which word is a better search term (and should get a higher weight)? WordCollection frequencyDocument frequency insurance10440 3997try 9800 8760 Sec. 6.2.1', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  tf-idf Weighting•The tf-idf weight of a term is the product of its tf weight and its idf weight. •Best known weighting scheme in information retrieval–Theoretically proven to work well (Papineni, NAACL 2001)–Note: the “-” in tf-idf is a hyphen, not a minus sign!–Alternative names: tf.idf, tf x idf•Increases with the number of occurrences within a document•Increases with the rarity of the term in the collection wt,d=tft,d×log10(N/dft)Sec. 6.2.2', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Computing tf-idf: An ExampleGiven a document containing terms with given frequencies:    A(3), B(2), C(1)Assume collection contains 10,000 documents and document frequencies of these terms are:    A(50), B(2500), C(100)Then (assuming log10)A:  tf = 3/3;  idf = log(10000/50) = 2.3;     tf-idf = 2.3B:  tf = 2/3;  idf = log(10000/2500) = 0.60; tf-idf = 0.40C:  tf = 1/3;  idf = log(10000/100) = 2.0;   tf-idf = 0.66', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Binary → Count → Weight matrixAntony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony5.253.180 0 0 0.35Brutus1.216.10 1 0 0Caesar8.592.540 1.510.250Calpurnia0 1.540 0 0 0Cleopatra2.850 0 0 0 0mercy1.510 1.90.125.250.88worser1.370 0.114.150.251.95 Each document is now represented by a real-valued vector of tf-idf weights ∈ R|V| Sec. 6.3', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Documents as Vectors•So we have a |V|-dimensional vector space•Terms are axes of the space•Documents are points or vectors in this space•Very high-dimensional: tens of millions of dimensions when you apply this to a web search engine•These are very sparse vectors - most entries are zero. Sec. 6.3', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Query as Vector•Query vector is typically treated as a document and also tf-idf weighted.•Alternative is for the user to supply weights for the given query terms.', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Similarity Measure•We now have vectors for all documents in the collection, a vector for the query, how to compute similarity? •A similarity measure is a function that computes the degree of similarity between two vectors.•Using a similarity measure between the query and each document:–It is possible to rank the retrieved documents in the order of presumed relevance.–It is possible to enforce a certain threshold so that the size of the retrieved set can be controlled.', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  First Cut: Euclidean Distance•Distance between vectors d1 and d2 is the length of the vector |d1 – d2|.–Euclidean distance•Exercise: Determine the Euclidean distance between the vectors (0, 3, 2, 1, 10) and (2, 7, 1, 0, 0)•Why is this not a great idea?•We still haven’t dealt with the issue of length normalization–Long documents would be more similar to each other by virtue of length, not topic', 'page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Second Cut: Manhattan Distance•Or “city block” measure–Based on the idea that generally in American cities you cannot follow a direct line between two points. •Uses the formula: •Exercise: Determine the Manhattan distance between the vectors (0, 3, 2, 1, 10) and (2, 7, 1, 0, 0) x y å = -= n i ii yxYXManhDist 1 ||),(', 'page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Third Cut: Inner Product•Similarity between vectors for the document di and query q can be computed as the vector inner product:               sim(dj,q) = dj•q =      wij · wiq        where wij is the weight of term i in document j and wiq is the weight of term i in the query•For binary vectors, the inner product is the number of matched query terms in the document (size of intersection).•For weighted term vectors, it is the sum of the products of the weights of the matched terms. å = t i 1', 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Properties of Inner Product•Favors long documents with a large number of unique terms.–Again, the issue of normalization•Measures how many terms matched but not how many terms are not matched.', 'page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  InnerProductExercise k1 k2 k3 q • dj  d1 1 0 1 ?  d2 1 0 0 ?  d3 0 1 1 ?  d4 1 0 0 ?  d5 1 1 1 ?  d6 1 1 0 ?  d7 0 1 0 ?        q 1 2 3', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity•Distance between vectors d1 and d2 captured by the cosine of the angle x between them.•Note – this is similarity, not distance t 1 d2 d1 t 3 t 2 θ', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity •Cosine of angle between two vectors•The denominator involves the lengths of the vectors•So the cosine measure is also known as the normalized inner product åå å == = = × = n i ki n i ji n i kiji kj kj kj ww ww dd dd ddsim 1 2 ,1 2 , 1 ,, ),( \\uf072\\uf072 \\uf072\\uf072 å = = n i jij wd 1 2 , Length \\uf072', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity Exercise•Exercise: Rank the following by decreasing cosine similarity:–(P1) Two documents that have only frequent words (the, a, an, of) in common.–(P2) Two documents that have no words in common.–(P3) Two documents that have many rare words in common (wingspan, tailfin). The ranking in decreasing order of their cosine similarity will be:A)P1, P3, P2B)P3, P2, P1C)P3, P1, P2', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity Example•Documents: Sense and Sensibility, Pride and Prejudice; Wuthering Heights  •cos(SaS,PaP) ≈ 0.789 × 0.832 + 0.515 × 0.555 + 0.335 × 0.0 + 0.0 × 0.0 ≈ 0.94•cos(SaS,WH) ≈ 0.79•cos(PaP,WH) ≈ 0.69 termSaSPaPWHaffection11558 20jealous10 7 11gossip2 0 6wuthering0 0 38 termSaSPaPWHaffection0.7890.8320.524jealous0.5150.5550.465gossip0.33500.405wuthering0 00.588 Why do we have cos(SaS,PaP) > cos(SaS,WH)?', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Cosine Similarity vs. Inner Product•Cosine similarity measures the cosine of the angle between two vectors.•Inner product normalized by the vector lengths.    D1 = 2T1 + 3T2 + 5T3     CosSim(D1 , Q) = 10 / Ö(4+9+25)(0+0+4) = 0.81D2 = 3T1 + 7T2 + 1T3     CosSim(D2 , Q) =  2 / Ö(9+49+1)(0+0+4) = 0.13 Q = 0T1 + 0T2 + 2T3 q2 t3 t1 t2 D1 D2 Qq1 D1 is 6 times better than D2 using cosine similarity but only 5 times better using inner product. å å å = = = • × × = × t i t i t i ww ww qd qd iqij iqij j j 1 1 22 1 )( \\uf072\\uf072 \\uf072\\uf072 CosSim(dj, q) = qd j \\uf072\\uf072 •InnerProduct(dj, q) =', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  ExerciseConsider the following four documents:•Doc1: apple orange banana peach•Doc2: orange orange apple apple•Doc3: banana tangerine peach•Doc4: peach peach apple bananaAnd the query:•Query: apple peach tangerineAssume no pre-processing (i.e., no normalization, no case-folding, no stopword-removal, no stemming), and a tfidf weighting scheme (tf not normalized, log based 10 for idf).1. Write the vector representations for each of the four documents and for the query.2. Determine the cosine similarities between each document and the query, and rank the documents.', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Comments on Vector Space Models•Simple, mathematically based approach. •Considers both local (tf) and global (idf) word occurrence frequencies.•Provides partial matching and ranked results.•Tends to work quite well in practice despite obvious weaknesses.•Allows efficient implementation for large document collections.', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Problems with Vector Space Model•Missing semantic information (e.g. word sense).•Missing syntactic information (e.g. phrase structure, word order, proximity information).•Assumption of term independence•Lacks the control of a Boolean model (e.g., requiring a term to appear in a document).–Given a two-term query “A B”, may prefer a document containing A frequently but not B, over a document that contains both A and B, but both less frequently.', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Evaluation of IR ModelsPrecision & Recall', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Standard Evaluation Measures w x y z n2 = w + y n1 = w + x N relevant not relevant retrievednot retrievedStart with a CONTINGENCY table', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Precision and Recall Recall: Precision: w w+y w+x w From all the documents that are relevant out there,how many did the IR system retrieve? From all the documents that are retrieved by the IR system, how many are relevant?', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Precision and Recall for a Set of Queries•For each query, determine the retrieved documents and the relevant documents  •Calculate–Macro-average: average the P/R/F calculated for the individual queries–Micro-average: sum all/relevant documents for individual queries, and calculate P/R/F only once', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Weighting Approaches', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Graphic RepresentationExample:D1 = 2T1 + 3T2 + 5T3D2 = 3T1 + 7T2 +   T3Q = 0T1 + 0T2 +  2T3 T3 T1 T2 D1 = 2T1+ 3T2 + 5T3 D2 = 3T1 + 7T2 +  T3 Q = 0T1 + 0T2 + 2T3 7 32 5 •Is D1 or D2 more similar to Q?•How to measure the degree of similarity? Distance? Angle? Projection?', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Document Collection Representation•A collection of n documents can be represented in the vector space model by a term-document matrix.•An entry in the matrix corresponds to the “weight” of a term in the document; zero means the term has no significance in the document or it simply doesn’t exist in the document.T1   T2    ….      TtD1    w11  w21   …      wt1D2 w12  w22   …      wt2 :       :      :               : :       :      :               :Dn    w1n  w2n   …      wtn', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Salton & Buckley•Experiments with term weighting approaches•Six collections, 1,800 term weighting approaches–287 combinations found to be distinct•Comparative evaluations using:–Ranking: the lower the better–Best weighting scheme has a rank of 1•Average search precision:–Average of precisions for recall points of 0.25, 0.50, 0.75•Average across queries:–Macro-average: average of the average search precisions', \"page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  IR Test Collections•CACM (articles from 'Communications of the ACM journal)•CISI (articles about information sciences)•CRAN (abstracts from aeronautics articles)•INSPEC (articles in computer engineering)•MED (medical articles) •NPL (articles about electrical engineering)\", 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  IR Collections', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Term Weighting Components', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Sample Weighting Schemes', 'page_label: 56 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Performance Results', 'page_label: 57 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Lessons Learned•Term weighting DOES matter•Query vector:–Term frequency•Use n for short queries•Use t for longer queries that require better discrimination among terms–Document frequency•Use f –Do not do normalization with query length', 'page_label: 58 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Lessons Learned•Document vectors:–Term-frequency:•For technical vocabulary (e.g., CRAN) use n•For more varied vocabulary, use t•For short document vectors, use b–Document frequency:•Inverse document-frequency f is similar to probabilistic term weight p: typically use f•For dynamic collections with many changes in the document collection makeup, use x–Normalization:•Typically use c (in particular when there is high deviation in vector length)•For short documents with homogenous length, use x', 'page_label: 59 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Vector Space Model Implementation', 'page_label: 60 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Naïve ImplementationConvert all documents in collection D to TF.IDF weighted vectors, dj, for keyword vocabulary V.Convert query to a tf-idf-weighted vector q.For each dj in D do      Compute score sj = cosSim(dj, q)Sort documents by decreasing score.Present top ranked documents to the user.Time complexity:  O(|V|·|D|)   Bad for large V & D !|V| = 10,000; |D| = 100,000; |V|·|D| = 1,000,000,000', 'page_label: 61 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Practical Implementation•Based on  the observation that documents containing none of the query keywords do not affect the final ranking•Try to identify only those documents that contain at least one query keyword•Actual implementation of an inverted index', 'page_label: 62 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 1: Preprocessing•Implement the preprocessing functions:–For tokenization–For stop word removal–For stemming •Input: Documents that are read one by one from the collection•Output: Tokens to be added to the index–No punctuation, no stop-words, stemmed', 'page_label: 63 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2: Indexing•Build an inverted index, with an entry for each word in the vocabulary •Input: Tokens obtained from the preprocessing module•Output: An inverted index for fast access', 'page_label: 64 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2 (continued)•Many data structures are appropriate for fast access•We need:–One entry for each word in the vocabulary–For each such entry:•Keep a list of all the documents where it appears together with the corresponding frequency à TF–For each such entry, keep the total number of occurrences in all documents:•à IDF', 'page_label: 65 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2 (continued) system computerdatabase scienceD2, 4D5, 2 D1, 3D7, 4Index termsdf32 41 Dj, tfj Index filelists •••', 'page_label: 66 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 2 (continued)•TF and IDF for each token can be computed in one pass •Cosine similarity also requires document lengths•Need a second pass to compute document vector lengths–Remember that the length of a document vector is the square-root of sum of the squares of the weights of its tokens.–Remember the weight of a token is: TF * IDF–Therefore, must wait until IDFs are known (and therefore until all documents are indexed) before document lengths can be determined.•Do a second pass over all documents: keep a list or hashtable with all document id-s, and for each document determine its length.', 'page_label: 67 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Time Complexity of Indexing•Complexity of creating vector and indexing a document of n tokens is O(n).•So indexing |D| such documents is O(|D| n).•Computing token IDFs can be done during the same first pass•Computing vector lengths is also O(|D| n).•Complete process is O(|D| n), which is also the complexity of just reading in the corpus.', 'page_label: 68 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 3: Retrieval •Use inverted index (from step 2) to find the limited set of documents that contain at least one of the query words.•Incrementally compute cosine similarity of each indexed document as query words are processed one by one.–If tf is normalized for the query, may need to first read all the query tokens•To accumulate a total score for each retrieved document, store retrieved documents in a hashtable (or another search data structure), where the document id is the key, and the partial accumulated score is the value.•Input: Query and Inverted Index (from Step 2)•Output: Similarity values between query and documents', 'page_label: 69 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Step 4: Ranking•Sort the search structure including the retrieved documents based on the value of cosine similarity•Return the documents in descending order of their relevance •Input: Similarity values between query and documents•Output: Ranked list of documented in reversed order of their relevance', 'page_label: 70 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf  Tfidf vectorizerIn the class, we learnt how to convert a document into a vector using tf-idf. While implementing a function for tf-idfis very easy, you can do that also using a library. Follow the code below.', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Information Retrieval and  Web SearchWord Representations', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Why Word Representations?•Computing with words–How similar is ‘car’ to ‘vehicle’? –How about ‘car’ to ‘wheel’?–How about ’car’ to ‘moon’?–How far is ‘man’ from ‘woman’?–How about ‘king’ from ‘queen’? •Mathematical representations of words, typically as vectors, that allow for computations–Measure similarity / distance between words', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Embeddings for IR•Compute similarity between query and documents using embedding vectors•Sum up all the embeddings to create one embedding for the document; one embedding for the query•Compute inner product or cosine similarity between these vectors•Note: embeddings are not transferable across spaces–The entries in the vector of embeddings have meaning only in the space where they were learned!', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Representations in IR/NLP•Core component in large number of IR tasks and applicationsQuery: ISTD SUTD But what if the words do not actually occur in the documents?', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Representations in IR/NLPQuestion answering:Q: “How tall is Mt. Everest?”Candidate A: “The official height of Mount Everest is 29029 feet” “tall” is similar to “height”', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  •Plagiarism detection Word Representations in IR/NLP', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Kulkarni, Al-Rfou, Perozzi, Skiena 2015 Word Representations in IR/NLP•Word meaning changes over time•Historical linguistics', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Core intuition:“You shall know a word by the company it keeps!”•Firth (1957)•Example:A bottle of tesgüino is on the tableEverybody likes tesgüinoTesgüino makes you drunkWe make tesgüino out of corn.•From context words humans can guess tesgüino means–an alcoholic beverage like beer•Two words are similar if they have similar word contexts.', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Vector RepresentationsSparse vector representations1.Vector space model2.Mutual-information co-occurrence matrices3.Explicit Semantic AnalysisDense vector representations:3.Singular value decomposition4.Neural network models (skip-grams, CBOW)', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Vector Space Model', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Term-Document MatrixAntony and CleopatraJulius CaesarThe TempestHamletOthelloMacbethAntony5.253.180 0 0 0.35Brutus1.216.10 1 0 0Caesar8.592.540 1.510.250Calpurnia0 1.540 0 0 0Cleopatra2.850 0 0 0 0mercy1.510 1.90.125.250.88worser1.370 0.114.150.251.95 Each word is now represented by a real-valued vector of tf-idf weights ∈ R|D| Sec. 6.3', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Co-occurrence Matrices', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word-Word or Word-Context Matrices•Instead of entire documents, use smaller contexts–Paragraph–Window of ± 4 words•A word is now defined by a vector over counts of context words•Instead of each vector being of length D•Each vector is now of length |V|•The word-word matrix is |V|x|V|', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word-Word MatrixSample contexts ± 7 words aardvarkcomputerdatapinchresultsugar…apricot0 0 0 1 0 1pineapple0 0 0 1 0 1digital0 2 1 0 1 0information0 1 6 0 4 0 19.1 • W ORDS AND V ECTORS 3 tors of numbers representing the terms (words) that occur within the collection (Salton, 1971) . In information retrieval these numbers are called the term weight ,aterm weight function of the term’s frequency in the document. More generally, the term-document matrix X has V rows (one for each word type in the vocabulary) and D columns (one for each document in the collection). Each column represents a document. A query is also represented by a vector q of length | V | . We go about ﬁnding the most relevant document to query by ﬁnding the document whose vector is most similar to the query; later in the chapter we’ll introduce some of the components of this process: the tf-idf term weighting, and the cosine similarity metric. But now let’s turn to the insight of vector semantics for representing the meaning of words . The idea is that we can also represent each word by a vector, now a row vector representing the counts of the word’s occurrence in each document. Thus the vectors for fool [37,58,1,5] and clown [5,117,0,0] are more similar to each other (occurring more in the comedies) while battle [1,1,8,15] and soldier [2,2,12,36] are more similar to each other (occurring less in the comedies). More commonly used for vector semantics than this term-document matrix is an alternative formulation, the term-term matrix , more commonly called the word-term-term matrix word matrix oro the term-context matrix , in which the columns are labeled by words rather than documents. This matrix is thus of dimensionality | V | ⇥ | V | and each cell records the number of times the row (target) word and the column (context) word co-occur in some context in some training corpus. The context could be the document, in which case the cell represents the number of times the two words appear in the same document. It is most common, however, to use smaller contexts, such as a window around the word, for example of 4 words to the left and 4 words to the right, in which case the cell represents the number of times (in some training corpus) the column word occurs in such a ± 4 word window around the row word. For example here are 7-word windows surrounding four sample words from the Brown corpus (just one example of each word): sugar, a sliced lemon, a tablespoonful of apricot preserve or jam, a pinch each of, their enjoyment. Cautiously she sampled her ﬁrst pineapple and another fruit whose taste she likened well suited to programming on the digital computer . In ﬁnding the optimal R-stage policy from for the purpose of gathering data and information necessary for the study authorized in the For each word we collect the counts (from the windows around each occurrence) of the occurrences of context words. Fig. 17.2 shows a selection from the word-word co-occurrence matrix computed from the Brown corpus for these four words. aardvark ... computer data pinch result sugar ... apricot 0 ... 0 0 10 1 pineapple 0 ... 0 0 10 1 digital 0 ... 2 10 10 information 0 ... 1 60 40 Figure 19.2 Co-occurrence vectors for four words, computed from the Brown corpus, showing only six of the dimensions (hand-picked for pedagogical purposes). Note that a real vector would be vastly more sparse. The shading in Fig. 17.2 makes clear the intuition that the two words apricot and pineapple are more similar (both pinch and sugar tend to occur in their window) while digital and information are more similar. Note that | V | , the length of the vector, is generally the size of the vocabulary, usually between 10,000 and 50,000 words (using the most frequent words in the … … •Two words are similar in meaning if their context vectors are similar', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word-word Matrix•We showed only 4x6, but the real matrix is 50,000 x 50,000–Very sparse•The size of windows depends on your goals–The shorter the windows , the more syntactic the representation± 1-3 very syntacticy–The longer the windows, the more semantic the representation± 4-10 more semanticy', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Pointwise Mutual Information Pointwise mutual information: Do events x and y co-occur more than if they were independent? PMI between two words:  (Church & Hanks 1989) Do words x and y co-occur more than if they were independent?  PMI𝑤𝑜𝑟𝑑!,𝑤𝑜𝑟𝑑\"=log\"𝑃(𝑤𝑜𝑟𝑑!,𝑤𝑜𝑟𝑑\")𝑃𝑤𝑜𝑟𝑑!𝑃(𝑤𝑜𝑟𝑑\") PMI(X,Y)=log2P(x,y)P(x)P(y)•Raw word frequency is not a great measure of association between words–It’s very skewed•“the” and “of” are very frequent, but maybe not the most discriminative', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Positive Pointwise Mutual Information–PMI ranges from −∞\\tto\\t+∞–But the negative values are problematic•Unreliable without very large corpora•It’s not clear people are good at “unrelatedness”–We just replace negative PMI values by 0–Positive PMI (PPMI) between word1 and word2:PPMI𝑤𝑜𝑟𝑑\",𝑤𝑜𝑟𝑑#=maxlog#𝑃(𝑤𝑜𝑟𝑑\",𝑤𝑜𝑟𝑑#)𝑃𝑤𝑜𝑟𝑑\"𝑃(𝑤𝑜𝑟𝑑#),0', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  PPMI on a Term-Context Matrix•Matrix F with W rows (words) and C columns (contexts)•fij is # of times wi occurs in context cj pij=fijfijj=1C∑i=1W∑pi*=fijj=1C∑fijj=1C∑i=1W∑p*j=fiji=1W∑fijj=1C∑i=1W∑pmiij=log2pijpi*p*jppmiij=pmiijif  pmiij>00otherwise!\"#$#', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  pij=fijfijj=1C∑i=1W∑pi*=fijj=1C∑fijj=1C∑i=1W∑p*j=fiji=1W∑fijj=1C∑i=1W∑What is PPMI(information,data)? pmiij=log2pijpi*p*jppmiij=pmiijif  pmiij>00otherwise!\"#$#', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  p(w,context)p(w)computerdatapinchresultsugarapricot0.000.000.050.000.050.11pineapple0.000.000.050.000.050.11digital0.110.050.000.050.000.21information0.050.320.000.210.000.58p(context)0.160.370.110.260.11 pij=fijfijj=1C∑i=1W∑', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  pmiij=log2pijpi*p*j p(w,context)p(w)computerdatapinchresultsugarapricot0.000.000.050.000.050.11pineapple0.000.000.050.000.050.11digital0.110.050.000.050.000.21information0.050.320.000.210.000.58p(context)0.160.370.110.260.11 PPMI(w,context)computerdatapinchresultsugarapricot1 1 2.251 2.25pineapple1 1 2.251 2.25digital1.660.001 0.001information0.000.571 0.471', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Weighting PMI•PMI is biased toward infrequent events–Very rare words have very high PMI values•Solution–Use Laplace smoothing', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Example: Add-two SmoothingAdd#2%Smoothed%Count(w,context)computerdatapinchresultsugarapricot2 2 3 2 3pineapple2 2 3 2 3digital4 3 2 3 2information3 8 2 6 2p(w,context),[add02]p(w)computerdatapinchresultsugarapricot0.030.030.050.030.050.20pineapple0.030.030.050.030.050.20digital0.070.050.030.050.030.24information0.050.140.030.100.030.36p(context)0.190.250.170.220.17', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  PPMI versus Add-2 Smoothed PPMI PPMI(w,context).[add22]computerdatapinchresultsugarapricot0.000.000.560.000.56pineapple0.000.000.560.000.56digital0.620.000.000.000.00information0.000.580.000.370.00 PPMI(w,context)computerdatapinchresultsugarapricot1 1 2.251 2.25pineapple1 1 2.251 2.25digital1.660.001 0.001information0.000.571 0.471', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis•Determine the extent to which each word is associated with every concept (article) of Wikipedia via term frequency or some other method.•For a text, sum up the associated concept vectors for a composite text concept vector.•Compare the texts using a standard vector similarity measure', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis Example•Word1: height•Word2: tallGlossary of cue sports termsAmerican Football StrategyBaseballBoston Red SoxWord1:2 0 6 3Word2:0 1 10 2', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Explicit Semantic Analysis Example•Text1: The dog caught the red ball.•Text2: A Labrador played in the park. •Can also be adapted to cross-language information retrieval Glossary of cue sports termsAmerican Football StrategyBaseballBoston Red SoxText1:27140 48 52Text2:10 17 10 7', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Singular Value Decomposition', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Sparse versus Dense Vectors•PPMI vectors are–long (length |V|= 20,000 to 50,000)–sparse (most elements are zero)•Alternative: learn vectors which are–short (length 200-1000)–dense (most elements are non-zero)', 'page_label: 31 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  •Why dense vectors?–Short vectors may be easier to use as features in machine learning (less weights to tune)–Dense vectors may generalize better than storing explicit counts–They may do better at capturing synonymy:•car and automobile are synonyms; but are represented as distinct dimensions; this fails to capture similarity between a word with car as a neighbor and a word with automobile as a neighbor Sparse versus Dense Vectors', \"page_label: 32 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Singular Value Decomposition•For any matrix X, with t rows and d columns, there exist matrices T0, S0 and D0', such that:•X = T0S0D0‘•T0 and D0 are the matrices of left and right singular vectors•S0 is the diagonal matrix of singular values\", \"page_label: 33 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Dimensions of Matrices X = T0 D0'S0 t x t t x m m x tm x m\", 'page_label: 34 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Reduced Rank•S0 can be chosen so that the diagonal elements are positive and decreasing in magnitude.  Keep the first k and set the others to zero.  •Delete the zero rows and columns of S0 and the corresponding rows and columns of T0 and D0. •Interpretation: If value of k is selected well, expectation is that X retains the semantic information, but eliminates noise from synonymy and recognizes dependence', \"page_label: 35 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Dimensionality  Reduction X = t x t t x k k x tk x k k is the number of latent concepts  (typically 300 ~ 500)X ~ X = TSD' T S D'^\", 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  SVD Applied to PPMI Word-Word Matrix 19.3 • D ENSE V ECTORS AND SVD 13 Singular Value Decomposition (SVD) is a method for ﬁnding the most impor- tant dimensions of a data set, those dimensions along which the data varies the most. It can be applied to any rectangular matrix and in language processing it was ﬁrst applied to the task of generating embeddings from term-document matrices by Deer- wester et al. (1988) in a model called Latent Semantic Indexing . In this section let’s look just at its application to a square term-context matrix M with | V | rows (one for each word) and columns (one for each context word) SVD factorizes M into the product of three square | V | ⇥ | V | matrices W , S , and C T . In W each row still represents a word, but the columns do not; each column now represents a dimension in a latent space, such that the | V | column vectors are orthogonal to each other and the columns are ordered by the amount of variance in the original dataset each accounts for. S is a diagonal | V | ⇥ | V | matrix, with singular values along the diagonal, expressing the importance of each dimension. The | V | ⇥ | V | matrix C T still represents contexts, but the rows now represent the new latent dimensions and the | V | row vectors are orthogonal to each other. By using only the ﬁrst k dimensions, of W, S, and C instead of all | V | dimen- sions, the product of these 3 matrices becomes a least-squares approximation to the original M . Since the ﬁrst dimensions encode the most variance, one way to view the reconstruction is thus as modeling the most important information in the original dataset. SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s V 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 C 3 7 7 7 7 7 5 | V | ⇥ | V | Taking only the top k dimensions after SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ k 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M .', 'page_label: 36 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M . 3 3 Note that early systems often instead weighted W k by the singular values, using the product W k · S k as an embedding instead of just the matrix W k , but this weighting leads to signiﬁcantly worse embeddings (Levy et al., 2015) .', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Truncated SVD – Keep K Dimensions 19.3 • D ENSE V ECTORS AND SVD 13 Singular Value Decomposition (SVD) is a method for ﬁnding the most impor- tant dimensions of a data set, those dimensions along which the data varies the most. It can be applied to any rectangular matrix and in language processing it was ﬁrst applied to the task of generating embeddings from term-document matrices by Deer- wester et al. (1988) in a model called Latent Semantic Indexing . In this section let’s look just at its application to a square term-context matrix M with | V | rows (one for each word) and columns (one for each context word) SVD factorizes M into the product of three square | V | ⇥ | V | matrices W , S , and C T . In W each row still represents a word, but the columns do not; each column now represents a dimension in a latent space, such that the | V | column vectors are orthogonal to each other and the columns are ordered by the amount of variance in the original dataset each accounts for. S is a diagonal | V | ⇥ | V | matrix, with singular values along the diagonal, expressing the importance of each dimension. The | V | ⇥ | V | matrix C T still represents contexts, but the rows now represent the new latent dimensions and the | V | row vectors are orthogonal to each other. By using only the ﬁrst k dimensions, of W, S, and C instead of all | V | dimen- sions, the product of these 3 matrices becomes a least-squares approximation to the original M . Since the ﬁrst dimensions encode the most variance, one way to view the reconstruction is thus as modeling the most important information in the original dataset. SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s V 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 C 3 7 7 7 7 7 5 | V | ⇥ | V | Taking only the top k dimensions after SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ k 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M .', 'page_label: 37 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M . 3 3 Note that early systems often instead weighted W k by the singular values, using the product W k · S k as an embedding instead of just the matrix W k , but this weighting leads to signiﬁcantly worse embeddings (Levy et al., 2015) .', 'page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Truncated SVD Produces Embeddings•Each row of W matrix is a k-dimensional representation of each word w•Generally we keep the top k dimensions, but some experiments suggest that getting rid of the top 1 dimension or  even the top 50 dimensions is helpful (Lapesa and Evert 2014). 19.3 • D ENSE V ECTORS AND SVD 13 Singular Value Decomposition (SVD) is a method for ﬁnding the most impor- tant dimensions of a data set, those dimensions along which the data varies the most. It can be applied to any rectangular matrix and in language processing it was ﬁrst applied to the task of generating embeddings from term-document matrices by Deer- wester et al. (1988) in a model called Latent Semantic Indexing . In this section let’s look just at its application to a square term-context matrix M with | V | rows (one for each word) and columns (one for each context word) SVD factorizes M into the product of three square | V | ⇥ | V | matrices W , S , and C T . In W each row still represents a word, but the columns do not; each column now represents a dimension in a latent space, such that the | V | column vectors are orthogonal to each other and the columns are ordered by the amount of variance in the original dataset each accounts for. S is a diagonal | V | ⇥ | V | matrix, with singular values along the diagonal, expressing the importance of each dimension. The | V | ⇥ | V | matrix C T still represents contexts, but the rows now represent the new latent dimensions and the | V | row vectors are orthogonal to each other. By using only the ﬁrst k dimensions, of W, S, and C instead of all | V | dimen- sions, the product of these 3 matrices becomes a least-squares approximation to the original M . Since the ﬁrst dimensions encode the most variance, one way to view the reconstruction is thus as modeling the most important information in the original dataset. SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s V 3 7 7 7 7 7 5 | V | ⇥ | V | 2 6 6 6 6 6 4 C 3 7 7 7 7 7 5 | V | ⇥ | V | Taking only the top k dimensions after SVD applied to co-occurrence matrix X: 2 6 6 6 6 6 4 X 3 7 7 7 7 7 5 | V | ⇥ | V | = 2 6 6 6 6 6 4 W 3 7 7 7 7 7 5 | V | ⇥ k 2 6 6 6 6 6 4 s 1 00 ... 0 0 s 2 0 ... 0 00 s 3 ... 0 . . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word.'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'554'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'987210'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'767ms'), (b'x-request-id', b'req_70a96e8825ef1eaf9078c5e95c7214c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c4212ce91a083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'554'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'987210'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'767ms'), (b'x-request-id', b'req_70a96e8825ef1eaf9078c5e95c7214c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c4212ce91a083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'554'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'987210'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'767ms'), (b'x-request-id', b'req_70a96e8825ef1eaf9078c5e95c7214c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c4212ce91a083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '554', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '987210', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '767ms', 'x-request-id': 'req_70a96e8825ef1eaf9078c5e95c7214c9', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c4212ce91a083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '554', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '987210', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '767ms', 'x-request-id': 'req_70a96e8825ef1eaf9078c5e95c7214c9', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c4212ce91a083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '554', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '987210', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '767ms', 'x-request-id': 'req_70a96e8825ef1eaf9078c5e95c7214c9', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c4212ce91a083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_70a96e8825ef1eaf9078c5e95c7214c9\n",
      "request_id: req_70a96e8825ef1eaf9078c5e95c7214c9\n",
      "request_id: req_70a96e8825ef1eaf9078c5e95c7214c9\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96b2e0>, 'json_data': {'input': ['page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M . 3 3 Note that early systems often instead weighted W k by the singular values, using the product W k · S k as an embedding instead of just the matrix W k , but this weighting leads to signiﬁcantly worse embeddings (Levy et al., 2015) . embedding for  word i', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Neural-Network Embeddings', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Neural Networks•Neural-inspired architectures used to predict output based on inputs–Typical classification task•Apply one or more layers of non-linear transformations to input data •Deep learning', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Applications of Neural Networks•Classification–Any classification task can be performed with an NN•Text representations–Word embeddings–Sentence embeddings•Sequence learning–Recurrent neural networks–LSTMs•Sequence generation–Sequence to sequence', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  A Neuron•A unit of computation in the neural network•Calculates output based on given input Σi1 i2 +1 w1w2 b Outputf(wi+b)', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Feed-forward Network Example •Assume a simple network, two inputs, two outputs, one hidden layer •Key idea: learn the weights from training data', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Training a Network•Run all the training instances through the network and adjust the weights•Typically:–Training data to learn weights–Development (dev) data to learn hyperparameters: •Number of layers•Number of units in layer•Learning rate•Etc.–Test data to evaluate performance', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Neural Networks for Word Embeddings•Skip-gram (Mikolov et al. 2013a)  •Continuous Bag of Words (CBOW) (Mikolov et al. 2013b)•Learn embeddings as part of the process of word prediction•Train a neural network to predict neighboring words•Inspired by neural net language models.•In so doing, learn dense embeddings for the words in the training corpus.', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Prediction-based Neural Network Models•Create a lot of training data “for free”•Take existing contexts as examples–“Children playing outside the house.”•Use a context window of 2C words from the current word–So for C=2, we are given word wt and have a context of 4 words: 14 C HAPTER 19 • V ECTOR S EMANTICS This method is sometimes called truncated SVD . SVD is parameterized by k ,truncated SVD the number of dimensions in the representation for each word, typically ranging from 500 to 1000. Usually, these are the highest-order dimensions, although for some tasks, it seems to help to actually throw out a small number of the most high- order dimensions, such as the ﬁrst 50 (Lapesa and Evert, 2014) . The dense embeddings produced by SVD sometimes perform better than the raw PPMI matrices on semantic tasks like word similarity. Various aspects of the dimensionality reduction seem to be contributing to the increased performance. If low-order dimensions represent unimportant information, the truncated SVD may be acting to removing noise. By removing parameters, the truncation may also help the models generalize better to unseen data. When using vectors in NLP tasks, having a smaller number of dimensions may make it easier for machine learning classiﬁers to properly weight the dimensions for the task. And the models may do better at capturing higher order co-occurrence. Nonetheless, there is a signiﬁcant computational cost for the SVD for a large co- occurrence matrix, and performance is not always better than using the full sparse PPMI vectors, so for some applications the sparse vectors are the right approach. Alternatively, the neural embeddings we discuss in the next section provide a popular efﬁcient solution to generating dense embeddings. 19.4 Embeddings from prediction: Skip-gram and CBOW An alternative to applying dimensionality reduction techniques like SVD to co- occurrence matrices is to apply methods that learn embeddings for words as part of the process of word prediction. Two methods for generating dense embeddings, skip-gram and CBOW ( continuous bag of words )( Mikolov et al. 2013 , Mikolovskip-gram CBOW et al. 2013a ), draw inspiration from the neural methods for language modeling intro- duced in Chapter 5. Like the neural language models, these models train a network to predict neighboring words, and while doing so learn dense embeddings for the words in the training corpus. The advantage of these methods is that they are fast, efﬁcient to train, and easily available online in the word2vec package; code and pretrained embeddings are both available. We’ll begin with the skip-gram model. The skip-gram model predicts each neighboring word in a context window of 2 C words from the current word. So for a context window C = 2 the context is [ w t \\x00 2 , w t \\x00 1 , w t + 1 , w t + 2 ] and we are pre- dicting each of these from word w t . Fig. 17.12 sketches the architecture for a sample context C = 1. The skip-gram model actually learns two d -dimensional embeddings for each word w : the input embedding v and the output embedding v 0 . These embeddings input embedding output embedding are encoded in two matrices, the input matrix W and the output matrix W 0 . Each column i of the input matrix W is the 1 ⇥ d vector embedding v i for word i in the vocabulary. Each row i of the output matrix W 0 is a d ⇥ 1 vector embedding v 0 i for word i in the vocabulary Let’s consider the prediction task. We are walking through a corpus of length T and currently pointing at the t th word w ( t ) , whose index in the vocabulary is j , so we’ll call it w j (1 < j < | V | ). Let’s consider predicting one of the 2 C context words, for example w ( t + 1 ) , whose index in the vocabulary is k (1 < k < | V | ). Hence our task is to compute P ( w k | w j ) .', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Learning Word Embeddings•Create a lot of training data “for free”•“Children playing outside the house.”•Two main “flavors” of word embeddings:•CBOW (continuous bag of words): predict the underlined word given its context•Skip-grams: predict the context given the underlined word', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Skip-grams Input layer Projection layer Output layer W |V|⨉d wt wt-1 wt+1 1-hot input vector 1⨉d1⨉|V| embedding for wt probabilities of context words W’ d ⨉ |V| W’ d ⨉ |V| x1 x2 xj x|V| y1 y2 yk y|V| y1 y2 yk y|V|', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Skip-grams: Training the Network•Use existing contexts as positive examples•Use random contexts as negative examples Children playing outside the housewt=outsidecontextpositive example [children, playing, the, house]negative examples [water, before, fast, no]            [today, increment, on, tube] 14 C HAPTER 19 • V ECTOR S EMANTICS This method is sometimes called truncated SVD . SVD is parameterized by k ,truncated SVD the number of dimensions in the representation for each word, typically ranging from 500 to 1000. Usually, these are the highest-order dimensions, although for some tasks, it seems to help to actually throw out a small number of the most high- order dimensions, such as the ﬁrst 50 (Lapesa and Evert, 2014) . The dense embeddings produced by SVD sometimes perform better than the raw PPMI matrices on semantic tasks like word similarity. Various aspects of the dimensionality reduction seem to be contributing to the increased performance. If low-order dimensions represent unimportant information, the truncated SVD may be acting to removing noise. By removing parameters, the truncation may also help the models generalize better to unseen data. When using vectors in NLP tasks, having a smaller number of dimensions may make it easier for machine learning classiﬁers to properly weight the dimensions for the task. And the models may do better at capturing higher order co-occurrence. Nonetheless, there is a signiﬁcant computational cost for the SVD for a large co- occurrence matrix, and performance is not always better than using the full sparse PPMI vectors, so for some applications the sparse vectors are the right approach. Alternatively, the neural embeddings we discuss in the next section provide a popular efﬁcient solution to generating dense embeddings. 19.4 Embeddings from prediction: Skip-gram and CBOW An alternative to applying dimensionality reduction techniques like SVD to co- occurrence matrices is to apply methods that learn embeddings for words as part of the process of word prediction. Two methods for generating dense embeddings, skip-gram and CBOW ( continuous bag of words )( Mikolov et al. 2013 , Mikolovskip-gram CBOW et al. 2013a ), draw inspiration from the neural methods for language modeling intro- duced in Chapter 5. Like the neural language models, these models train a network to predict neighboring words, and while doing so learn dense embeddings for the words in the training corpus. The advantage of these methods is that they are fast, efﬁcient to train, and easily available online in the word2vec package; code and pretrained embeddings are both available. We’ll begin with the skip-gram model. The skip-gram model predicts each neighboring word in a context window of 2 C words from the current word. So for a context window C = 2 the context is [ w t \\x00 2 , w t \\x00 1 , w t + 1 , w t + 2 ] and we are pre- dicting each of these from word w t . Fig. 17.12 sketches the architecture for a sample context C = 1. The skip-gram model actually learns two d -dimensional embeddings for each word w : the input embedding v and the output embedding v 0 . These embeddings input embedding output embedding are encoded in two matrices, the input matrix W and the output matrix W 0 . Each column i of the input matrix W is the 1 ⇥ d vector embedding v i for word i in the vocabulary. Each row i of the output matrix W 0 is a d ⇥ 1 vector embedding v 0 i for word i in the vocabulary Let’s consider the prediction task. We are walking through a corpus of length T and currently pointing at the t th word w ( t ) , whose index in the vocabulary is j , so we’ll call it w j (1 < j < | V | ). Let’s consider predicting one of the 2 C context words, for example w ( t + 1 ) , whose index in the vocabulary is k (1 < k < | V | ). Hence our task is to compute P ( w k | w j ) .', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  One-hot Vectors•As input, represent a word as a one-hot vector•A vector of length V (vocabulary), with just one component flipped to indicate the word•E.g., if “outside” is the 3rd word in the vocabulary, the one-hot vector will be  [0, 0, 1, 0, 0, …. 0]', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Forward/backward propagation•Initialize all weights with random values•Run forward propagation •Loss function:–Measure similarity of word with context\\t𝜎𝑤$%#𝑤$+𝜎𝑤$%\"𝑤$+𝜎𝑤$&\"𝑤$+ 𝜎𝑤$&#𝑤$–Minimize distance between  wt and context in positive example–Maximize distance between wt and context in negative examples', 'page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Skip-grams Input layer Projection layer Output layer W |V|⨉d wt wt-1 wt+1 1-hot input vector 1⨉d1⨉|V| embedding for wt probabilities of context words W’ d ⨉ |V| W’ d ⨉ |V| x1 x2 xj x|V| y1 y2 yk y|V| y1 y2 yk y|V|', 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  CBOWInput layer Projection layer Output layer W|V|⨉d wt wt-1 wt+1 1-hot input vectors for each context word 1⨉d 1⨉|V| sum of embeddings  for context words probability of wt W’ d ⨉ |V| x1 x2 xj x|V| y1 y2 yk y|V| x1 x2 xj x|V| W|V|⨉d', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Result•A “dense” vector learned after training the network, or length d•d varies: 50-300 –Larger d means more weights to learn•Learning word embeddings requires very large data–Mainly because we have to learn a large set of parameters (weights and embeddings)•Word embeddings capture word meaning–vector(‘king’) - vector(‘man’) + vector(‘woman’)  ≈\\tvector(‘queen’)–vector(‘Paris’) - vector(‘France’) + vector(‘Italy’) ≈ vector(‘Rome’)', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Embeddings in Practice•word2vec •https://code.google.com/p/word2vec/ includes the models and pre-trained embeddings–Trained on large news data•Gensim: Python library that works with word2vec–https://radimrehurek.com/gensim/', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  Introduction to Information Retrieval CS3245 Information Retrieval Lecture 4: Probabilistic IR', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilisticIRModelsataGlance InformationRetrieval 2 1.Classicalprobabilistic retrievalmodel■Probabilityrankingprinciple■BinaryIndependenceModel,BestMatch25(Okapi)2.Languagemodelapproachto IR■Importantrecentwork,competitiveperformanceProbabilisticmethodsareoneoftheoldestbutalsooneof  thecurrentlyhottesttopicsinIR Ch.11', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  ProbabilisticApproachtoRetrieval InformationRetrieval 3 ■Givenauserinformationneed(representedasaquery) and a collection of documents (transformed into documentrepresentations),asystemmustdetermine  howwellthedocumentssatisfythequery■BooleanorvectorspacemodelsofIR:query--document matching done in a formally defined but semantically imprecisecalculusof indexterms■An IR systemhas an uncertainunderstandingof the user query,and makesanuncertainguessofwhetheradocumentsatisfiesthequery■Probabilitytheoryprovidesaprincipledfoundationfor suchreasoningunderuncertainty■Probabilisticmodelsexploitthisfoundationtoestimatehowlikelyitis thatadocumentisrelevanttoaquery Ch.11', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  BasicProbabilityTheory InformationRetrieval 4 ■ForeventsAandB■JointprobabilityP(A,B)ofbotheventsoccurring.■ConditionalprobabilityP(A|B)ofeventA occurringgiventhateventBhas occurred.■Chainrulegivesfundamentalrelationshipbetweenjointandconditional probabilities: ■Similarlyforthecomplementofanevent:■Partitionrule:if B can be divided into an exhaustivesetof disjoint subcases,thenP(B)isthesumoftheprobabilitiesofthesubcases.■Thebinaryformofthisrulegives: Sec.11.1', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BasicProbabilityTheory InformationRetrieval 5 ■Bayes’Ruleforinvertingconditionalprobabilities: ■Canbethoughtof asawayofupdatingprobabilities:■StartoffwithpriorprobabilityP(A)(initialestimateofhow  likelyeventAisintheabsenceofanyotherinformation)■Derive a posterior probability P(A|B) after having seen the evidenceB,basedonthelikelihoodofBoccurringinthetwo  casesthatAdoesordoesnothold■Oddsofaneventprovideamultiplierforhow  probabilitieschange: Sec.11.1', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  THEPROBABILITY RANKINGPRINCIPLE Sec.11.2 InformationRetrieval 6', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval TheDocumentRankingProblem InformationRetrieval 7 ■Rankedretrievalsetup:givenacollectionof  documents,theuserissuesaquery, andanordered listofdocumentsisreturned,■Assume binary notion of relevance: Rd,q is a random binaryvariable,suchthat:■Rd,q=1ifdocumentdisrelevanttoqueryq■Rd,q=0otherwise■Probabilisticrankingordersdocumentsdecreasingly bytheirestimatedprobabilityofrelevancetothe  query:P(R=1|d,q) Sec.11.2', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilityRankingPrinciple(PRP) InformationRetrieval 8 ■PRPinbrief■Iftheretrieveddocuments(w.r.t.aquery)areranked  decreasingly on their probability of relevance, then the effectivenessofthesystemwillbethebestthatisobtainable■PRPinfull■If [the IR] system’s response to each [query] is a ranking of the documents[...]inorderofdecreasingprobabilityofrelevanceto the [query], where the probabilities are estimated as accuratelyaspossibleonthebasisofwhateverdatahavebeen madeavailabletothesystemforthispurpose,theoverall  effectivenessofthesystemtoitsuserwillbethebestthatis  obtainableonthebasisofthosedata Sec.11.2', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel(BIM) InformationRetrieval 9 ■TraditionallyusedwiththePRPAssumptions:■Binary(equivalenttoBoolean):documentsand  queriesrepresentedasbinarytermincidencevectors■E.g.,documentdrepresentedbyvector®x=(x1,...,xM),where■xt =1iftermtoccursindandxt =0otherwise■Differentdocumentsmayhavethesamevectorrepresentation■Independence:noassociationbetweenterms(not true,butworksinpractice–naïveassumption) Sec.11.3', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel InformationRetrieval 10 ■To make a probabilistic retrieval strategy precise, we needtoestimatehowtermsindocumentscontributeto relevance■Findmeasurablestatisticsthataffectjudgmentsabout  documentrelevance■UsethemtoestimatetheprobabilityofrelevanceP(R|d,q)■Orderdocumentsbydecreasingprobabilityvalues.■Assume:Relevanceofindividualdocumentsareindependent (nottrue;duplicateresultsconsideredbad) Sec.11.3', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel InformationRetrieval 11 ismodeledusingtermincidencevectorsas ■ : :and probabilitythatifarelevantor  nonrelevant document is retrieved, then that document’s representationis■Statisticsabouttheactualdocumentcollectionareusedto  estimatetheseprobabilities Sec.11.3', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel InformationRetrieval 12 ■ and :priorprobabilityofretrievingarelevantornonrelevantdocumentforaqueryq■Estimateand frompercentageofrelevantdocumentsinthecollection■Sinceadocumentiseitherrelevantornonrelevanttoaquery, wehave: Sec.11.3 Sameequationas onpreviousslide', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Givenaqueryq,rankingdocumentsby ismodeledunderBIMasrankingthemby■Easier:rankdocumentsbytheiroddsofrelevance(givessame  ranking,pluswecanignorethecommondenominator) ■ isaconstantforagivenquery–canbeignored Deriving aRankingFunction  forQueryTerms InformationRetrieval 13 Sec.11.3.1 Dropthis  term', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Itisatthispointthatwemakethe(NaïveBayes)conditional independenceassumptionthatthepresenceorabsenceofa wordinadocumentisindependentofthepresenceor  absenceofanyotherword(giventhequery): ■So: Deriving aRankingFunction  forQueryTerms InformationRetrieval 14 Sec.11.3.1 Dropped  termJustfocusonthisterm', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Sinceeachxtiseitherpresent(1)orabsent(0),wecan  separatethetermstogive: ■Let betheprobabilityofaterm  appearinginrelevantdocument■Let betheprobabilityofaterm  appearinginanonrelevantdocument■Visualisethisasacontingencytable: Deriving aRankingFunction  forQueryTerms InformationRetrieval 15 Sec.11.3.1', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Additionalsimplifyingassumption:termsnotoccurringin thequeryareequally likelytooccurinrelevantand  nonrelevantdocuments. I.e.,Ifqt=0,thenpt=ut■Nowweneedonlytoconsidertermsintheproductsthatappearinthequery: ■Theleftproductisoverquerytermsfoundinthedocumentand therightproductisoverquerytermsnotfoundinthedocument Deriving aRankingFunction  forQueryTerms !! !O(R|q,x) =O(R|q)× t×upt 1-ptt:xt=qt=1Õ 1-utt:xt=0,qt=1Õ Sec.11.3.1 InformationRetrieval 16', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Includingthequerytermsfoundinthedocumentintotheright product,butsimultaneouslydividingthroughbythemintheleft product,gives:■Theleftproductisstilloverquerytermsfoundinthedocument, buttherightproductisnowoverallqueryterms,hence  constantforaparticularqueryandcanbeignored.Theonlyquantitythatneedstobeestimatedtorankdocumentsw.r.t.aqueryistheLHSproduct.■HencetheRetrievalStatusValue(RSV)inthismodelis: Deriving aRankingFunction  forQueryTerms InformationRetrieval 17 Sec.11.3.1', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval Deriving aRankingFunction  forQueryTerms InformationRetrieval 18 ■SoitboilsdowntocomputingRSV.Wecanrankdocuments usingthelogoddsratiosforthetermsinthequeryct: ■Theoddsratioistheratiooftwoodds:(i)theoddsofthetermappearingifrelevant(pt/(1−pt)),and(ii)theoddsofthetermappearingifnonrelevant(ut/(1−ut))■ct= 0 if a termhas equal odds of appearingin relevantand nonrelevantdocuments,and ct is positiveif it is more likely to appear inrelevantdocuments.■ctfunctionsasatermweight,sothat■Operationally,wesumctquantitiesinaccumulatorsforquery termsappearingindocuments,justlikeintheVSM. Sec.11.3.1', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilityEstimatesinTheory InformationRetrieval 19 ■Foreachtermtinaquery,estimatectinthewholecollectionusing acontingencytableofcountsofdocumentsinthecollection,where dft isthenumberofdocumentsthatcontaintermt:■s = number of relevant documents where x_t= q_t= 1■S = number of total retrieved documents.  ■Toavoidzeroprobabilities(suchasifeveryornorelevant  documenthasaparticularterm),weapplysmoothing. Sec.11.3.1 +-Termpresent inrelevantdocument+-Termabsent inrelevant document', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  ProbabilityEstimatesinPractice InformationRetrieval 20 ■Assumingthatrelevantdocumentsareaverysmall  percentage of the collection, we approximate statistics for nonrelevant documents by statistics fromthewholecollection■Hence, ut (the probability of term occurrence in nonrelevantdocumentsforaquery)isdft/Nand,log[(1 −ut)/ut]=log[(N−dft)/dft]≈log N/dft ■Butnotethattheaboveapproximationcannoteasily beextendedtorelevantdocuments. Sec.11.3.3', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilityEstimatesinPractice■Statisticsofrelevantdocuments(pt)canbeestimatedin variousways:1.Usethefrequencyoftermoccurrenceinknownrelevant  documents(ifknown).2.Setasconstant.E.g.,assumethatptisconstantoverallterms xt inthequeryandthatpt =0.5■Eachtermisequallylikelytooccurinarelevantdocument,andsothe  ptand(1−pt)factorscanceloutintheexpressionforRSV■Weakestimate,butdoesn’tdisagreeviolentlywithexpectationthat  querytermsappearinmanybutnotallrelevantdocuments■Combiningthismethodwiththeearlierapproximationforut,the  documentrankingisdeterminedsimplybywhichquerytermsoccurin documentsscaledbytheiridfweighting■Forshortdocuments(titlesorabstracts)inone--passretrieval situations,thisestimatecanbequitesatisfactoryInformationRetrieval Sec.11.3.3', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  Probabilistic Relevance Feedback k k + + = || || )1( )2( V pV p ii i 1.Guess a preliminary probabilistic description of R=1documents; use it to retrieve a set of documents2.Interact with the user to refine the description: learn some definite members with R = 1 and R = 03.Re-estimate piand uion the basis ofthese• If iappears in Viwithin set of documents V: pi= |Vi|/|V|•Or can combine new information with original guess (use Bayesian prior):4.Repeat, thus generating a succession of approximations to relevant documents κis priorweight', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  Pseudo-relevance feedback(iteratively auto-estimate piandui)1.Assume that piis constant over all xiin query and uias before•pi= 0.5 (even odds) for any given doc2.Determine guess of relevant document set:•Vis fixed size set of highest ranked documents on this model3.We need to improve our guesses for piand ui, so•Use distribution of xiin docs in V. Let Vibe set of documents containing xi•pi= |Vi| / |V|•Assume if not retrieved then not relevant •ui= (dfi–|Vi|) / (N –|V|)4.Go to 2. until converges then return ranking 23', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ANAPPRAISALOF PROBABILISTICMODELS24 Sec.11.4 InformationRetrieval', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval AnAppraisalofProbabilisticModels InformationRetrieval ■AmongtheoldestformalmodelsinIR■(MaronandKuhns,1960)SinceanIR systemcannot  predictwithcertaintywhichdocumentisrelevant,we shoulddealwithprobabilities■Assumptionsforgettingreasonableapproximations  oftheneededprobabilities(intheBIM):■Booleanrepresentationofdocuments/queries/relevance■Termindependence■Out--of--querytermsdonotaffectretrieval■Documentrelevancevaluesareindependent', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval AnAppraisalofProbabilisticModels InformationRetrieval ■Thedifferencebetween‘vectorspace’and‘probabilistic’IRisnotthatgreat:■Ineithercaseyoubuildaninformationretrievalschemein  theexactsameway.■Difference:forprobabilisticIR,attheend,youscore  queriesnotbycosinesimilarityandtf.idfinavectorspace, butbyaslightlydifferentformulamotivatedbyprobability theory Sec.11.4.1', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:ANonbinaryModel InformationRetrieval ■TheBIMwasoriginallydesignedforshortcatalog recordsoffairlyconsistentlength,anditworks  reasonablyinthesecontexts■Formodernfull--textsearchcollections,amodel should pay attention to term frequency and documentlength■BestMatch25(i.e.,BM25orOkapi)issensitiveto thesequantities■From1994untiltoday,BM25isoneofthemost widelyusedandrobustretrievalmodels Sec.11.4.3', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:ANonbinaryModel InformationRetrieval ■Thesimplestscorefordocumentdisjustidfweightingofthequery termspresentinthedocument: ■Improvethisformulabyfactoringinthetermfrequencyand documentlength: ■tftd:termfrequencyindocumentd■Ld(Lave):lengthofdocumentd(averagedocumentlengthinthe wholecollection)■k1:tuningparametercontrollingthedocumenttermfrequency scaling■b:tuningparametercontrollingthescalingbydocumentlength Sec.11.4.3', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:ANonbinaryModel InformationRetrieval ■Ifthequeryislong,wemightalsousesimilarweightingforquery terms ■tftq:termfrequencyinthequeryq■k3:tuningparametercontrollingtermfrequencyscalingofthe query■Nolengthnormalizationofqueries(becauseretrievalisbeingdonewithrespecttoasinglefixedquery)■Theabovetuningparametersshouldbesetbyoptimizationona developmenttestcollection.Experimentshaveshownreasonable valuesfork1andk3asvaluesbetween1.2and2andb=0.75 Sec.11.4.3', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:Factoring in the Relevance Feedback in Equation you see in slide 19. InformationRetrieval Sec.11.4.3 Including relevance feedback in c_tor the above term will give us the equation below for BM25. s is |VR_t|S –s is |VNR_t|. |VR| = total retrieved relevant documents. |VR_t| = total retrieved relevant documents where term t appears. |VNR_t| = total retrieved relevant documents where term t does not appear. Check slide 19 and consider we got some user inputs on the relevance'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96b2e0>, 'json_data': {'input': ['page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M . 3 3 Note that early systems often instead weighted W k by the singular values, using the product W k · S k as an embedding instead of just the matrix W k , but this weighting leads to signiﬁcantly worse embeddings (Levy et al., 2015) . embedding for  word i', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Neural-Network Embeddings', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Neural Networks•Neural-inspired architectures used to predict output based on inputs–Typical classification task•Apply one or more layers of non-linear transformations to input data •Deep learning', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Applications of Neural Networks•Classification–Any classification task can be performed with an NN•Text representations–Word embeddings–Sentence embeddings•Sequence learning–Recurrent neural networks–LSTMs•Sequence generation–Sequence to sequence', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  A Neuron•A unit of computation in the neural network•Calculates output based on given input Σi1 i2 +1 w1w2 b Outputf(wi+b)', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Feed-forward Network Example •Assume a simple network, two inputs, two outputs, one hidden layer •Key idea: learn the weights from training data', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Training a Network•Run all the training instances through the network and adjust the weights•Typically:–Training data to learn weights–Development (dev) data to learn hyperparameters: •Number of layers•Number of units in layer•Learning rate•Etc.–Test data to evaluate performance', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Neural Networks for Word Embeddings•Skip-gram (Mikolov et al. 2013a)  •Continuous Bag of Words (CBOW) (Mikolov et al. 2013b)•Learn embeddings as part of the process of word prediction•Train a neural network to predict neighboring words•Inspired by neural net language models.•In so doing, learn dense embeddings for the words in the training corpus.', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Prediction-based Neural Network Models•Create a lot of training data “for free”•Take existing contexts as examples–“Children playing outside the house.”•Use a context window of 2C words from the current word–So for C=2, we are given word wt and have a context of 4 words: 14 C HAPTER 19 • V ECTOR S EMANTICS This method is sometimes called truncated SVD . SVD is parameterized by k ,truncated SVD the number of dimensions in the representation for each word, typically ranging from 500 to 1000. Usually, these are the highest-order dimensions, although for some tasks, it seems to help to actually throw out a small number of the most high- order dimensions, such as the ﬁrst 50 (Lapesa and Evert, 2014) . The dense embeddings produced by SVD sometimes perform better than the raw PPMI matrices on semantic tasks like word similarity. Various aspects of the dimensionality reduction seem to be contributing to the increased performance. If low-order dimensions represent unimportant information, the truncated SVD may be acting to removing noise. By removing parameters, the truncation may also help the models generalize better to unseen data. When using vectors in NLP tasks, having a smaller number of dimensions may make it easier for machine learning classiﬁers to properly weight the dimensions for the task. And the models may do better at capturing higher order co-occurrence. Nonetheless, there is a signiﬁcant computational cost for the SVD for a large co- occurrence matrix, and performance is not always better than using the full sparse PPMI vectors, so for some applications the sparse vectors are the right approach. Alternatively, the neural embeddings we discuss in the next section provide a popular efﬁcient solution to generating dense embeddings. 19.4 Embeddings from prediction: Skip-gram and CBOW An alternative to applying dimensionality reduction techniques like SVD to co- occurrence matrices is to apply methods that learn embeddings for words as part of the process of word prediction. Two methods for generating dense embeddings, skip-gram and CBOW ( continuous bag of words )( Mikolov et al. 2013 , Mikolovskip-gram CBOW et al. 2013a ), draw inspiration from the neural methods for language modeling intro- duced in Chapter 5. Like the neural language models, these models train a network to predict neighboring words, and while doing so learn dense embeddings for the words in the training corpus. The advantage of these methods is that they are fast, efﬁcient to train, and easily available online in the word2vec package; code and pretrained embeddings are both available. We’ll begin with the skip-gram model. The skip-gram model predicts each neighboring word in a context window of 2 C words from the current word. So for a context window C = 2 the context is [ w t \\x00 2 , w t \\x00 1 , w t + 1 , w t + 2 ] and we are pre- dicting each of these from word w t . Fig. 17.12 sketches the architecture for a sample context C = 1. The skip-gram model actually learns two d -dimensional embeddings for each word w : the input embedding v and the output embedding v 0 . These embeddings input embedding output embedding are encoded in two matrices, the input matrix W and the output matrix W 0 . Each column i of the input matrix W is the 1 ⇥ d vector embedding v i for word i in the vocabulary. Each row i of the output matrix W 0 is a d ⇥ 1 vector embedding v 0 i for word i in the vocabulary Let’s consider the prediction task. We are walking through a corpus of length T and currently pointing at the t th word w ( t ) , whose index in the vocabulary is j , so we’ll call it w j (1 < j < | V | ). Let’s consider predicting one of the 2 C context words, for example w ( t + 1 ) , whose index in the vocabulary is k (1 < k < | V | ). Hence our task is to compute P ( w k | w j ) .', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Learning Word Embeddings•Create a lot of training data “for free”•“Children playing outside the house.”•Two main “flavors” of word embeddings:•CBOW (continuous bag of words): predict the underlined word given its context•Skip-grams: predict the context given the underlined word', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Skip-grams Input layer Projection layer Output layer W |V|⨉d wt wt-1 wt+1 1-hot input vector 1⨉d1⨉|V| embedding for wt probabilities of context words W’ d ⨉ |V| W’ d ⨉ |V| x1 x2 xj x|V| y1 y2 yk y|V| y1 y2 yk y|V|', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Skip-grams: Training the Network•Use existing contexts as positive examples•Use random contexts as negative examples Children playing outside the housewt=outsidecontextpositive example [children, playing, the, house]negative examples [water, before, fast, no]            [today, increment, on, tube] 14 C HAPTER 19 • V ECTOR S EMANTICS This method is sometimes called truncated SVD . SVD is parameterized by k ,truncated SVD the number of dimensions in the representation for each word, typically ranging from 500 to 1000. Usually, these are the highest-order dimensions, although for some tasks, it seems to help to actually throw out a small number of the most high- order dimensions, such as the ﬁrst 50 (Lapesa and Evert, 2014) . The dense embeddings produced by SVD sometimes perform better than the raw PPMI matrices on semantic tasks like word similarity. Various aspects of the dimensionality reduction seem to be contributing to the increased performance. If low-order dimensions represent unimportant information, the truncated SVD may be acting to removing noise. By removing parameters, the truncation may also help the models generalize better to unseen data. When using vectors in NLP tasks, having a smaller number of dimensions may make it easier for machine learning classiﬁers to properly weight the dimensions for the task. And the models may do better at capturing higher order co-occurrence. Nonetheless, there is a signiﬁcant computational cost for the SVD for a large co- occurrence matrix, and performance is not always better than using the full sparse PPMI vectors, so for some applications the sparse vectors are the right approach. Alternatively, the neural embeddings we discuss in the next section provide a popular efﬁcient solution to generating dense embeddings. 19.4 Embeddings from prediction: Skip-gram and CBOW An alternative to applying dimensionality reduction techniques like SVD to co- occurrence matrices is to apply methods that learn embeddings for words as part of the process of word prediction. Two methods for generating dense embeddings, skip-gram and CBOW ( continuous bag of words )( Mikolov et al. 2013 , Mikolovskip-gram CBOW et al. 2013a ), draw inspiration from the neural methods for language modeling intro- duced in Chapter 5. Like the neural language models, these models train a network to predict neighboring words, and while doing so learn dense embeddings for the words in the training corpus. The advantage of these methods is that they are fast, efﬁcient to train, and easily available online in the word2vec package; code and pretrained embeddings are both available. We’ll begin with the skip-gram model. The skip-gram model predicts each neighboring word in a context window of 2 C words from the current word. So for a context window C = 2 the context is [ w t \\x00 2 , w t \\x00 1 , w t + 1 , w t + 2 ] and we are pre- dicting each of these from word w t . Fig. 17.12 sketches the architecture for a sample context C = 1. The skip-gram model actually learns two d -dimensional embeddings for each word w : the input embedding v and the output embedding v 0 . These embeddings input embedding output embedding are encoded in two matrices, the input matrix W and the output matrix W 0 . Each column i of the input matrix W is the 1 ⇥ d vector embedding v i for word i in the vocabulary. Each row i of the output matrix W 0 is a d ⇥ 1 vector embedding v 0 i for word i in the vocabulary Let’s consider the prediction task. We are walking through a corpus of length T and currently pointing at the t th word w ( t ) , whose index in the vocabulary is j , so we’ll call it w j (1 < j < | V | ). Let’s consider predicting one of the 2 C context words, for example w ( t + 1 ) , whose index in the vocabulary is k (1 < k < | V | ). Hence our task is to compute P ( w k | w j ) .', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  One-hot Vectors•As input, represent a word as a one-hot vector•A vector of length V (vocabulary), with just one component flipped to indicate the word•E.g., if “outside” is the 3rd word in the vocabulary, the one-hot vector will be  [0, 0, 1, 0, 0, …. 0]', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Forward/backward propagation•Initialize all weights with random values•Run forward propagation •Loss function:–Measure similarity of word with context\\t𝜎𝑤$%#𝑤$+𝜎𝑤$%\"𝑤$+𝜎𝑤$&\"𝑤$+ 𝜎𝑤$&#𝑤$–Minimize distance between  wt and context in positive example–Maximize distance between wt and context in negative examples', 'page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Skip-grams Input layer Projection layer Output layer W |V|⨉d wt wt-1 wt+1 1-hot input vector 1⨉d1⨉|V| embedding for wt probabilities of context words W’ d ⨉ |V| W’ d ⨉ |V| x1 x2 xj x|V| y1 y2 yk y|V| y1 y2 yk y|V|', 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  CBOWInput layer Projection layer Output layer W|V|⨉d wt wt-1 wt+1 1-hot input vectors for each context word 1⨉d 1⨉|V| sum of embeddings  for context words probability of wt W’ d ⨉ |V| x1 x2 xj x|V| y1 y2 yk y|V| x1 x2 xj x|V| W|V|⨉d', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Result•A “dense” vector learned after training the network, or length d•d varies: 50-300 –Larger d means more weights to learn•Learning word embeddings requires very large data–Mainly because we have to learn a large set of parameters (weights and embeddings)•Word embeddings capture word meaning–vector(‘king’) - vector(‘man’) + vector(‘woman’)  ≈\\tvector(‘queen’)–vector(‘Paris’) - vector(‘France’) + vector(‘Italy’) ≈ vector(‘Rome’)', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Embeddings in Practice•word2vec •https://code.google.com/p/word2vec/ includes the models and pre-trained embeddings–Trained on large news data•Gensim: Python library that works with word2vec–https://radimrehurek.com/gensim/', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  Introduction to Information Retrieval CS3245 Information Retrieval Lecture 4: Probabilistic IR', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilisticIRModelsataGlance InformationRetrieval 2 1.Classicalprobabilistic retrievalmodel■Probabilityrankingprinciple■BinaryIndependenceModel,BestMatch25(Okapi)2.Languagemodelapproachto IR■Importantrecentwork,competitiveperformanceProbabilisticmethodsareoneoftheoldestbutalsooneof  thecurrentlyhottesttopicsinIR Ch.11', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  ProbabilisticApproachtoRetrieval InformationRetrieval 3 ■Givenauserinformationneed(representedasaquery) and a collection of documents (transformed into documentrepresentations),asystemmustdetermine  howwellthedocumentssatisfythequery■BooleanorvectorspacemodelsofIR:query--document matching done in a formally defined but semantically imprecisecalculusof indexterms■An IR systemhas an uncertainunderstandingof the user query,and makesanuncertainguessofwhetheradocumentsatisfiesthequery■Probabilitytheoryprovidesaprincipledfoundationfor suchreasoningunderuncertainty■Probabilisticmodelsexploitthisfoundationtoestimatehowlikelyitis thatadocumentisrelevanttoaquery Ch.11', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  BasicProbabilityTheory InformationRetrieval 4 ■ForeventsAandB■JointprobabilityP(A,B)ofbotheventsoccurring.■ConditionalprobabilityP(A|B)ofeventA occurringgiventhateventBhas occurred.■Chainrulegivesfundamentalrelationshipbetweenjointandconditional probabilities: ■Similarlyforthecomplementofanevent:■Partitionrule:if B can be divided into an exhaustivesetof disjoint subcases,thenP(B)isthesumoftheprobabilitiesofthesubcases.■Thebinaryformofthisrulegives: Sec.11.1', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BasicProbabilityTheory InformationRetrieval 5 ■Bayes’Ruleforinvertingconditionalprobabilities: ■Canbethoughtof asawayofupdatingprobabilities:■StartoffwithpriorprobabilityP(A)(initialestimateofhow  likelyeventAisintheabsenceofanyotherinformation)■Derive a posterior probability P(A|B) after having seen the evidenceB,basedonthelikelihoodofBoccurringinthetwo  casesthatAdoesordoesnothold■Oddsofaneventprovideamultiplierforhow  probabilitieschange: Sec.11.1', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  THEPROBABILITY RANKINGPRINCIPLE Sec.11.2 InformationRetrieval 6', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval TheDocumentRankingProblem InformationRetrieval 7 ■Rankedretrievalsetup:givenacollectionof  documents,theuserissuesaquery, andanordered listofdocumentsisreturned,■Assume binary notion of relevance: Rd,q is a random binaryvariable,suchthat:■Rd,q=1ifdocumentdisrelevanttoqueryq■Rd,q=0otherwise■Probabilisticrankingordersdocumentsdecreasingly bytheirestimatedprobabilityofrelevancetothe  query:P(R=1|d,q) Sec.11.2', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilityRankingPrinciple(PRP) InformationRetrieval 8 ■PRPinbrief■Iftheretrieveddocuments(w.r.t.aquery)areranked  decreasingly on their probability of relevance, then the effectivenessofthesystemwillbethebestthatisobtainable■PRPinfull■If [the IR] system’s response to each [query] is a ranking of the documents[...]inorderofdecreasingprobabilityofrelevanceto the [query], where the probabilities are estimated as accuratelyaspossibleonthebasisofwhateverdatahavebeen madeavailabletothesystemforthispurpose,theoverall  effectivenessofthesystemtoitsuserwillbethebestthatis  obtainableonthebasisofthosedata Sec.11.2', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel(BIM) InformationRetrieval 9 ■TraditionallyusedwiththePRPAssumptions:■Binary(equivalenttoBoolean):documentsand  queriesrepresentedasbinarytermincidencevectors■E.g.,documentdrepresentedbyvector®x=(x1,...,xM),where■xt =1iftermtoccursindandxt =0otherwise■Differentdocumentsmayhavethesamevectorrepresentation■Independence:noassociationbetweenterms(not true,butworksinpractice–naïveassumption) Sec.11.3', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel InformationRetrieval 10 ■To make a probabilistic retrieval strategy precise, we needtoestimatehowtermsindocumentscontributeto relevance■Findmeasurablestatisticsthataffectjudgmentsabout  documentrelevance■UsethemtoestimatetheprobabilityofrelevanceP(R|d,q)■Orderdocumentsbydecreasingprobabilityvalues.■Assume:Relevanceofindividualdocumentsareindependent (nottrue;duplicateresultsconsideredbad) Sec.11.3', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel InformationRetrieval 11 ismodeledusingtermincidencevectorsas ■ : :and probabilitythatifarelevantor  nonrelevant document is retrieved, then that document’s representationis■Statisticsabouttheactualdocumentcollectionareusedto  estimatetheseprobabilities Sec.11.3', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel InformationRetrieval 12 ■ and :priorprobabilityofretrievingarelevantornonrelevantdocumentforaqueryq■Estimateand frompercentageofrelevantdocumentsinthecollection■Sinceadocumentiseitherrelevantornonrelevanttoaquery, wehave: Sec.11.3 Sameequationas onpreviousslide', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Givenaqueryq,rankingdocumentsby ismodeledunderBIMasrankingthemby■Easier:rankdocumentsbytheiroddsofrelevance(givessame  ranking,pluswecanignorethecommondenominator) ■ isaconstantforagivenquery–canbeignored Deriving aRankingFunction  forQueryTerms InformationRetrieval 13 Sec.11.3.1 Dropthis  term', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Itisatthispointthatwemakethe(NaïveBayes)conditional independenceassumptionthatthepresenceorabsenceofa wordinadocumentisindependentofthepresenceor  absenceofanyotherword(giventhequery): ■So: Deriving aRankingFunction  forQueryTerms InformationRetrieval 14 Sec.11.3.1 Dropped  termJustfocusonthisterm', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Sinceeachxtiseitherpresent(1)orabsent(0),wecan  separatethetermstogive: ■Let betheprobabilityofaterm  appearinginrelevantdocument■Let betheprobabilityofaterm  appearinginanonrelevantdocument■Visualisethisasacontingencytable: Deriving aRankingFunction  forQueryTerms InformationRetrieval 15 Sec.11.3.1', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Additionalsimplifyingassumption:termsnotoccurringin thequeryareequally likelytooccurinrelevantand  nonrelevantdocuments. I.e.,Ifqt=0,thenpt=ut■Nowweneedonlytoconsidertermsintheproductsthatappearinthequery: ■Theleftproductisoverquerytermsfoundinthedocumentand therightproductisoverquerytermsnotfoundinthedocument Deriving aRankingFunction  forQueryTerms !! !O(R|q,x) =O(R|q)× t×upt 1-ptt:xt=qt=1Õ 1-utt:xt=0,qt=1Õ Sec.11.3.1 InformationRetrieval 16', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Includingthequerytermsfoundinthedocumentintotheright product,butsimultaneouslydividingthroughbythemintheleft product,gives:■Theleftproductisstilloverquerytermsfoundinthedocument, buttherightproductisnowoverallqueryterms,hence  constantforaparticularqueryandcanbeignored.Theonlyquantitythatneedstobeestimatedtorankdocumentsw.r.t.aqueryistheLHSproduct.■HencetheRetrievalStatusValue(RSV)inthismodelis: Deriving aRankingFunction  forQueryTerms InformationRetrieval 17 Sec.11.3.1', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval Deriving aRankingFunction  forQueryTerms InformationRetrieval 18 ■SoitboilsdowntocomputingRSV.Wecanrankdocuments usingthelogoddsratiosforthetermsinthequeryct: ■Theoddsratioistheratiooftwoodds:(i)theoddsofthetermappearingifrelevant(pt/(1−pt)),and(ii)theoddsofthetermappearingifnonrelevant(ut/(1−ut))■ct= 0 if a termhas equal odds of appearingin relevantand nonrelevantdocuments,and ct is positiveif it is more likely to appear inrelevantdocuments.■ctfunctionsasatermweight,sothat■Operationally,wesumctquantitiesinaccumulatorsforquery termsappearingindocuments,justlikeintheVSM. Sec.11.3.1', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilityEstimatesinTheory InformationRetrieval 19 ■Foreachtermtinaquery,estimatectinthewholecollectionusing acontingencytableofcountsofdocumentsinthecollection,where dft isthenumberofdocumentsthatcontaintermt:■s = number of relevant documents where x_t= q_t= 1■S = number of total retrieved documents.  ■Toavoidzeroprobabilities(suchasifeveryornorelevant  documenthasaparticularterm),weapplysmoothing. Sec.11.3.1 +-Termpresent inrelevantdocument+-Termabsent inrelevant document', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  ProbabilityEstimatesinPractice InformationRetrieval 20 ■Assumingthatrelevantdocumentsareaverysmall  percentage of the collection, we approximate statistics for nonrelevant documents by statistics fromthewholecollection■Hence, ut (the probability of term occurrence in nonrelevantdocumentsforaquery)isdft/Nand,log[(1 −ut)/ut]=log[(N−dft)/dft]≈log N/dft ■Butnotethattheaboveapproximationcannoteasily beextendedtorelevantdocuments. Sec.11.3.3', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilityEstimatesinPractice■Statisticsofrelevantdocuments(pt)canbeestimatedin variousways:1.Usethefrequencyoftermoccurrenceinknownrelevant  documents(ifknown).2.Setasconstant.E.g.,assumethatptisconstantoverallterms xt inthequeryandthatpt =0.5■Eachtermisequallylikelytooccurinarelevantdocument,andsothe  ptand(1−pt)factorscanceloutintheexpressionforRSV■Weakestimate,butdoesn’tdisagreeviolentlywithexpectationthat  querytermsappearinmanybutnotallrelevantdocuments■Combiningthismethodwiththeearlierapproximationforut,the  documentrankingisdeterminedsimplybywhichquerytermsoccurin documentsscaledbytheiridfweighting■Forshortdocuments(titlesorabstracts)inone--passretrieval situations,thisestimatecanbequitesatisfactoryInformationRetrieval Sec.11.3.3', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  Probabilistic Relevance Feedback k k + + = || || )1( )2( V pV p ii i 1.Guess a preliminary probabilistic description of R=1documents; use it to retrieve a set of documents2.Interact with the user to refine the description: learn some definite members with R = 1 and R = 03.Re-estimate piand uion the basis ofthese• If iappears in Viwithin set of documents V: pi= |Vi|/|V|•Or can combine new information with original guess (use Bayesian prior):4.Repeat, thus generating a succession of approximations to relevant documents κis priorweight', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  Pseudo-relevance feedback(iteratively auto-estimate piandui)1.Assume that piis constant over all xiin query and uias before•pi= 0.5 (even odds) for any given doc2.Determine guess of relevant document set:•Vis fixed size set of highest ranked documents on this model3.We need to improve our guesses for piand ui, so•Use distribution of xiin docs in V. Let Vibe set of documents containing xi•pi= |Vi| / |V|•Assume if not retrieved then not relevant •ui= (dfi–|Vi|) / (N –|V|)4.Go to 2. until converges then return ranking 23', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ANAPPRAISALOF PROBABILISTICMODELS24 Sec.11.4 InformationRetrieval', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval AnAppraisalofProbabilisticModels InformationRetrieval ■AmongtheoldestformalmodelsinIR■(MaronandKuhns,1960)SinceanIR systemcannot  predictwithcertaintywhichdocumentisrelevant,we shoulddealwithprobabilities■Assumptionsforgettingreasonableapproximations  oftheneededprobabilities(intheBIM):■Booleanrepresentationofdocuments/queries/relevance■Termindependence■Out--of--querytermsdonotaffectretrieval■Documentrelevancevaluesareindependent', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval AnAppraisalofProbabilisticModels InformationRetrieval ■Thedifferencebetween‘vectorspace’and‘probabilistic’IRisnotthatgreat:■Ineithercaseyoubuildaninformationretrievalschemein  theexactsameway.■Difference:forprobabilisticIR,attheend,youscore  queriesnotbycosinesimilarityandtf.idfinavectorspace, butbyaslightlydifferentformulamotivatedbyprobability theory Sec.11.4.1', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:ANonbinaryModel InformationRetrieval ■TheBIMwasoriginallydesignedforshortcatalog recordsoffairlyconsistentlength,anditworks  reasonablyinthesecontexts■Formodernfull--textsearchcollections,amodel should pay attention to term frequency and documentlength■BestMatch25(i.e.,BM25orOkapi)issensitiveto thesequantities■From1994untiltoday,BM25isoneofthemost widelyusedandrobustretrievalmodels Sec.11.4.3', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:ANonbinaryModel InformationRetrieval ■Thesimplestscorefordocumentdisjustidfweightingofthequery termspresentinthedocument: ■Improvethisformulabyfactoringinthetermfrequencyand documentlength: ■tftd:termfrequencyindocumentd■Ld(Lave):lengthofdocumentd(averagedocumentlengthinthe wholecollection)■k1:tuningparametercontrollingthedocumenttermfrequency scaling■b:tuningparametercontrollingthescalingbydocumentlength Sec.11.4.3', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:ANonbinaryModel InformationRetrieval ■Ifthequeryislong,wemightalsousesimilarweightingforquery terms ■tftq:termfrequencyinthequeryq■k3:tuningparametercontrollingtermfrequencyscalingofthe query■Nolengthnormalizationofqueries(becauseretrievalisbeingdonewithrespecttoasinglefixedquery)■Theabovetuningparametersshouldbesetbyoptimizationona developmenttestcollection.Experimentshaveshownreasonable valuesfork1andk3asvaluesbetween1.2and2andb=0.75 Sec.11.4.3', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:Factoring in the Relevance Feedback in Equation you see in slide 19. InformationRetrieval Sec.11.4.3 Including relevance feedback in c_tor the above term will give us the equation below for BM25. s is |VR_t|S –s is |VNR_t|. |VR| = total retrieved relevant documents. |VR_t| = total retrieved relevant documents where term t appears. |VNR_t| = total retrieved relevant documents where term t does not appear. Check slide 19 and consider we got some user inputs on the relevance'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c96b2e0>, 'json_data': {'input': ['page_label: 38 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  . . . . . . . . . . . . . . 000 ... s k 3 7 7 7 7 7 5 k ⇥ k h C i k ⇥ | V | Figure 19.11 SVD factors a matrix X into a product of three matrices, W, S , and C. Taking the ﬁrst k dimensions gives a | V | ⇥ k matrix W k that has one k -dimensioned row per word that can be used as an embedding. Using only the top k dimensions (corresponding to the k most important singular values), leads to a reduced | V | ⇥ k matrix W k , with one k -dimensioned row per word. This row now acts as a dense k -dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original M . 3 3 Note that early systems often instead weighted W k by the singular values, using the product W k · S k as an embedding instead of just the matrix W k , but this weighting leads to signiﬁcantly worse embeddings (Levy et al., 2015) . embedding for  word i', 'page_label: 39 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Neural-Network Embeddings', 'page_label: 40 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Neural Networks•Neural-inspired architectures used to predict output based on inputs–Typical classification task•Apply one or more layers of non-linear transformations to input data •Deep learning', 'page_label: 41 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Applications of Neural Networks•Classification–Any classification task can be performed with an NN•Text representations–Word embeddings–Sentence embeddings•Sequence learning–Recurrent neural networks–LSTMs•Sequence generation–Sequence to sequence', 'page_label: 42 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  A Neuron•A unit of computation in the neural network•Calculates output based on given input Σi1 i2 +1 w1w2 b Outputf(wi+b)', 'page_label: 43 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Feed-forward Network Example •Assume a simple network, two inputs, two outputs, one hidden layer •Key idea: learn the weights from training data', 'page_label: 44 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Training a Network•Run all the training instances through the network and adjust the weights•Typically:–Training data to learn weights–Development (dev) data to learn hyperparameters: •Number of layers•Number of units in layer•Learning rate•Etc.–Test data to evaluate performance', 'page_label: 45 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Neural Networks for Word Embeddings•Skip-gram (Mikolov et al. 2013a)  •Continuous Bag of Words (CBOW) (Mikolov et al. 2013b)•Learn embeddings as part of the process of word prediction•Train a neural network to predict neighboring words•Inspired by neural net language models.•In so doing, learn dense embeddings for the words in the training corpus.', 'page_label: 46 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Prediction-based Neural Network Models•Create a lot of training data “for free”•Take existing contexts as examples–“Children playing outside the house.”•Use a context window of 2C words from the current word–So for C=2, we are given word wt and have a context of 4 words: 14 C HAPTER 19 • V ECTOR S EMANTICS This method is sometimes called truncated SVD . SVD is parameterized by k ,truncated SVD the number of dimensions in the representation for each word, typically ranging from 500 to 1000. Usually, these are the highest-order dimensions, although for some tasks, it seems to help to actually throw out a small number of the most high- order dimensions, such as the ﬁrst 50 (Lapesa and Evert, 2014) . The dense embeddings produced by SVD sometimes perform better than the raw PPMI matrices on semantic tasks like word similarity. Various aspects of the dimensionality reduction seem to be contributing to the increased performance. If low-order dimensions represent unimportant information, the truncated SVD may be acting to removing noise. By removing parameters, the truncation may also help the models generalize better to unseen data. When using vectors in NLP tasks, having a smaller number of dimensions may make it easier for machine learning classiﬁers to properly weight the dimensions for the task. And the models may do better at capturing higher order co-occurrence. Nonetheless, there is a signiﬁcant computational cost for the SVD for a large co- occurrence matrix, and performance is not always better than using the full sparse PPMI vectors, so for some applications the sparse vectors are the right approach. Alternatively, the neural embeddings we discuss in the next section provide a popular efﬁcient solution to generating dense embeddings. 19.4 Embeddings from prediction: Skip-gram and CBOW An alternative to applying dimensionality reduction techniques like SVD to co- occurrence matrices is to apply methods that learn embeddings for words as part of the process of word prediction. Two methods for generating dense embeddings, skip-gram and CBOW ( continuous bag of words )( Mikolov et al. 2013 , Mikolovskip-gram CBOW et al. 2013a ), draw inspiration from the neural methods for language modeling intro- duced in Chapter 5. Like the neural language models, these models train a network to predict neighboring words, and while doing so learn dense embeddings for the words in the training corpus. The advantage of these methods is that they are fast, efﬁcient to train, and easily available online in the word2vec package; code and pretrained embeddings are both available. We’ll begin with the skip-gram model. The skip-gram model predicts each neighboring word in a context window of 2 C words from the current word. So for a context window C = 2 the context is [ w t \\x00 2 , w t \\x00 1 , w t + 1 , w t + 2 ] and we are pre- dicting each of these from word w t . Fig. 17.12 sketches the architecture for a sample context C = 1. The skip-gram model actually learns two d -dimensional embeddings for each word w : the input embedding v and the output embedding v 0 . These embeddings input embedding output embedding are encoded in two matrices, the input matrix W and the output matrix W 0 . Each column i of the input matrix W is the 1 ⇥ d vector embedding v i for word i in the vocabulary. Each row i of the output matrix W 0 is a d ⇥ 1 vector embedding v 0 i for word i in the vocabulary Let’s consider the prediction task. We are walking through a corpus of length T and currently pointing at the t th word w ( t ) , whose index in the vocabulary is j , so we’ll call it w j (1 < j < | V | ). Let’s consider predicting one of the 2 C context words, for example w ( t + 1 ) , whose index in the vocabulary is k (1 < k < | V | ). Hence our task is to compute P ( w k | w j ) .', 'page_label: 47 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Learning Word Embeddings•Create a lot of training data “for free”•“Children playing outside the house.”•Two main “flavors” of word embeddings:•CBOW (continuous bag of words): predict the underlined word given its context•Skip-grams: predict the context given the underlined word', 'page_label: 48 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Skip-grams Input layer Projection layer Output layer W |V|⨉d wt wt-1 wt+1 1-hot input vector 1⨉d1⨉|V| embedding for wt probabilities of context words W’ d ⨉ |V| W’ d ⨉ |V| x1 x2 xj x|V| y1 y2 yk y|V| y1 y2 yk y|V|', 'page_label: 49 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Skip-grams: Training the Network•Use existing contexts as positive examples•Use random contexts as negative examples Children playing outside the housewt=outsidecontextpositive example [children, playing, the, house]negative examples [water, before, fast, no]            [today, increment, on, tube] 14 C HAPTER 19 • V ECTOR S EMANTICS This method is sometimes called truncated SVD . SVD is parameterized by k ,truncated SVD the number of dimensions in the representation for each word, typically ranging from 500 to 1000. Usually, these are the highest-order dimensions, although for some tasks, it seems to help to actually throw out a small number of the most high- order dimensions, such as the ﬁrst 50 (Lapesa and Evert, 2014) . The dense embeddings produced by SVD sometimes perform better than the raw PPMI matrices on semantic tasks like word similarity. Various aspects of the dimensionality reduction seem to be contributing to the increased performance. If low-order dimensions represent unimportant information, the truncated SVD may be acting to removing noise. By removing parameters, the truncation may also help the models generalize better to unseen data. When using vectors in NLP tasks, having a smaller number of dimensions may make it easier for machine learning classiﬁers to properly weight the dimensions for the task. And the models may do better at capturing higher order co-occurrence. Nonetheless, there is a signiﬁcant computational cost for the SVD for a large co- occurrence matrix, and performance is not always better than using the full sparse PPMI vectors, so for some applications the sparse vectors are the right approach. Alternatively, the neural embeddings we discuss in the next section provide a popular efﬁcient solution to generating dense embeddings. 19.4 Embeddings from prediction: Skip-gram and CBOW An alternative to applying dimensionality reduction techniques like SVD to co- occurrence matrices is to apply methods that learn embeddings for words as part of the process of word prediction. Two methods for generating dense embeddings, skip-gram and CBOW ( continuous bag of words )( Mikolov et al. 2013 , Mikolovskip-gram CBOW et al. 2013a ), draw inspiration from the neural methods for language modeling intro- duced in Chapter 5. Like the neural language models, these models train a network to predict neighboring words, and while doing so learn dense embeddings for the words in the training corpus. The advantage of these methods is that they are fast, efﬁcient to train, and easily available online in the word2vec package; code and pretrained embeddings are both available. We’ll begin with the skip-gram model. The skip-gram model predicts each neighboring word in a context window of 2 C words from the current word. So for a context window C = 2 the context is [ w t \\x00 2 , w t \\x00 1 , w t + 1 , w t + 2 ] and we are pre- dicting each of these from word w t . Fig. 17.12 sketches the architecture for a sample context C = 1. The skip-gram model actually learns two d -dimensional embeddings for each word w : the input embedding v and the output embedding v 0 . These embeddings input embedding output embedding are encoded in two matrices, the input matrix W and the output matrix W 0 . Each column i of the input matrix W is the 1 ⇥ d vector embedding v i for word i in the vocabulary. Each row i of the output matrix W 0 is a d ⇥ 1 vector embedding v 0 i for word i in the vocabulary Let’s consider the prediction task. We are walking through a corpus of length T and currently pointing at the t th word w ( t ) , whose index in the vocabulary is j , so we’ll call it w j (1 < j < | V | ). Let’s consider predicting one of the 2 C context words, for example w ( t + 1 ) , whose index in the vocabulary is k (1 < k < | V | ). Hence our task is to compute P ( w k | w j ) .', 'page_label: 50 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  One-hot Vectors•As input, represent a word as a one-hot vector•A vector of length V (vocabulary), with just one component flipped to indicate the word•E.g., if “outside” is the 3rd word in the vocabulary, the one-hot vector will be  [0, 0, 1, 0, 0, …. 0]', 'page_label: 51 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Forward/backward propagation•Initialize all weights with random values•Run forward propagation •Loss function:–Measure similarity of word with context\\t𝜎𝑤$%#𝑤$+𝜎𝑤$%\"𝑤$+𝜎𝑤$&\"𝑤$+ 𝜎𝑤$&#𝑤$–Minimize distance between  wt and context in positive example–Maximize distance between wt and context in negative examples', 'page_label: 52 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Skip-grams Input layer Projection layer Output layer W |V|⨉d wt wt-1 wt+1 1-hot input vector 1⨉d1⨉|V| embedding for wt probabilities of context words W’ d ⨉ |V| W’ d ⨉ |V| x1 x2 xj x|V| y1 y2 yk y|V| y1 y2 yk y|V|', 'page_label: 53 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  CBOWInput layer Projection layer Output layer W|V|⨉d wt wt-1 wt+1 1-hot input vectors for each context word 1⨉d 1⨉|V| sum of embeddings  for context words probability of wt W’ d ⨉ |V| x1 x2 xj x|V| y1 y2 yk y|V| x1 x2 xj x|V| W|V|⨉d', 'page_label: 54 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Result•A “dense” vector learned after training the network, or length d•d varies: 50-300 –Larger d means more weights to learn•Learning word embeddings requires very large data–Mainly because we have to learn a large set of parameters (weights and embeddings)•Word embeddings capture word meaning–vector(‘king’) - vector(‘man’) + vector(‘woman’)  ≈\\tvector(‘queen’)–vector(‘Paris’) - vector(‘France’) + vector(‘Italy’) ≈ vector(‘Rome’)', 'page_label: 55 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf  Word Embeddings in Practice•word2vec •https://code.google.com/p/word2vec/ includes the models and pre-trained embeddings–Trained on large news data•Gensim: Python library that works with word2vec–https://radimrehurek.com/gensim/', 'page_label: 1 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  Introduction to Information Retrieval CS3245 Information Retrieval Lecture 4: Probabilistic IR', 'page_label: 2 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilisticIRModelsataGlance InformationRetrieval 2 1.Classicalprobabilistic retrievalmodel■Probabilityrankingprinciple■BinaryIndependenceModel,BestMatch25(Okapi)2.Languagemodelapproachto IR■Importantrecentwork,competitiveperformanceProbabilisticmethodsareoneoftheoldestbutalsooneof  thecurrentlyhottesttopicsinIR Ch.11', 'page_label: 3 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  ProbabilisticApproachtoRetrieval InformationRetrieval 3 ■Givenauserinformationneed(representedasaquery) and a collection of documents (transformed into documentrepresentations),asystemmustdetermine  howwellthedocumentssatisfythequery■BooleanorvectorspacemodelsofIR:query--document matching done in a formally defined but semantically imprecisecalculusof indexterms■An IR systemhas an uncertainunderstandingof the user query,and makesanuncertainguessofwhetheradocumentsatisfiesthequery■Probabilitytheoryprovidesaprincipledfoundationfor suchreasoningunderuncertainty■Probabilisticmodelsexploitthisfoundationtoestimatehowlikelyitis thatadocumentisrelevanttoaquery Ch.11', 'page_label: 4 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  BasicProbabilityTheory InformationRetrieval 4 ■ForeventsAandB■JointprobabilityP(A,B)ofbotheventsoccurring.■ConditionalprobabilityP(A|B)ofeventA occurringgiventhateventBhas occurred.■Chainrulegivesfundamentalrelationshipbetweenjointandconditional probabilities: ■Similarlyforthecomplementofanevent:■Partitionrule:if B can be divided into an exhaustivesetof disjoint subcases,thenP(B)isthesumoftheprobabilitiesofthesubcases.■Thebinaryformofthisrulegives: Sec.11.1', 'page_label: 5 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BasicProbabilityTheory InformationRetrieval 5 ■Bayes’Ruleforinvertingconditionalprobabilities: ■Canbethoughtof asawayofupdatingprobabilities:■StartoffwithpriorprobabilityP(A)(initialestimateofhow  likelyeventAisintheabsenceofanyotherinformation)■Derive a posterior probability P(A|B) after having seen the evidenceB,basedonthelikelihoodofBoccurringinthetwo  casesthatAdoesordoesnothold■Oddsofaneventprovideamultiplierforhow  probabilitieschange: Sec.11.1', 'page_label: 6 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  THEPROBABILITY RANKINGPRINCIPLE Sec.11.2 InformationRetrieval 6', 'page_label: 7 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval TheDocumentRankingProblem InformationRetrieval 7 ■Rankedretrievalsetup:givenacollectionof  documents,theuserissuesaquery, andanordered listofdocumentsisreturned,■Assume binary notion of relevance: Rd,q is a random binaryvariable,suchthat:■Rd,q=1ifdocumentdisrelevanttoqueryq■Rd,q=0otherwise■Probabilisticrankingordersdocumentsdecreasingly bytheirestimatedprobabilityofrelevancetothe  query:P(R=1|d,q) Sec.11.2', 'page_label: 8 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilityRankingPrinciple(PRP) InformationRetrieval 8 ■PRPinbrief■Iftheretrieveddocuments(w.r.t.aquery)areranked  decreasingly on their probability of relevance, then the effectivenessofthesystemwillbethebestthatisobtainable■PRPinfull■If [the IR] system’s response to each [query] is a ranking of the documents[...]inorderofdecreasingprobabilityofrelevanceto the [query], where the probabilities are estimated as accuratelyaspossibleonthebasisofwhateverdatahavebeen madeavailabletothesystemforthispurpose,theoverall  effectivenessofthesystemtoitsuserwillbethebestthatis  obtainableonthebasisofthosedata Sec.11.2', 'page_label: 9 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel(BIM) InformationRetrieval 9 ■TraditionallyusedwiththePRPAssumptions:■Binary(equivalenttoBoolean):documentsand  queriesrepresentedasbinarytermincidencevectors■E.g.,documentdrepresentedbyvector®x=(x1,...,xM),where■xt =1iftermtoccursindandxt =0otherwise■Differentdocumentsmayhavethesamevectorrepresentation■Independence:noassociationbetweenterms(not true,butworksinpractice–naïveassumption) Sec.11.3', 'page_label: 10 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel InformationRetrieval 10 ■To make a probabilistic retrieval strategy precise, we needtoestimatehowtermsindocumentscontributeto relevance■Findmeasurablestatisticsthataffectjudgmentsabout  documentrelevance■UsethemtoestimatetheprobabilityofrelevanceP(R|d,q)■Orderdocumentsbydecreasingprobabilityvalues.■Assume:Relevanceofindividualdocumentsareindependent (nottrue;duplicateresultsconsideredbad) Sec.11.3', 'page_label: 11 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel InformationRetrieval 11 ismodeledusingtermincidencevectorsas ■ : :and probabilitythatifarelevantor  nonrelevant document is retrieved, then that document’s representationis■Statisticsabouttheactualdocumentcollectionareusedto  estimatetheseprobabilities Sec.11.3', 'page_label: 12 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval BinaryIndependenceModel InformationRetrieval 12 ■ and :priorprobabilityofretrievingarelevantornonrelevantdocumentforaqueryq■Estimateand frompercentageofrelevantdocumentsinthecollection■Sinceadocumentiseitherrelevantornonrelevanttoaquery, wehave: Sec.11.3 Sameequationas onpreviousslide', 'page_label: 13 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Givenaqueryq,rankingdocumentsby ismodeledunderBIMasrankingthemby■Easier:rankdocumentsbytheiroddsofrelevance(givessame  ranking,pluswecanignorethecommondenominator) ■ isaconstantforagivenquery–canbeignored Deriving aRankingFunction  forQueryTerms InformationRetrieval 13 Sec.11.3.1 Dropthis  term', 'page_label: 14 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Itisatthispointthatwemakethe(NaïveBayes)conditional independenceassumptionthatthepresenceorabsenceofa wordinadocumentisindependentofthepresenceor  absenceofanyotherword(giventhequery): ■So: Deriving aRankingFunction  forQueryTerms InformationRetrieval 14 Sec.11.3.1 Dropped  termJustfocusonthisterm', 'page_label: 15 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Sinceeachxtiseitherpresent(1)orabsent(0),wecan  separatethetermstogive: ■Let betheprobabilityofaterm  appearinginrelevantdocument■Let betheprobabilityofaterm  appearinginanonrelevantdocument■Visualisethisasacontingencytable: Deriving aRankingFunction  forQueryTerms InformationRetrieval 15 Sec.11.3.1', 'page_label: 16 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Additionalsimplifyingassumption:termsnotoccurringin thequeryareequally likelytooccurinrelevantand  nonrelevantdocuments. I.e.,Ifqt=0,thenpt=ut■Nowweneedonlytoconsidertermsintheproductsthatappearinthequery: ■Theleftproductisoverquerytermsfoundinthedocumentand therightproductisoverquerytermsnotfoundinthedocument Deriving aRankingFunction  forQueryTerms !! !O(R|q,x) =O(R|q)× t×upt 1-ptt:xt=qt=1Õ 1-utt:xt=0,qt=1Õ Sec.11.3.1 InformationRetrieval 16', 'page_label: 17 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ■Includingthequerytermsfoundinthedocumentintotheright product,butsimultaneouslydividingthroughbythemintheleft product,gives:■Theleftproductisstilloverquerytermsfoundinthedocument, buttherightproductisnowoverallqueryterms,hence  constantforaparticularqueryandcanbeignored.Theonlyquantitythatneedstobeestimatedtorankdocumentsw.r.t.aqueryistheLHSproduct.■HencetheRetrievalStatusValue(RSV)inthismodelis: Deriving aRankingFunction  forQueryTerms InformationRetrieval 17 Sec.11.3.1', 'page_label: 18 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval Deriving aRankingFunction  forQueryTerms InformationRetrieval 18 ■SoitboilsdowntocomputingRSV.Wecanrankdocuments usingthelogoddsratiosforthetermsinthequeryct: ■Theoddsratioistheratiooftwoodds:(i)theoddsofthetermappearingifrelevant(pt/(1−pt)),and(ii)theoddsofthetermappearingifnonrelevant(ut/(1−ut))■ct= 0 if a termhas equal odds of appearingin relevantand nonrelevantdocuments,and ct is positiveif it is more likely to appear inrelevantdocuments.■ctfunctionsasatermweight,sothat■Operationally,wesumctquantitiesinaccumulatorsforquery termsappearingindocuments,justlikeintheVSM. Sec.11.3.1', 'page_label: 19 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilityEstimatesinTheory InformationRetrieval 19 ■Foreachtermtinaquery,estimatectinthewholecollectionusing acontingencytableofcountsofdocumentsinthecollection,where dft isthenumberofdocumentsthatcontaintermt:■s = number of relevant documents where x_t= q_t= 1■S = number of total retrieved documents.  ■Toavoidzeroprobabilities(suchasifeveryornorelevant  documenthasaparticularterm),weapplysmoothing. Sec.11.3.1 +-Termpresent inrelevantdocument+-Termabsent inrelevant document', 'page_label: 20 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  ProbabilityEstimatesinPractice InformationRetrieval 20 ■Assumingthatrelevantdocumentsareaverysmall  percentage of the collection, we approximate statistics for nonrelevant documents by statistics fromthewholecollection■Hence, ut (the probability of term occurrence in nonrelevantdocumentsforaquery)isdft/Nand,log[(1 −ut)/ut]=log[(N−dft)/dft]≈log N/dft ■Butnotethattheaboveapproximationcannoteasily beextendedtorelevantdocuments. Sec.11.3.3', 'page_label: 21 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ProbabilityEstimatesinPractice■Statisticsofrelevantdocuments(pt)canbeestimatedin variousways:1.Usethefrequencyoftermoccurrenceinknownrelevant  documents(ifknown).2.Setasconstant.E.g.,assumethatptisconstantoverallterms xt inthequeryandthatpt =0.5■Eachtermisequallylikelytooccurinarelevantdocument,andsothe  ptand(1−pt)factorscanceloutintheexpressionforRSV■Weakestimate,butdoesn’tdisagreeviolentlywithexpectationthat  querytermsappearinmanybutnotallrelevantdocuments■Combiningthismethodwiththeearlierapproximationforut,the  documentrankingisdeterminedsimplybywhichquerytermsoccurin documentsscaledbytheiridfweighting■Forshortdocuments(titlesorabstracts)inone--passretrieval situations,thisestimatecanbequitesatisfactoryInformationRetrieval Sec.11.3.3', 'page_label: 22 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  Probabilistic Relevance Feedback k k + + = || || )1( )2( V pV p ii i 1.Guess a preliminary probabilistic description of R=1documents; use it to retrieve a set of documents2.Interact with the user to refine the description: learn some definite members with R = 1 and R = 03.Re-estimate piand uion the basis ofthese• If iappears in Viwithin set of documents V: pi= |Vi|/|V|•Or can combine new information with original guess (use Bayesian prior):4.Repeat, thus generating a succession of approximations to relevant documents κis priorweight', 'page_label: 23 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  Pseudo-relevance feedback(iteratively auto-estimate piandui)1.Assume that piis constant over all xiin query and uias before•pi= 0.5 (even odds) for any given doc2.Determine guess of relevant document set:•Vis fixed size set of highest ranked documents on this model3.We need to improve our guesses for piand ui, so•Use distribution of xiin docs in V. Let Vibe set of documents containing xi•pi= |Vi| / |V|•Assume if not retrieved then not relevant •ui= (dfi–|Vi|) / (N –|V|)4.Go to 2. until converges then return ranking 23', 'page_label: 24 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval ANAPPRAISALOF PROBABILISTICMODELS24 Sec.11.4 InformationRetrieval', 'page_label: 25 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval AnAppraisalofProbabilisticModels InformationRetrieval ■AmongtheoldestformalmodelsinIR■(MaronandKuhns,1960)SinceanIR systemcannot  predictwithcertaintywhichdocumentisrelevant,we shoulddealwithprobabilities■Assumptionsforgettingreasonableapproximations  oftheneededprobabilities(intheBIM):■Booleanrepresentationofdocuments/queries/relevance■Termindependence■Out--of--querytermsdonotaffectretrieval■Documentrelevancevaluesareindependent', 'page_label: 26 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval AnAppraisalofProbabilisticModels InformationRetrieval ■Thedifferencebetween‘vectorspace’and‘probabilistic’IRisnotthatgreat:■Ineithercaseyoubuildaninformationretrievalschemein  theexactsameway.■Difference:forprobabilisticIR,attheend,youscore  queriesnotbycosinesimilarityandtf.idfinavectorspace, butbyaslightlydifferentformulamotivatedbyprobability theory Sec.11.4.1', 'page_label: 27 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:ANonbinaryModel InformationRetrieval ■TheBIMwasoriginallydesignedforshortcatalog recordsoffairlyconsistentlength,anditworks  reasonablyinthesecontexts■Formodernfull--textsearchcollections,amodel should pay attention to term frequency and documentlength■BestMatch25(i.e.,BM25orOkapi)issensitiveto thesequantities■From1994untiltoday,BM25isoneofthemost widelyusedandrobustretrievalmodels Sec.11.4.3', 'page_label: 28 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:ANonbinaryModel InformationRetrieval ■Thesimplestscorefordocumentdisjustidfweightingofthequery termspresentinthedocument: ■Improvethisformulabyfactoringinthetermfrequencyand documentlength: ■tftd:termfrequencyindocumentd■Ld(Lave):lengthofdocumentd(averagedocumentlengthinthe wholecollection)■k1:tuningparametercontrollingthedocumenttermfrequency scaling■b:tuningparametercontrollingthescalingbydocumentlength Sec.11.4.3', 'page_label: 29 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:ANonbinaryModel InformationRetrieval ■Ifthequeryislong,wemightalsousesimilarweightingforquery terms ■tftq:termfrequencyinthequeryq■k3:tuningparametercontrollingtermfrequencyscalingofthe query■Nolengthnormalizationofqueries(becauseretrievalisbeingdonewithrespecttoasinglefixedquery)■Theabovetuningparametersshouldbesetbyoptimizationona developmenttestcollection.Experimentshaveshownreasonable valuesfork1andk3asvaluesbetween1.2and2andb=0.75 Sec.11.4.3', 'page_label: 30 file_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf  CS3245–InformationRetrieval OkapiBM25:Factoring in the Relevance Feedback in Equation you see in slide 19. InformationRetrieval Sec.11.4.3 Including relevance feedback in c_tor the above term will give us the equation below for BM25. s is |VR_t|S –s is |VNR_t|. |VR| = total retrieved relevant documents. |VR_t| = total retrieved relevant documents where term t appears. |VNR_t| = total retrieved relevant documents where term t does not appear. Check slide 19 and consider we got some user inputs on the relevance'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'589'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992456'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'452ms'), (b'x-request-id', b'req_0afc6dc45427047a48bc43dd08b69ed3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c421f2c2ea083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'589'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992456'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'452ms'), (b'x-request-id', b'req_0afc6dc45427047a48bc43dd08b69ed3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c421f2c2ea083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:10:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'589'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992456'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'452ms'), (b'x-request-id', b'req_0afc6dc45427047a48bc43dd08b69ed3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c421f2c2ea083-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '589', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '992456', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '452ms', 'x-request-id': 'req_0afc6dc45427047a48bc43dd08b69ed3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c421f2c2ea083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '589', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '992456', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '452ms', 'x-request-id': 'req_0afc6dc45427047a48bc43dd08b69ed3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c421f2c2ea083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:10:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-ada-002', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '589', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '992456', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '452ms', 'x-request-id': 'req_0afc6dc45427047a48bc43dd08b69ed3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c421f2c2ea083-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_0afc6dc45427047a48bc43dd08b69ed3\n",
      "request_id: req_0afc6dc45427047a48bc43dd08b69ed3\n",
      "request_id: req_0afc6dc45427047a48bc43dd08b69ed3\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/docstore.json\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/docstore.json\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/docstore.json\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/index_store.json\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/index_store.json\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/index_store.json\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/graph_store.json\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/graph_store.json\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/graph_store.json\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/default__vector_store.json\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/default__vector_store.json\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/default__vector_store.json\n",
      "DEBUG:fsspec.local:open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/image__vector_store.json\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/image__vector_store.json\n",
      "open file: /Users/zhengwei/Documents/codeL/llamaindex/storage/image__vector_store.json\n"
     ]
    }
   ],
   "source": [
    "# check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c8e7420>, 'json_data': {'input': ['What did the author do growing up?'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c8e7420>, 'json_data': {'input': ['What did the author do growing up?'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c8e7420>, 'json_data': {'input': ['What did the author do growing up?'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      "close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c5db2d0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c5db2d0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c5db2d0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x149790a70> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x149790a70> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x149790a70> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1497e3590>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1497e3590>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1497e3590>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:12:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'335'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999992'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_ed14fc2d5ebeb150311fb040ef199c55'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=AxKHQ.MBvyqZSE7RgEqkZ_1ojTJpYHJz9c4z1U0dmNA-1731474726-1.0.1.1-Jc7BbaLV_UaqU.vuecDmyywnlEXdHrqmcKAQSTQsUmR8mOEcwPx5aMI6LeOQSN6AR6.u5demZRnHbFmY.fO61A; path=/; expires=Wed, 13-Nov-24 05:42:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=oGdp3blNJVjlyeZrBAskJ8G6UfVa.7I_veCgUUTPfek-1731474726562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c43bb49444b68-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:12:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'335'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999992'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_ed14fc2d5ebeb150311fb040ef199c55'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=AxKHQ.MBvyqZSE7RgEqkZ_1ojTJpYHJz9c4z1U0dmNA-1731474726-1.0.1.1-Jc7BbaLV_UaqU.vuecDmyywnlEXdHrqmcKAQSTQsUmR8mOEcwPx5aMI6LeOQSN6AR6.u5demZRnHbFmY.fO61A; path=/; expires=Wed, 13-Nov-24 05:42:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=oGdp3blNJVjlyeZrBAskJ8G6UfVa.7I_veCgUUTPfek-1731474726562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c43bb49444b68-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:12:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'335'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999992'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_ed14fc2d5ebeb150311fb040ef199c55'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=AxKHQ.MBvyqZSE7RgEqkZ_1ojTJpYHJz9c4z1U0dmNA-1731474726-1.0.1.1-Jc7BbaLV_UaqU.vuecDmyywnlEXdHrqmcKAQSTQsUmR8mOEcwPx5aMI6LeOQSN6AR6.u5demZRnHbFmY.fO61A; path=/; expires=Wed, 13-Nov-24 05:42:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=oGdp3blNJVjlyeZrBAskJ8G6UfVa.7I_veCgUUTPfek-1731474726562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c43bb49444b68-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Wed, 13 Nov 2024 05:12:06 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-ada-002'), ('openai-organization', 'user-1d0msvoq8nnxhbarposyss9g'), ('openai-processing-ms', '335'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999992'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_ed14fc2d5ebeb150311fb040ef199c55'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=AxKHQ.MBvyqZSE7RgEqkZ_1ojTJpYHJz9c4z1U0dmNA-1731474726-1.0.1.1-Jc7BbaLV_UaqU.vuecDmyywnlEXdHrqmcKAQSTQsUmR8mOEcwPx5aMI6LeOQSN6AR6.u5demZRnHbFmY.fO61A; path=/; expires=Wed, 13-Nov-24 05:42:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=oGdp3blNJVjlyeZrBAskJ8G6UfVa.7I_veCgUUTPfek-1731474726562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e1c43bb49444b68-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Wed, 13 Nov 2024 05:12:06 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-ada-002'), ('openai-organization', 'user-1d0msvoq8nnxhbarposyss9g'), ('openai-processing-ms', '335'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999992'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_ed14fc2d5ebeb150311fb040ef199c55'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=AxKHQ.MBvyqZSE7RgEqkZ_1ojTJpYHJz9c4z1U0dmNA-1731474726-1.0.1.1-Jc7BbaLV_UaqU.vuecDmyywnlEXdHrqmcKAQSTQsUmR8mOEcwPx5aMI6LeOQSN6AR6.u5demZRnHbFmY.fO61A; path=/; expires=Wed, 13-Nov-24 05:42:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=oGdp3blNJVjlyeZrBAskJ8G6UfVa.7I_veCgUUTPfek-1731474726562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e1c43bb49444b68-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Wed, 13 Nov 2024 05:12:06 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-ada-002'), ('openai-organization', 'user-1d0msvoq8nnxhbarposyss9g'), ('openai-processing-ms', '335'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999992'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_ed14fc2d5ebeb150311fb040ef199c55'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=AxKHQ.MBvyqZSE7RgEqkZ_1ojTJpYHJz9c4z1U0dmNA-1731474726-1.0.1.1-Jc7BbaLV_UaqU.vuecDmyywnlEXdHrqmcKAQSTQsUmR8mOEcwPx5aMI6LeOQSN6AR6.u5demZRnHbFmY.fO61A; path=/; expires=Wed, 13-Nov-24 05:42:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=oGdp3blNJVjlyeZrBAskJ8G6UfVa.7I_veCgUUTPfek-1731474726562-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e1c43bb49444b68-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_ed14fc2d5ebeb150311fb040ef199c55\n",
      "request_id: req_ed14fc2d5ebeb150311fb040ef199c55\n",
      "request_id: req_ed14fc2d5ebeb150311fb040ef199c55\n",
      "DEBUG:llama_index.core.indices.utils:> Top 2 nodes:\n",
      "> [Node 26ff32df-e084-4053-87b9-b2b563d531f6] [Similarity score:             0.757859] Words of Wisdom!•I have just crossed my 30 \n",
      "😁 – stop calling me Prof. Call me SJ. How cool it is ...\n",
      "> [Node a03061b2-7587-4a5c-b763-c4f1439120d3] [Similarity score:             0.741039] Learning Word Embeddings•Create a lot of training data “for free”•“Children playing outside the h...\n",
      "> Top 2 nodes:\n",
      "> [Node 26ff32df-e084-4053-87b9-b2b563d531f6] [Similarity score:             0.757859] Words of Wisdom!•I have just crossed my 30 \n",
      "😁 – stop calling me Prof. Call me SJ. How cool it is ...\n",
      "> [Node a03061b2-7587-4a5c-b763-c4f1439120d3] [Similarity score:             0.741039] Learning Word Embeddings•Create a lot of training data “for free”•“Children playing outside the h...\n",
      "> Top 2 nodes:\n",
      "> [Node 26ff32df-e084-4053-87b9-b2b563d531f6] [Similarity score:             0.757859] Words of Wisdom!•I have just crossed my 30 \n",
      "😁 – stop calling me Prof. Call me SJ. How cool it is ...\n",
      "> [Node a03061b2-7587-4a5c-b763-c4f1439120d3] [Similarity score:             0.741039] Learning Word Embeddings•Create a lot of training data “for free”•“Children playing outside the h...\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}, {'role': 'user', 'content': 'Context information is below.\\n---------------------\\npage_label: 4\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf\\n\\nWords of Wisdom!•I have just crossed my 30 \\n😁 – stop calling me Prof. Call me SJ. How cool it is \\n😁•My handwriting is horrible \\n🥲–Tell me when you do not understand what I wrote on the whiteboard.•Getting good marks is super easy!–Focus on learning and applying new things.•Ask me 100 of questions!\\n\\npage_label: 47\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf\\n\\nLearning Word Embeddings•Create a lot of training data “for free”•“Children playing outside the house.”•Two main “flavors” of word embeddings:•CBOW (continuous bag of words): predict the underlined word given its context•Skip-grams: predict the context given the underlined word\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What did the author do growing up?\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}, {'role': 'user', 'content': 'Context information is below.\\n---------------------\\npage_label: 4\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf\\n\\nWords of Wisdom!•I have just crossed my 30 \\n😁 – stop calling me Prof. Call me SJ. How cool it is \\n😁•My handwriting is horrible \\n🥲–Tell me when you do not understand what I wrote on the whiteboard.•Getting good marks is super easy!–Focus on learning and applying new things.•Ask me 100 of questions!\\n\\npage_label: 47\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf\\n\\nLearning Word Embeddings•Create a lot of training data “for free”•“Children playing outside the house.”•Two main “flavors” of word embeddings:•CBOW (continuous bag of words): predict the underlined word given its context•Skip-grams: predict the context given the underlined word\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What did the author do growing up?\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}, {'role': 'user', 'content': 'Context information is below.\\n---------------------\\npage_label: 4\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 BooleanRetrieval.pdf\\n\\nWords of Wisdom!•I have just crossed my 30 \\n😁 – stop calling me Prof. Call me SJ. How cool it is \\n😁•My handwriting is horrible \\n🥲–Tell me when you do not understand what I wrote on the whiteboard.•Getting good marks is super easy!–Focus on learning and applying new things.•Ask me 100 of questions!\\n\\npage_label: 47\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 2WordRepresentations.pdf\\n\\nLearning Word Embeddings•Create a lot of training data “for free”•“Children playing outside the house.”•Two main “flavors” of word embeddings:•CBOW (continuous bag of words): predict the underlined word given its context•Skip-grams: predict the context given the underlined word\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What did the author do growing up?\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      "close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14cad6990>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14cad6990>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14cad6990>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x149791ac0> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x149791ac0> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x149791ac0> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14b7baf50>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14b7baf50>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14b7baf50>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:12:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'411'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199637'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'108ms'), (b'x-request-id', b'req_bf4dd7a057837e25eaf524e7e211ac7a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=VzWm48qYyoZm1LCejljs8__C0aQZdmmBEeaTISCSdOY-1731474727-1.0.1.1-.4CxJte7gPsM8iD9ZfZcRow4pIlAtWTEt5fU8WIqu88HlhR1ibSD.4P2I1rl8OLOPAQ_O4ZdPb9yEgkb7hbEQw; path=/; expires=Wed, 13-Nov-24 05:42:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c43d1edf73e4f-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:12:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'411'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199637'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'108ms'), (b'x-request-id', b'req_bf4dd7a057837e25eaf524e7e211ac7a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=VzWm48qYyoZm1LCejljs8__C0aQZdmmBEeaTISCSdOY-1731474727-1.0.1.1-.4CxJte7gPsM8iD9ZfZcRow4pIlAtWTEt5fU8WIqu88HlhR1ibSD.4P2I1rl8OLOPAQ_O4ZdPb9yEgkb7hbEQw; path=/; expires=Wed, 13-Nov-24 05:42:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c43d1edf73e4f-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:12:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'411'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199637'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'108ms'), (b'x-request-id', b'req_bf4dd7a057837e25eaf524e7e211ac7a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=VzWm48qYyoZm1LCejljs8__C0aQZdmmBEeaTISCSdOY-1731474727-1.0.1.1-.4CxJte7gPsM8iD9ZfZcRow4pIlAtWTEt5fU8WIqu88HlhR1ibSD.4P2I1rl8OLOPAQ_O4ZdPb9yEgkb7hbEQw; path=/; expires=Wed, 13-Nov-24 05:42:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c43d1edf73e4f-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:12:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '411', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199637', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '108ms', 'x-request-id': 'req_bf4dd7a057837e25eaf524e7e211ac7a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=VzWm48qYyoZm1LCejljs8__C0aQZdmmBEeaTISCSdOY-1731474727-1.0.1.1-.4CxJte7gPsM8iD9ZfZcRow4pIlAtWTEt5fU8WIqu88HlhR1ibSD.4P2I1rl8OLOPAQ_O4ZdPb9yEgkb7hbEQw; path=/; expires=Wed, 13-Nov-24 05:42:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c43d1edf73e4f-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:12:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '411', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199637', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '108ms', 'x-request-id': 'req_bf4dd7a057837e25eaf524e7e211ac7a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=VzWm48qYyoZm1LCejljs8__C0aQZdmmBEeaTISCSdOY-1731474727-1.0.1.1-.4CxJte7gPsM8iD9ZfZcRow4pIlAtWTEt5fU8WIqu88HlhR1ibSD.4P2I1rl8OLOPAQ_O4ZdPb9yEgkb7hbEQw; path=/; expires=Wed, 13-Nov-24 05:42:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c43d1edf73e4f-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:12:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '411', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199637', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '108ms', 'x-request-id': 'req_bf4dd7a057837e25eaf524e7e211ac7a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=VzWm48qYyoZm1LCejljs8__C0aQZdmmBEeaTISCSdOY-1731474727-1.0.1.1-.4CxJte7gPsM8iD9ZfZcRow4pIlAtWTEt5fU8WIqu88HlhR1ibSD.4P2I1rl8OLOPAQ_O4ZdPb9yEgkb7hbEQw; path=/; expires=Wed, 13-Nov-24 05:42:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c43d1edf73e4f-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_bf4dd7a057837e25eaf524e7e211ac7a\n",
      "request_id: req_bf4dd7a057837e25eaf524e7e211ac7a\n",
      "request_id: req_bf4dd7a057837e25eaf524e7e211ac7a\n",
      "The author mentioned that they used to play outside the house when they were younger.\n"
     ]
    }
   ],
   "source": [
    "# Either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c8e7740>, 'json_data': {'input': ['What is a vector space model?'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c8e7740>, 'json_data': {'input': ['What is a vector space model?'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14c8e7740>, 'json_data': {'input': ['What is a vector space model?'], 'model': 'text-embedding-ada-002', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      "close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c88e090>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c88e090>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c88e090>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x149790a70> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x149790a70> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x149790a70> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14cada4d0>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14cada4d0>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14cada4d0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:14:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999993'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_878334cf0656617b9784da2a647be8f8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=D635xGLQfeOnjFBBlnE1OBS_JLJp_C_hWnC1SntsoVA-1731474845-1.0.1.1-WZNs_i0U4GThPT8JwAYgzme.wWrlco.ocN6NXLRG09VsldgKo56toCl38WLl0nlmTQcaPAoEIzaBRLuUgrT1DQ; path=/; expires=Wed, 13-Nov-24 05:44:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=WQ4vxzfqc94W95Cu6hblW5cndMng6yMrqe24KGOyDZs-1731474845173-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c46b43ad78856-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:14:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999993'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_878334cf0656617b9784da2a647be8f8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=D635xGLQfeOnjFBBlnE1OBS_JLJp_C_hWnC1SntsoVA-1731474845-1.0.1.1-WZNs_i0U4GThPT8JwAYgzme.wWrlco.ocN6NXLRG09VsldgKo56toCl38WLl0nlmTQcaPAoEIzaBRLuUgrT1DQ; path=/; expires=Wed, 13-Nov-24 05:44:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=WQ4vxzfqc94W95Cu6hblW5cndMng6yMrqe24KGOyDZs-1731474845173-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c46b43ad78856-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:14:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-ada-002'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999993'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_878334cf0656617b9784da2a647be8f8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=D635xGLQfeOnjFBBlnE1OBS_JLJp_C_hWnC1SntsoVA-1731474845-1.0.1.1-WZNs_i0U4GThPT8JwAYgzme.wWrlco.ocN6NXLRG09VsldgKo56toCl38WLl0nlmTQcaPAoEIzaBRLuUgrT1DQ; path=/; expires=Wed, 13-Nov-24 05:44:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=WQ4vxzfqc94W95Cu6hblW5cndMng6yMrqe24KGOyDZs-1731474845173-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c46b43ad78856-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Wed, 13 Nov 2024 05:14:05 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-ada-002'), ('openai-organization', 'user-1d0msvoq8nnxhbarposyss9g'), ('openai-processing-ms', '120'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999993'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_878334cf0656617b9784da2a647be8f8'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=D635xGLQfeOnjFBBlnE1OBS_JLJp_C_hWnC1SntsoVA-1731474845-1.0.1.1-WZNs_i0U4GThPT8JwAYgzme.wWrlco.ocN6NXLRG09VsldgKo56toCl38WLl0nlmTQcaPAoEIzaBRLuUgrT1DQ; path=/; expires=Wed, 13-Nov-24 05:44:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=WQ4vxzfqc94W95Cu6hblW5cndMng6yMrqe24KGOyDZs-1731474845173-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e1c46b43ad78856-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Wed, 13 Nov 2024 05:14:05 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-ada-002'), ('openai-organization', 'user-1d0msvoq8nnxhbarposyss9g'), ('openai-processing-ms', '120'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999993'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_878334cf0656617b9784da2a647be8f8'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=D635xGLQfeOnjFBBlnE1OBS_JLJp_C_hWnC1SntsoVA-1731474845-1.0.1.1-WZNs_i0U4GThPT8JwAYgzme.wWrlco.ocN6NXLRG09VsldgKo56toCl38WLl0nlmTQcaPAoEIzaBRLuUgrT1DQ; path=/; expires=Wed, 13-Nov-24 05:44:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=WQ4vxzfqc94W95Cu6hblW5cndMng6yMrqe24KGOyDZs-1731474845173-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e1c46b43ad78856-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Wed, 13 Nov 2024 05:14:05 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-ada-002'), ('openai-organization', 'user-1d0msvoq8nnxhbarposyss9g'), ('openai-processing-ms', '120'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999993'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_878334cf0656617b9784da2a647be8f8'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=D635xGLQfeOnjFBBlnE1OBS_JLJp_C_hWnC1SntsoVA-1731474845-1.0.1.1-WZNs_i0U4GThPT8JwAYgzme.wWrlco.ocN6NXLRG09VsldgKo56toCl38WLl0nlmTQcaPAoEIzaBRLuUgrT1DQ; path=/; expires=Wed, 13-Nov-24 05:44:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=WQ4vxzfqc94W95Cu6hblW5cndMng6yMrqe24KGOyDZs-1731474845173-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e1c46b43ad78856-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_878334cf0656617b9784da2a647be8f8\n",
      "request_id: req_878334cf0656617b9784da2a647be8f8\n",
      "request_id: req_878334cf0656617b9784da2a647be8f8\n",
      "DEBUG:llama_index.core.indices.utils:> Top 2 nodes:\n",
      "> [Node 67444546-b7f5-485e-8891-89ae42b847ec] [Similarity score:             0.865388] Vector-Space ModelQuery as vector:•We regard query as short document•We return the documents rank...\n",
      "> [Node 33182804-e49f-44cf-9858-fc71f76b1213] [Similarity score:             0.85925] Documents as Vectors•So we have a |V|-dimensional vector space•Terms are axes of the space•Docume...\n",
      "> Top 2 nodes:\n",
      "> [Node 67444546-b7f5-485e-8891-89ae42b847ec] [Similarity score:             0.865388] Vector-Space ModelQuery as vector:•We regard query as short document•We return the documents rank...\n",
      "> [Node 33182804-e49f-44cf-9858-fc71f76b1213] [Similarity score:             0.85925] Documents as Vectors•So we have a |V|-dimensional vector space•Terms are axes of the space•Docume...\n",
      "> Top 2 nodes:\n",
      "> [Node 67444546-b7f5-485e-8891-89ae42b847ec] [Similarity score:             0.865388] Vector-Space ModelQuery as vector:•We regard query as short document•We return the documents rank...\n",
      "> [Node 33182804-e49f-44cf-9858-fc71f76b1213] [Similarity score:             0.85925] Documents as Vectors•So we have a |V|-dimensional vector space•Terms are axes of the space•Docume...\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}, {'role': 'user', 'content': 'Context information is below.\\n---------------------\\npage_label: 15\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf\\n\\nVector-Space ModelQuery as vector:•We regard query as short document•We return the documents ranked by the closeness of their vectors to the query, also represented as a vector.\\n•Vector-space model was developed in the SMART system (Salton, c.1970) and standardly used by TREC participants and web IR systems\\n\\npage_label: 28\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf\\n\\nDocuments as Vectors•So we have a |V|-dimensional vector space•Terms are axes of the space•Documents are points or vectors in this space•Very high-dimensional: tens of millions of dimensions when you apply this to a web search engine•These are very sparse vectors - most entries are zero.\\nSec. 6.3\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What is a vector space model?\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}, {'role': 'user', 'content': 'Context information is below.\\n---------------------\\npage_label: 15\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf\\n\\nVector-Space ModelQuery as vector:•We regard query as short document•We return the documents ranked by the closeness of their vectors to the query, also represented as a vector.\\n•Vector-space model was developed in the SMART system (Salton, c.1970) and standardly used by TREC participants and web IR systems\\n\\npage_label: 28\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf\\n\\nDocuments as Vectors•So we have a |V|-dimensional vector space•Terms are axes of the space•Documents are points or vectors in this space•Very high-dimensional: tens of millions of dimensions when you apply this to a web search engine•These are very sparse vectors - most entries are zero.\\nSec. 6.3\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What is a vector space model?\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}, {'role': 'user', 'content': 'Context information is below.\\n---------------------\\npage_label: 15\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf\\n\\nVector-Space ModelQuery as vector:•We regard query as short document•We return the documents ranked by the closeness of their vectors to the query, also represented as a vector.\\n•Vector-space model was developed in the SMART system (Salton, c.1970) and standardly used by TREC participants and web IR systems\\n\\npage_label: 28\\nfile_path: /Users/zhengwei/Documents/codeL/llamaindex/data/wk 1 VectorSpaceModel.pdf\\n\\nDocuments as Vectors•So we have a |V|-dimensional vector space•Terms are axes of the space•Documents are points or vectors in this space•Very high-dimensional: tens of millions of dimensions when you apply this to a web search engine•These are very sparse vectors - most entries are zero.\\nSec. 6.3\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What is a vector space model?\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      "close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c5da390>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c5da390>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c5da390>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x149791ac0> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x149791ac0> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x149791ac0> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c84e4d0>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c84e4d0>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14c84e4d0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:14:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'874'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199638'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'108ms'), (b'x-request-id', b'req_274e5ff08871bab77c18f4089d2c8640'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c46b7192444af-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:14:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'874'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199638'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'108ms'), (b'x-request-id', b'req_274e5ff08871bab77c18f4089d2c8640'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c46b7192444af-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 13 Nov 2024 05:14:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-1d0msvoq8nnxhbarposyss9g'), (b'openai-processing-ms', b'874'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199638'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'108ms'), (b'x-request-id', b'req_274e5ff08871bab77c18f4089d2c8640'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e1c46b7192444af-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:14:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '874', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199638', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '108ms', 'x-request-id': 'req_274e5ff08871bab77c18f4089d2c8640', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c46b7192444af-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:14:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '874', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199638', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '108ms', 'x-request-id': 'req_274e5ff08871bab77c18f4089d2c8640', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c46b7192444af-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 13 Nov 2024 05:14:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-1d0msvoq8nnxhbarposyss9g', 'openai-processing-ms': '874', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199638', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '108ms', 'x-request-id': 'req_274e5ff08871bab77c18f4089d2c8640', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e1c46b7192444af-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_274e5ff08871bab77c18f4089d2c8640\n",
      "request_id: req_274e5ff08871bab77c18f4089d2c8640\n",
      "request_id: req_274e5ff08871bab77c18f4089d2c8640\n",
      "A vector space model is a method where queries and documents are represented as vectors in a high-dimensional space. In this model, terms serve as axes in the space, and documents are depicted as points or vectors within this space. The vector space model is commonly used in information retrieval systems to rank documents based on the proximity of their vectors to the query vector.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is a vector space model?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='BM25 is a retrieval model that was originally designed for short catalog records of fairly consistent length. It is a non-binary model that takes into account term frequency and document length, making it sensitive to these quantities. BM25, also known as Okapi, has been widely used and is considered one of the most robust retrieval models from 1994 until today.', source_nodes=[NodeWithScore(node=TextNode(id_='c6396c19-5775-40da-9028-89b020fee7b3', embedding=None, metadata={'page_label': '27', 'file_name': 'wk 4prob-IR.pdf', 'file_path': '/Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf', 'file_type': 'application/pdf', 'file_size': 977888, 'creation_date': '2024-11-13', 'last_modified_date': '2024-11-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e037c940-7dcd-43cc-88d6-456cc1973d45', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '27', 'file_name': 'wk 4prob-IR.pdf', 'file_path': '/Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf', 'file_type': 'application/pdf', 'file_size': 977888, 'creation_date': '2024-11-13', 'last_modified_date': '2024-11-13'}, hash='b1b61abf5098c3a57c39ebec6db52c7690d4f6b99c84e3b99a384382b6b6a180')}, text='CS3245–InformationRetrieval\\nOkapiBM25:ANonbinaryModel\\nInformationRetrieval\\n■TheBIMwasoriginallydesignedforshortcatalog recordsoffairlyconsistentlength,anditworks  reasonablyinthesecontexts■Formodernfull--textsearchcollections,amodel should pay attention to term frequency and documentlength■BestMatch25(i.e.,BM25orOkapi)issensitiveto thesequantities■From1994untiltoday,BM25isoneofthemost widelyusedandrobustretrievalmodels\\nSec.11.4.3', mimetype='text/plain', start_char_idx=0, end_char_idx=433, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7958927110952833), NodeWithScore(node=TextNode(id_='b11808bd-7285-4ded-9841-4c07685d5b80', embedding=None, metadata={'page_label': '30', 'file_name': 'wk 4prob-IR.pdf', 'file_path': '/Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf', 'file_type': 'application/pdf', 'file_size': 977888, 'creation_date': '2024-11-13', 'last_modified_date': '2024-11-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c49a5178-1c5d-4f88-b26e-16d8d8f3d2e8', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '30', 'file_name': 'wk 4prob-IR.pdf', 'file_path': '/Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf', 'file_type': 'application/pdf', 'file_size': 977888, 'creation_date': '2024-11-13', 'last_modified_date': '2024-11-13'}, hash='f0c1bc7f871299cacb99518aead03cd5cbf24eccff24a45832ae1868c656368b')}, text='CS3245–InformationRetrieval\\nOkapiBM25:Factoring in the Relevance Feedback in Equation you see in slide 19.\\nInformationRetrieval\\nSec.11.4.3\\nIncluding relevance feedback in c_tor the above term will give us the equation below for BM25. s is |VR_t|S –s is |VNR_t|. |VR| = total retrieved relevant documents. |VR_t| = total retrieved relevant documents where term t appears. |VNR_t| = total retrieved relevant documents where term t does not appear. Check slide 19 and consider we got some user inputs on the relevance', mimetype='text/plain', start_char_idx=0, end_char_idx=514, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7788391750895559)], metadata={'c6396c19-5775-40da-9028-89b020fee7b3': {'page_label': '27', 'file_name': 'wk 4prob-IR.pdf', 'file_path': '/Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf', 'file_type': 'application/pdf', 'file_size': 977888, 'creation_date': '2024-11-13', 'last_modified_date': '2024-11-13'}, 'b11808bd-7285-4ded-9841-4c07685d5b80': {'page_label': '30', 'file_name': 'wk 4prob-IR.pdf', 'file_path': '/Users/zhengwei/Documents/codeL/llamaindex/data/wk 4prob-IR.pdf', 'file_type': 'application/pdf', 'file_size': 977888, 'creation_date': '2024-11-13', 'last_modified_date': '2024-11-13'}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.query(\"What is BM25?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
